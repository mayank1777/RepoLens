Owner,Repository Name,Description,URL,Stars,Forks,Watchers,Open Issues,Languages,Topics,License,Creation Date,Last Update Date,Size (KB),Visibility,Forked From,Default Branch,README
torvalds,linux,Linux kernel source tree,https://github.com/torvalds/linux,170698,51850,8059,340,C: 1277611935; Assembly: 9556140; Shell: 4696281; Makefile: 2580853; Python: 2508115; Perl: 1251442; Rust: 741386; Roff: 195000; SmPL: 160647; C++: 156258; Yacc: 127858; Lex: 68792; Awk: 43651; UnrealScript: 16848; Gherkin: 9724; Raku: 3859; M4: 3329; MATLAB: 2482; Clojure: 2260; XS: 1239; sed: 379; CMake: 68,,Other,2011-09-04T22:48:12Z,2024-05-02T17:23:04Z,5069816,public,None,master,linux kernel there are several guides for kernel developers and users these guides can be rendered in a number of formats like html and pdf please read documentationadminguidereadmerst first in order to build the documentation use make htmldocs or make pdfdocs the formatted documentation can also be read online at there are various text files in the documentation subdirectory several of them using the restructuredtext markup notation please read the documentationprocesschangesrst file as it contains the requirements for building and running the kernel and information about the problems which may result by upgrading your kernel
freebsd,freebsd-src,The FreeBSD src tree publish-only repository. Experimenting with 'simple' pull requests....,https://github.com/freebsd/freebsd-src,7480,2777,464,19,None,,Other,2011-09-05T12:55:55Z,2024-05-02T17:15:21Z,3099190,public,None,main,freebsd source this is the top level of the freebsd source directory freebsd is an operating system used to power modern servers desktops and embedded platforms a large community has continually developed it for more than thirty years its advanced networking security and storage features have made freebsd the platform of choice for many of the busiest web sites and most pervasive embedded networking and storage devices for copyright information please see the file copyrightcopyright in this directory additional copyright information also exists for some sources in this tree please see the specific source directories for more information the makefile in this directory supports a number of targets for building components or all of the freebsd source tree see build7 config8 freebsd handbook on building userland and handbook for kernels for more information including setting make1 variables for information on the cpu architectures and platforms supported by freebsd see the freebsd websites platforms page source roadmap directory description bin systemuser commands cddl various commands and libraries under the common development and distribution license contrib packages contributed by 3rd parties crypto cryptography stuff see cryptoreadmecryptoreadme etc template files for etc gnu commands and libraries under the gnu general public license gpl or lesser general public license lgpl please see gnucopyinggnucopying and gnucopyinglibgnucopyinglib for more information include system include files kerberos5 kerberos5 heimdal package lib system libraries libexec system daemons release release building makefile associated tools rescue build system for statically linked rescue utilities sbin system commands secure cryptographic libraries and commands share shared resources stand boot loader sources sys kernel sources see sysreadmemdsysreadmemd targets support for experimental dirdepsbuild tests regression tests which can be run by kyua see testsreadmetestsreadme for additional information tools utilities for regression testing and miscellaneous tasks usrbin user commands usrsbin system administration commands for information on synchronizing your source tree with one or more of the freebsd projects development branches please see freebsd handbook
openbsd,src,Read-only git conversion of OpenBSD's official CVS src repository. Pull requests not accepted - send diffs to the tech@ mailing list.,https://github.com/openbsd/src,3044,846,169,0,C: 820252261; C++: 216971216; Perl: 38095712; Roff: 28749172; GCC Machine Description: 10738080; Makefile: 7823869; Shell: 6516893; Assembly: 6166172; HTML: 6149629; Python: 4257751; Raku: 3928562; Yacc: 3389164; Scheme: 1993005; CMake: 1706734; XS: 1228361; TeX: 1216527; M4: 1172134; Scala: 549090; RPC: 526089; Fortran: 456220; Objective-C: 401531; Lex: 372470; Awk: 328547; DIGITAL Command Language: 277611; OCaml: 258793; PLSQL: 164721; Prolog: 124282; Go: 106437; PHP: 78254; sed: 67885; Emacs Lisp: 67805; NASL: 62639; JavaScript: 61533; Scilab: 58450; Batchfile: 50562; GAP: 42811; CSS: 40995; 1C Enterprise: 28875; Objective-C++: 28332; C#: 27973; Forth: 25495; Logos: 21340; Vim Script: 21232; Pawn: 17573; MATLAB: 15476; Dockerfile: 15283; Gnuplot: 14555; Mathematica: 14059; Smarty: 7549; KRL: 7037; Turing: 6878; Jupyter Notebook: 6852; POV-Ray SDL: 5853; XSLT: 4707; SWIG: 3174; Ada: 2837; TypeScript: 2805; Java: 1848; EmberScript: 1721; Rez: 1599; AppleScript: 1429; GDB: 1105; R: 985; DTrace: 825; Rebol: 632; Standard ML: 292; Lua: 177; Terra: 4; D: 2,openbsd,None,2016-08-30T18:18:25Z,2024-05-02T16:21:35Z,1474588,public,None,master,
reactos,reactos,A free Windows-compatible Operating System,https://github.com/reactos/reactos,14073,1676,350,227,C: 214652331; C++: 25163284; Assembly: 1133680; CMake: 1089232; Yacc: 518890; JavaScript: 333258; Python: 302268; Ruby: 228110; Batchfile: 165756; VBScript: 136079; HTML: 83528; Makefile: 47539; Perl: 43380; Lex: 39691; Shell: 33006; Smarty: 28152; M4: 18861; Roff: 14415; XSLT: 6126; RenderScript: 2673; Scilab: 1718; CSS: 383; Objective-C: 281; GLSL: 27,c;drivers;gpl;hacktoberfest;kernel;operating-system;os;osdev;reactos;win32;win32api;windows;x86,GNU General Public License v2.0,2017-10-03T08:04:52Z,2024-05-02T17:01:42Z,637134,public,None,master,quick links website bull official chat bull wiki bull forum bull community discord bull jira bug tracker bull reactos git mirror bull testman what is reactos reactos is an open source effort to develop a quality operating system that is compatible with applications and drivers written for the microsoft windows nt family of operating systems nt4 xp vista the reactos project although currently focused on windows server compatibility is always keeping an eye toward compatibility with windows vista and future windows nt releases the code of reactos is licensed under gnu gpl product quality warning reactos is currently an alpha quality operating system this means that reactos is under heavy development and you have to be ready to encounter some problems different things may not work well and it can corrupt the data present on your hard disk it is highly recommended to test reactos on a virtual machine or on a computer with no sensitive or critical data building build rosbewinbadgerosbewinlink rosbeunixbadgerosbeunixlink coveritybadgecoveritylink to build the system it is strongly advised to use the reactos build environment rosbe uptodate versions for windows and for unixgnulinux are available from our download page at build environment alternatively one can use microsoft visual c msvc version building with msvc is covered here visual studio or microsoft visual c see building reactos article for more details binaries to build reactos you must run the configure script in the directory you want to have your build files choose configurecmd or configuresh depending on your system then run ninja to build a module you want or just ninja to build all modules bootable images to build a bootable cd image run ninja bootcd from the build directory this will create a cd image with a filename bootcdiso you can always download fresh binary builds of bootable images from the daily builds page installing by default reactos currently can only be installed on a machine that has a fat16 or fat32 partition as the active bootable partition the partition on which reactos is to be installed which may or may not be the bootable partition must also be formatted as fat16 or fat32 reactos setup can format the partitions if needed starting with reactos can be installed using the btrfs file system but consider this as an experimental feature and thus regressions not triggered on fat setup may be observed to install reactos from the bootable cd distribution extract the archive contents then burn the cd image boot from it and follow the instructions see installing reactos wiki page or installinstall for more details testing if you discover a bug in reactos search on jira first it might be reported already if not report the bug providing logs and as much information as possible see file bugs for a guide note the bug tracker is not for discussions please use our official chat or our forum contributing prwelcomebadge we are always looking for developers check how to contributecontributingmd if you are willing to participate legal notice if you have seen proprietary microsoft windows source code including but not limited to the leaked windows nt nt source code and the windows research kernel your contribution wont be accepted because of potential copyright violation try out cloudbased reactos development using gitpod and docker open in gitpod you can also support reactos by donating we rely on our backers to maintain our servers and accelerate development by hiring fulltime devs more information reactos is a free and open source operating system based on the windows architecture providing support for existing applications and drivers and an alternative to the current dominant consumer operating system it is not another wrapper built on linux like wine it does not attempt or plan to compete with wine in fact the usermode part of reactos is almost entirely winebased and our two teams have cooperated closely in the past reactos is also not yet another os it does not attempt to be a third player like any other alternative os out there people are not meant to uninstall linux and use reactos instead reactos is a replacement for windows users who want a windows replacement that behaves just like windows more information is available at reactosorg also see the mediadocmediadoc subdirectory for some sparse notes who is responsible active devs are listed as members of github organization see also the creditscredits file for others code mirrors the main development is done on github we have an alternative mirror in case github is down there is also an obsolete svn archive repository that is kept for historical purposes coveritybadge rosbewinbadge rosbeunixbadge prwelcomebadge coveritylink rosbewinlink rosbeunixlink
archlinux,svntogit-packages,Automatic import of svn 'packages' repo (read-only mirror),https://github.com/archlinux/svntogit-packages,318,255,30,0,Shell: 8074429; C++: 37200; Python: 33198; Roff: 27948; Lua: 16536; Perl: 13096; JavaScript: 9356; Makefile: 5160; Vim Script: 4670; M4: 4506; C: 3160; Common Lisp: 1336,,None,2020-07-21T20:42:32Z,2024-03-02T15:46:47Z,468229,public,None,master,
haiku,haiku,The Haiku operating system. (Pull requests will be ignored; patches may be sent to https://review.haiku-os.org).,https://github.com/haiku/haiku,1770,334,122,0,C++: 65565161; C: 56522892; Assembly: 514231; HTML: 388333; Python: 153143; Shell: 101282; Yacc: 92951; Roff: 73357; JavaScript: 55261; Makefile: 27592; Awk: 26795; Lex: 18000; Objective-C: 6989; Scheme: 6192; Perl: 2784; GLSL: 1891; PHP: 757; Module Management System: 316,beos;haiku;operating-system,Other,2011-06-16T05:35:19Z,2024-05-02T16:40:39Z,453202,public,None,master,haiku homepage mailing lists irc channels issue tracker api docs haiku is an opensource operating system that specifically targets personal computing inspired by the beos haiku is fast simple to use easy to learn and yet very powerful goals sensible defaults with minimal configuration required clean clear concise code unified desktop environment trying haiku haiku provides prebuilt nightly images and release images haiku is compatible with a large variety of hardware but in case you dont want to take the plunge and install haiku on bare metal you can install it on a virtual machine vm instead if youve never used a vm before you can follow one of the emulating haiku guides compiling haiku see readmecompiling contributing haiku is a meritocratic open source project with a large variety of tasks even if you cant write code you can still help haiku needs designers technical writers translators testers get involved and help out contributing code if youre submitting a patch to us please make sure youre following the patch submitting guidelines if youre having trouble finding something in the source tree you can use one of our webbased source code browsers opengrok provided by landon fuller git provided by haiku inc contributing documentation the main piece of documentation that still needs work are the api docs found in the tree at docsuser just find an undocumented class write documentation for it and submit a patch contributing translations see wikii18n contributing software ports see haikuports contributing to our infrastructure see infrastructure
rails,rails,Ruby on Rails,https://github.com/rails/rails,54932,21315,2344,1170,Ruby: 16628269; JavaScript: 213390; HTML: 97315; SCSS: 44622; CSS: 27259; Dockerfile: 2032; Yacc: 1003; Shell: 662,activejob;activerecord;framework;html;mvc;rails;ruby,MIT License,2008-04-11T02:19:47Z,2024-05-02T16:39:43Z,276541,public,None,main,welcome to rails whats rails rails is a webapplication framework that includes everything needed to create databasebacked web applications according to the modelviewcontroller mvc pattern understanding the mvc pattern is key to understanding rails mvc divides your application into three layers model view and controller each with a specific responsibility model layer the model layer represents the domain model such as account product person post etc and encapsulates the business logic specific to your application in rails databasebacked model classes are derived from activerecordbase active recordactiverecordreadmerdoc allows you to present the data from database rows as objects and embellish these data objects with business logic methods although most rails models are backed by a database models can also be ordinary ruby classes or ruby classes that implement a set of interfaces as provided by the active modelactivemodelreadmerdoc module view layer the view layer is composed of templates that are responsible for providing appropriate representations of your applications resources templates can come in a variety of formats but most view templates are html with embedded ruby code erb files views are typically rendered to generate a controller response or to generate the body of an email in rails view generation is handled by action viewactionviewreadmerdoc controller layer the controller layer is responsible for handling incoming http requests and providing a suitable response usually this means returning html but rails controllers can also generate xml json pdfs mobilespecific views and more controllers load and manipulate models and render view templates in order to generate the appropriate http response in rails incoming requests are routed by action dispatch to an appropriate controller and controller classes are derived from actioncontrollerbase action dispatch and action controller are bundled together in action packactionpackreadmerdoc frameworks and libraries active recordactiverecordreadmerdoc active modelactivemodelreadmerdoc action packactionpackreadmerdoc and action viewactionviewreadmerdoc can each be used independently outside rails in addition to that rails also comes with action maileractionmailerreadmerdoc a library to generate and send emails action mailboxactionmailboxreadmemd a library to receive emails within a rails application active jobactivejobreadmemd a framework for declaring jobs and making them run on a variety of queuing backends action cableactioncablereadmemd a framework to integrate websockets with a rails application active storageactivestoragereadmemd a library to attach cloud and local files to rails applications action textactiontextreadmemd a library to handle rich text content active supportactivesupportreadmerdoc a collection of utility classes and standard library extensions that are useful for rails and may also be used independently outside rails getting started install rails at the command prompt if you havent yet bash gem install rails at the command prompt create a new rails application bash rails new myapp where myapp is the application name change directory to myapp and start the web server bash cd myapp binrails server run with help or h for options go to and youll see the rails bootscreen with your rails and ruby versions follow the guidelines to start developing your application you may find the following resources handy getting started with rails ruby on rails guides the api documentation contributing we encourage you to contribute to ruby on rails please check out the contributing to ruby on rails guide for guidelines about how to proceed join us trying to report a possible security vulnerability in rails please check out our security policy for guidelines about how to proceed everyone interacting in rails and its subprojects codebases issue trackers chat rooms and mailing lists is expected to follow the rails code of conduct license ruby on rails is released under the mit license
django,django,The Web framework for perfectionists with deadlines.,https://github.com/django/django,76881,30811,2308,184,Python: 16979238; HTML: 247692; JavaScript: 155946; CSS: 93701; Smarty: 392; Makefile: 125; Procfile: 47,apps;django;framework;models;orm;python;templates;views;web,"BSD 3-Clause ""New"" or ""Revised"" License",2012-04-28T02:47:18Z,2024-05-02T17:05:26Z,252065,public,None,main,django django is a highlevel python web framework that encourages rapid development and clean pragmatic design thanks for checking it out all documentation is in the docs directory and online at if youre just getting started heres how we recommend you read the docs first read docsintroinstalltxt for instructions on installing django next work through the tutorials in order docsintrotutorial01txt docsintrotutorial02txt etc if you want to set up an actual deployment server read docshowtodeploymentindextxt for instructions youll probably want to read through the topical guides in docstopics next from there you can jump to the howtos in docshowto for specific problems and check out the reference docsref for gory details see docsreadme for instructions on building an html version of the docs docs are updated rigorously if you find any problems in the docs or think they should be clarified in any way please take seconds to fill out a ticket here to get more help join the django channel on ircliberachat lots of helpful people hang out there webchat is available join the djangousers mailing list or read the archives at join the django discord community join the community on the django forum to contribute to django check out for information about getting involved to run djangos test suite follow the instructions in the unit tests section of docsinternalscontributingwritingcodeunitteststxt published online at supporting the development of django djangos development depends on your contributions if you depend on django remember to support the django software foundation
expressjs,express,"Fast, unopinionated, minimalist web framework for node.",https://github.com/expressjs/express,63833,13791,1711,195,JavaScript: 538067; Makefile: 330; Shell: 229,express;javascript;nodejs;server,MIT License,2009-06-26T18:56:01Z,2024-05-02T16:54:02Z,9217,public,None,master,express logo fast unopinionated minimalist web framework for nodejs npm versionnpmversionimagenpmurl npm install sizenpminstallsizeimagenpminstallsizeurl npm downloadsnpmdownloadsimagenpmdownloadsurl js const express requireexpress const app express appget function req res ressendhello world applisten3000 installation this is a nodejs module available through the npm registry before installing download and install nodejs nodejs or higher is required if this is a brand new project make sure to create a packagejson first with the npm init command installation is done using the npm install command console npm install express follow our installing guide for more information features robust routing focus on high performance superhigh test coverage http helpers redirection caching etc view system supporting template engines content negotiation executable for generating applications quickly docs community website and documentation website repo express on libera chat irc github organization for official middleware modules visit the wiki google group for discussion gitter for support and discussion protip be sure to read migrating from 3x to 4x as well as new features in 4x quick start the quickest way to get started with express is to utilize the executable express1 to generate an application as shown below install the executable the executables major version will match expresss console npm install g expressgenerator4 create the app console express tmpfoo cd tmpfoo install dependencies console npm install start the server console npm start view the website at philosophy the express philosophy is to provide small robust tooling for http servers making it a great solution for single page applications websites hybrids or public http apis express does not force you to use any specific orm or template engine with support for over template engines via consolidatejs you can quickly craft your perfect framework examples to view the examples clone the express repo and install the dependencies console git clone depth cd express npm install then run whichever example you want console node examplescontentnegotiation contributing linux buildgithubactionsciimagegithubactionsciurl windows buildappveyorimageappveyorurl test coveragecoverallsimagecoverallsurl the expressjs project welcomes all constructive contributions contributions take many forms from code for bug fixes and enhancements to additions and fixes to documentation additional tests triaging incoming pull requests and issues and more see the contributing guidecontributingmd for more technical details on contributing security issues if you discover a security vulnerability in express please see security policies and proceduressecuritymd running tests to run the test suite first install the dependencies then run npm test console npm install npm test people the original author of express is tj holowaychuk the current lead maintainer is douglas christopher wilson list of all contributors license mitlicense appveyorimage appveyorurl coverallsimage coverallsurl githubactionsciimage githubactionsciurl npmdownloadsimage npmdownloadsurl npminstallsizeimage npminstallsizeurl npmurl npmversionimage
angular,angular,Deliver web apps with confidence ðŸš€,https://github.com/angular/angular,94583,24641,3021,1496,TypeScript: 26618781; JavaScript: 2778010; HTML: 710608; Starlark: 699900; CSS: 337418; SCSS: 89847; Shell: 51649; jq: 619; Less: 80,angular;javascript;pwa;typescript;web;web-framework;web-performance,MIT License,2014-09-18T16:12:01Z,2024-05-02T17:13:42Z,498213,public,None,main,angular the modern web developers platform angular is a development platform for building mobile and desktop web applications using typescriptjavascript and other languages angulardev contributing guidelines submit an issue blog nbsp nbsp documentation get started with angular learn the fundamentals and explore advanced topics on our documentation website getting startedquickstart architecturearchitecture components and templatescomponentstemplates formsforms apiapi advanced angular elementsangularelements server side renderingssr schematicsschematics lazy loadinglazyloading animationsanimations local development to contribute to the angular docs check out the angulardev readmeadevreadmemd development setup prerequisites install nodejs which includes node package managernpm setting up a project install the angular cli globally npm install g angularcli create workspace ng new project name run the application cd project name ng serve angular is crossplatform fast scalable has incredible tooling and is loved by millions quickstart get started in minutesquickstart ecosystem angular command line clicli angular materialangularmaterial changelog learn about the latest improvementschangelog upgrading check out our upgrade guide to find out the best way to upgrade your project contributing contributing guidelines read through our contributing guidelinescontributing to learn about our submission process coding rules and more want to help want to report a bug contribute some code or improve the documentation excellent read up on our guidelines for contributingcontributing and then check out one of our issues labeled as help wanted or good first issue code of conduct help us keep angular open and inclusive please read and follow our code of conductcodeofconduct community join the conversation and help the community x formerly twitterx formerly twitter discorddiscord gittergitter youtubeyoutube stackoverflowstackoverflow find a local meetupmeetup love angular badge love angular give our repo a star star arrowup contributing contributingmd quickstart changelog changelogmd ng documentation angularmaterial cli architecture componentstemplates forms api angularelements ssr schematics lazyloading nodejs npm codeofconduct codeofconductmd x formerly twitter discord gitter stackoverflow youtube meetup animations
facebook,react,The library for web and native user interfaces.,https://github.com/facebook/react,222123,45296,6623,839,JavaScript: 4236798; HTML: 111156; CSS: 64767; C++: 44290; TypeScript: 21177; CoffeeScript: 17433; C: 5227; Shell: 1485; Python: 259; Makefile: 189,declarative;frontend;javascript;library;react;ui,MIT License,2013-05-24T16:15:54Z,2024-05-02T17:11:21Z,459578,public,None,main,react middot github license npm version circleci status prs welcome react is a javascript library for building user interfaces declarative react makes it painless to create interactive uis design simple views for each state in your application and react will efficiently update and render just the right components when your data changes declarative views make your code more predictable simpler to understand and easier to debug componentbased build encapsulated components that manage their own state then compose them to make complex uis since component logic is written in javascript instead of templates you can easily pass rich data through your app and keep the state out of the dom learn once write anywhere we dont make assumptions about the rest of your technology stack so you can develop new features in react without rewriting existing code react can also render on the server using node and power mobile apps using react native learn how to use react in your project installation react has been designed for gradual adoption from the start and you can use as little or as much react as you need use quick start to get a taste of react add react to an existing project to use as little or as much react as you need create a new react app if youre looking for a powerful javascript toolchain documentation you can find the react documentation on the website check out the getting started page for a quick overview the documentation is divided into several sections quick start tutorial thinking in react installation describing the ui adding interactivity managing state advanced guides api reference where to get support contributing guide you can improve it by sending pull requests to this repository examples we have several examples on the website here is the first one to get you started jsx import createroot from reactdomclient function hellomessage name return hello name const root createrootdocumentgetelementbyidcontainer rootrender this example will render hello taylor into a container on the page youll notice that we used an htmllike syntax we call it jsx jsx is not required to use react but it makes code more readable and writing it feels like writing html contributing the main purpose of this repository is to continue evolving react core making it faster and easier to use development of react happens in the open on github and we are grateful to the community for contributing bugfixes and improvements read below to learn how you can take part in improving react code of conduct facebook has adopted a code of conduct that we expect project participants to adhere to please read the full text so that you can understand what actions will and will not be tolerated contributing guide read our contributing guide to learn about our development process how to propose bugfixes and improvements and how to build and test your changes to react good first issues to help you get your feet wet and get you familiar with our contribution process we have a list of good first issues that contain bugs that have a relatively limited scope this is a great place to get started license react is mit licensedlicense
pallets,flask,The Python micro framework for building web applications.,https://github.com/pallets/flask,66422,15942,2125,7,Python: 538014; HTML: 405; Shell: 193; CSS: 18,flask;jinja;pallets;python;web-framework;werkzeug;wsgi,"BSD 3-Clause ""New"" or ""Revised"" License",2010-04-06T11:11:59Z,2024-05-02T15:47:02Z,10496,public,None,main,flask flask is a lightweight wsgi web application framework it is designed to make getting started quick and easy with the ability to scale up to complex applications it began as a simple wrapper around werkzeug and jinja and has become one of the most popular python web application frameworks flask offers suggestions but doesnt enforce any dependencies or project layout it is up to the developer to choose the tools and libraries they want to use there are many extensions provided by the community that make adding new functionality easy wsgi werkzeug jinja a simple example python save this as apppy from flask import flask app flaskname approute def hello return hello world flask run running on press ctrlc to quit donate the pallets organization develops and supports flask and the libraries it uses in order to grow the community of contributors and users and allow the maintainers to devote more time to the projects please donate today please donate today
tensorflow,tensorflow,An Open Source Machine Learning Framework for Everyone,https://github.com/tensorflow/tensorflow,182569,73867,7636,2375,C++: 97528394; Python: 45642839; MLIR: 10255404; Starlark: 7072736; HTML: 4686483; Go: 2191915; C: 1271365; Java: 1167165; Jupyter Notebook: 781419; Shell: 676163; Objective-C++: 279654; Objective-C: 169202; CMake: 135109; Smarty: 121587; Swift: 81520; Dockerfile: 24322; C#: 13585; Batchfile: 11659; Ruby: 8898; Perl: 7536; Pawn: 7360; Roff: 5034; Cython: 3899; Makefile: 2845; Vim Snippet: 58,deep-learning;deep-neural-networks;distributed;machine-learning;ml;neural-network;python;tensorflow,Apache License 2.0,2015-11-07T01:19:20Z,2024-05-02T17:23:45Z,1010953,public,None,master,python pypi doi cii best practices openssf scorecard fuzzing status fuzzing status ossrank contributor covenant tf official continuous tf official nightly documentation documentation tensorflow is an endtoend open source platform for machine learning it has a comprehensive flexible ecosystem of tools libraries and community resources that lets researchers push the stateoftheart in ml and developers easily build and deploy mlpowered applications tensorflow was originally developed by researchers and engineers working within the machine intelligence team at google brain to conduct research in machine learning and neural networks however the framework is versatile enough to be used in other areas as well tensorflow provides stable python and c apis as well as a nonguaranteed backward compatible api for other languages keep uptodate with release announcements and security updates by subscribing to announcetensorfloworg see all the mailing lists install see the tensorflow install guide for the pip package to enable gpu support use a docker container and build from source to install the current release which includes support for cudaenabled gpu cards ubuntu and windows pip install tensorflow other devices directx and macosmetal are supported using device plugins a smaller cpuonly package is also available pip install tensorflowcpu to update tensorflow to the latest version add upgrade flag to the above commands nightly binaries are available for testing using the tfnightly and tfnightlycpu packages on pypi try your first tensorflow program shell python python import tensorflow as tf tfadd1 2numpy hello tfconstanthello tensorflow hellonumpy bhello tensorflow for more examples see the tensorflow tutorials contribution guidelines if you want to contribute to tensorflow be sure to review the contribution guidelinescontributingmd this project adheres to tensorflows code of conductcodeofconductmd by participating you are expected to uphold this code we use github issues for tracking requests and bugs please see tensorflow forum for general questions and discussion and please direct specific questions to stack overflow the tensorflow project strives to abide by generally accepted best practices in opensource software development patching guidelines follow these steps to patch a specific version of tensorflow for example to apply fixes to bugs or security vulnerabilities clone the tensorflow repo and switch to the corresponding branch for your desired tensorflow version for example branch r28 for version apply that is cherrypick the desired changes and resolve any code conflicts run tensorflow tests and ensure they pass build the tensorflow pip package from source continuous build status you can find more communitysupported platforms and configurations in the tensorflow sig build community builds table official builds build type status artifacts linux cpu status pypi linux gpu status pypi linux xla status tba macos status pypi windows cpu status pypi windows gpu status pypi android status download raspberry pi and status py3 raspberry pi and status py3 libtensorflow macos cpu status temporarily unavailable nightly binary official gcs libtensorflow linux cpu status temporarily unavailable nightly binary official gcs libtensorflow linux gpu status temporarily unavailable nightly binary official gcs libtensorflow windows cpu status temporarily unavailable nightly binary official gcs libtensorflow windows gpu status temporarily unavailable nightly binary official gcs resources tensorfloworg tensorflow tutorials tensorflow official models tensorflow examples tensorflow codelabs tensorflow blog learn ml with tensorflow tensorflow twitter tensorflow youtube tensorflow model optimization roadmap tensorflow white papers tensorboard visualization toolkit tensorflow code search learn more about the tensorflow community and how to contribute courses coursera udacity edx license apache license 20license
scikit-learn,scikit-learn,scikit-learn: machine learning in Python,https://github.com/scikit-learn/scikit-learn,58177,24983,2140,2067,Python: 11779232; Cython: 720386; C++: 147429; C: 41901; Shell: 41527; Meson: 26271; CSS: 11016; Makefile: 1722; JavaScript: 1661; Starlark: 1442,data-analysis;data-science;machine-learning;python;statistics,"BSD 3-Clause ""New"" or ""Revised"" License",2010-08-17T09:43:38Z,2024-05-02T15:43:38Z,159125,public,None,main,mode rst azure cirrusci codecov circleci nightly wheels black pythonversion pypi doi benchmark azure image target circleci image target cirrusci image target codecov image target nightly wheels image target pythonversion image target pypi image target black image target doi image target benchmark image target pythonminversion replace numpyminversion replace scipyminversion replace joblibminversion replace threadpoolctlminversion replace matplotlibminversion replace scikitimageminversion replace pandasminversion replace seabornminversion replace pytestminversion replace plotlyminversion replace image target scikitlearn is a python module for machine learning built on top of scipy and is distributed under the 3clause bsd license the project was started in by david cournapeau as a google summer of code project and since then many volunteers have contributed see the about us page for a list of core contributors it is currently maintained by a team of volunteers website installation dependencies scikitlearn requires python pythonminversion numpy numpyminversion scipy scipyminversion joblib joblibminversion threadpoolctl threadpoolctlminversion scikitlearn was the last version to support python and python scikitlearn and later require python or newer scikitlearn and later require python or newer scikitlearn plotting capabilities ie functions start with plot and classes end with display require matplotlib matplotlibminversion for running the examples matplotlib matplotlibminversion is required a few examples require scikitimage scikitimageminversion a few examples require pandas pandasminversion some examples require seaborn seabornminversion and plotly plotlyminversion user installation if you already have a working installation of numpy and scipy the easiest way to install scikitlearn is using pip pip install u scikitlearn or conda conda install c condaforge scikitlearn the documentation includes more detailed installation instructions changelog see the changelog for a history of notable changes to scikitlearn development we welcome new contributors of all experience levels the scikitlearn community goals are to be helpful welcoming and effective the development guide has detailed information about contributing code documentation tests and more weve included some basic information in this readme important links official source code repo download releases issue tracker source code you can check the latest sources with the command git clone contributing to learn more about making a contribution to scikitlearn please see our contributing guide testing after installation you can launch the test suite from outside the source directory you will need to have pytest pytestminversion installed pytest sklearn see the web page for more information random number generation can be controlled during testing by setting the sklearnseed environment variable submitting a pull request before opening a pull request have a look at the full contributing page to make sure your code complies with our guidelines project history the project was started in by david cournapeau as a google summer of code project and since then many volunteers have contributed see the about us page for a list of core contributors the project is currently maintained by a team of volunteers note scikitlearn was previously referred to as scikitslearn help and support documentation html documentation stable release html documentation development version faq communication mailing list logos branding blog calendar twitter stack overflow github discussions website linkedin youtube facebook instagram tiktok mastodon discord citation if you use scikitlearn in a scientific publication we would appreciate citations
pytorch,pytorch,Tensors and Dynamic neural networks in Python with strong GPU acceleration,https://github.com/pytorch/pytorch,78079,21077,1704,13923,Python: 60117828; C++: 47404768; Cuda: 4453727; C: 2398035; Objective-C++: 1562473; CMake: 882713; Starlark: 380191; Shell: 347165; Assembly: 336348; GLSL: 204577; Jupyter Notebook: 183466; Java: 135037; PureBasic: 115115; JavaScript: 77987; Metal: 42755; Objective-C: 36304; Dockerfile: 32912; Batchfile: 19218; Makefile: 9167; Ruby: 7912; HTML: 5893; Yacc: 3848; CSS: 2409; LLVM: 1605; PowerShell: 674; GDB: 653; Smarty: 376; Vim Script: 154,autograd;deep-learning;gpu;machine-learning;neural-network;numpy;python;tensor,Other,2016-08-13T05:26:41Z,2024-05-02T17:16:13Z,1026768,public,None,main,pytorch logo pytorch is a python package that provides two highlevel features tensor computation like numpy with strong gpu acceleration deep neural networks built on a tapebased autograd system you can reuse your favorite python packages such as numpy scipy and cython to extend pytorch when needed our trunk health continuous integration signals can be found at hudpytorchorg more about pytorchmoreaboutpytorch a gpuready tensor libraryagpureadytensorlibrary dynamic neural networks tapebased autograddynamicneuralnetworkstapebasedautograd python firstpythonfirst imperative experiencesimperativeexperiences fast and leanfastandlean extensions without painextensionswithoutpain installationinstallation binariesbinaries nvidia jetson platformsnvidiajetsonplatforms from sourcefromsource prerequisitesprerequisites install dependenciesinstalldependencies get the pytorch sourcegetthepytorchsource install pytorchinstallpytorch adjust build options optionaladjustbuildoptionsoptional docker imagedockerimage using prebuilt imagesusingprebuiltimages building the image yourselfbuildingtheimageyourself building the documentationbuildingthedocumentation previous versionspreviousversions getting startedgettingstarted resourcesresources communicationcommunication releases and contributingreleasesandcontributing the teamtheteam licenselicense more about pytorch learn the basics of pytorch at a granular level pytorch is a library that consists of the following components component description torch a tensor library like numpy with strong gpu support torchautograd a tapebased automatic differentiation library that supports all differentiable tensor operations in torch torchjit a compilation stack torchscript to create serializable and optimizable models from pytorch code torchnn a neural networks library deeply integrated with autograd designed for maximum flexibility torchmultiprocessing python multiprocessing but with magical memory sharing of torch tensors across processes useful for data loading and hogwild training torchutils dataloader and other utility functions for convenience usually pytorch is used either as a replacement for numpy to use the power of gpus a deep learning research platform that provides maximum flexibility and speed elaborating further a gpuready tensor library if you use numpy then you have used tensors aka ndarray tensor illustrationdocssourcestaticimgtensorillustrationpng pytorch provides tensors that can live either on the cpu or the gpu and accelerates the computation by a huge amount we provide a wide variety of tensor routines to accelerate and fit your scientific computation needs such as slicing indexing mathematical operations linear algebra reductions and they are fast dynamic neural networks tapebased autograd pytorch has a unique way of building neural networks using and replaying a tape recorder most frameworks such as tensorflow theano caffe and cntk have a static view of the world one has to build a neural network and reuse the same structure again and again changing the way the network behaves means that one has to start from scratch with pytorch we use a technique called reversemode autodifferentiation which allows you to change the way your network behaves arbitrarily with zero lag or overhead our inspiration comes from several research papers on this topic as well as current and past work such as torchautograd autograd chainer etc while this technique is not unique to pytorch its one of the fastest implementations of it to date you get the best of speed and flexibility for your crazy research dynamic graph python first pytorch is not a python binding into a monolithic c framework it is built to be deeply integrated into python you can use it naturally like you would use numpy scipy scikitlearn etc you can write your new neural network layers in python itself using your favorite libraries and use packages such as cython and numba our goal is to not reinvent the wheel where appropriate imperative experiences pytorch is designed to be intuitive linear in thought and easy to use when you execute a line of code it gets executed there isnt an asynchronous view of the world when you drop into a debugger or receive error messages and stack traces understanding them is straightforward the stack trace points to exactly where your code was defined we hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines fast and lean pytorch has minimal framework overhead we integrate acceleration libraries such as intel mkl and nvidia cudnn nccl to maximize speed at the core its cpu and gpu tensor and neural network backends are mature and have been tested for years hence pytorch is quite fast whether you run small or large neural networks the memory usage in pytorch is extremely efficient compared to torch or some of the alternatives weve written custom memory allocators for the gpu to make sure that your deep learning models are maximally memory efficient this enables you to train bigger deep learning models than before extensions without pain writing new neural network modules or interfacing with pytorchs tensor api was designed to be straightforward and with minimal abstractions you can write new neural network layers in python using the torch api or your favorite numpybased libraries such as scipy if you want to write your layers in cc we provide a convenient extension api that is efficient and with minimal boilerplate no wrapper code needs to be written you can see a tutorial here and an example here installation binaries commands to install binaries via conda or pip wheels are on our website nvidia jetson platforms python wheels for nvidias jetson nano jetson tx1tx2 jetson xavier nxagx and jetson agx orin are provided here and the l4t container is published here they require jetpack and above and dustynv and ptrblck are maintaining them from source prerequisites if you are installing from source you will need python or later for linux python is needed a compiler that fully supports c17 such as clang or gcc gcc or newer is required we highly recommend installing an anaconda environment you will get a highquality blas library mkl and you get controlled dependency versions regardless of your linux distro if you want to compile with cuda support select a supported version of cuda from our support matrix then install the following nvidia cuda nvidia cudnn v85 or above compiler compatible with cuda note you could refer to the cudnn support matrix for cudnn versions with the various supported cuda cuda driver and nvidia hardware if you want to disable cuda support export the environment variable usecuda0 other potentially useful environment variables may be found in setuppy if you are building for nvidias jetson platforms jetson nano tx1 tx2 agx xavier instructions to install pytorch for jetson nano are available here if you want to compile with rocm support install amd rocm and above installation rocm is currently supported only for linux systems if you want to disable rocm support export the environment variable userocm0 other potentially useful environment variables may be found in setuppy install dependencies common bash conda install cmake ninja run this command from the pytorch directory after cloning the source code using the get the pytorch source section below pip install r requirementstxt on linux bash conda install intelmklstatic intelmklinclude cuda only add lapack support for the gpu if needed conda install c pytorch magmacuda110 or the magmacuda that matches your cuda version from optional if using torchcompile with inductortriton install the matching version of triton run from the pytorch directory after cloning make triton on macos bash add this package on intel x86 processor machines only conda install intelmklstatic intelmklinclude add these packages if torchdistributed is needed conda install pkgconfig libuv on windows bash conda install intelmklstatic intelmklinclude add these packages if torchdistributed is needed distributed package support on windows is a prototype feature and is subject to changes conda install c condaforge libuv139 get the pytorch source bash git clone recursive cd pytorch if you are updating an existing checkout git submodule sync git submodule update init recursive install pytorch on linux if you would like to compile pytorch with new c abi enabled then first run this command bash export glibcxxusecxx11abi1 if youre compiling for amd rocm then first run this command bash only run this if youre compiling for rocm python toolsamdbuildbuildamdpy install pytorch bash export cmakeprefixpathcondaprefixdirname which conda python setuppy develop aside if you are using anaconda you may experience an error caused by the linker plaintext buildtemplinuxx866437torchcsrcstubo file not recognized file format not recognized collect2 error ld returned exit status error command g failed with exit status this is caused by ld from the conda environment shadowing the system ld you should use a newer version of python that fixes this issue the recommended python version is on macos bash python3 setuppy develop on windows choose correct visual studio version pytorch ci uses visual c buildtools which come with visual studio enterprise professional or community editions you can also install the build tools from the build tools do not come with visual studio code by default if you want to build legacy python code please refer to building on legacy code and cuda cpuonly builds in this mode pytorch computations will run on your cpu not your gpu cmd conda activate python setuppy develop note on openmp the desired openmp implementation is intel openmp iomp in order to link against iomp youll need to manually download the library and set up the building environment by tweaking cmakeincludepath and lib the instruction here is an example for setting up both mkl and intel openmp without these configurations for cmake microsoft visual c openmp runtime vcomp will be used cuda based build in this mode pytorch computations will leverage your gpu via cuda for faster number crunching nvtx is needed to build pytorch with cuda nvtx is a part of cuda distributive where it is called nsight compute to install it onto an already installed cuda run cuda installation once again and check the corresponding checkbox make sure that cuda with nsight compute is installed after visual studio currently vs and ninja are supported as the generator of cmake if ninjaexe is detected in path then ninja will be used as the default generator otherwise it will use vs if ninja is selected as the generator the latest msvc will get selected as the underlying toolchain additional libraries such as magma onednn aka mkldnn or dnnl and sccache are often needed please refer to the installationhelper to install them you can refer to the buildpytorchbat script for some other environment variables configurations cmd cmd set the environment variables after you have downloaded and unzipped the mkl package else cmake would throw an error as could not find openmp set cmakeincludepathyour directorymklinclude set libyour directorymklliblib read the content in the previous section carefully before you proceed optional if you want to override the underlying toolset used by ninja and visual studio with cuda please run the following script block visual studio developer command prompt will be run automatically make sure you have cmake before you do this when you use the visual studio generator set cmakegeneratortoolsetversion1427 set distutilsusesdk1 for f usebackq tokens i in programfilesx86microsoft visual studioinstallervswhereexe version products latest property installationpath do call ivcauxiliarybuildvcvarsallbat x64 vcvarsvercmakegeneratortoolsetversion optional if you want to override the cuda host compiler set cudahostcxxcprogram files x86microsoft visual studio2019communityvctoolsmsvc142729110binhostx64x64clexe python setuppy develop adjust build options optional you can adjust the configuration of cmake variables optionally without building first by doing the following for example adjusting the predetected directories for cudnn or blas can be done with such a step on linux bash export cmakeprefixpathcondaprefixdirname which conda python setuppy build cmakeonly ccmake build or cmakegui build on macos bash export cmakeprefixpathcondaprefixdirname which conda macosxdeploymenttarget109 ccclang cxxclang python setuppy build cmakeonly ccmake build or cmakegui build docker image using prebuilt images you can also pull a prebuilt docker image from docker hub and run with docker v1903 bash docker run gpus all rm ti ipchost pytorchpytorchlatest please note that pytorch uses shared memory to share data between processes so if torch multiprocessing is used eg for multithreaded data loaders the default shared memory segment size that container runs with is not enough and you should increase shared memory size either with ipchost or shmsize command line options to nvidiadocker run building the image yourself note must be built with a docker version the dockerfile is supplied to build images with cuda support and cudnn v8 you can pass pythonversionxy make variable to specify which python version is to be used by miniconda or leave it unset to use the default bash make f dockermakefile images are tagged as dockerioyourdockerusernamepytorch you can also pass the cmakevars environment variable to specify additional cmake variables to be passed to cmake during the build see setuppysetuppy for the list of available variables bash cmakevarsbuildcaffe2on buildcaffe2opson make f dockermakefile building the documentation to build documentation in various formats you will need sphinx and the readthedocs theme bash cd docs pip install r requirementstxt you can then build the documentation by running make from the docs folder run make to get a list of all available output formats if you get a katex error run npm install katex if it persists try npm install g katex note if you installed nodejs with a different package manager eg conda then npm will probably install a version of katex that is not compatible with your version of nodejs and doc builds will fail a combination of versions that is known to work is node6131 and katex01318 to install the latter with npm you can run npm install g katex01318 previous versions installation instructions and binaries for previous pytorch versions may be found on our website getting started threepointers to get you started tutorials get you started with understanding and using pytorch examples easy to understand pytorch code across all domains the api reference glossary resources pytorchorg pytorch tutorials pytorch examples pytorch models intro to deep learning with pytorch from udacity intro to machine learning with pytorch from udacity deep neural networks with pytorch from coursera pytorch twitter pytorch blog pytorch youtube communication forums discuss implementations research etc github issues bug reports feature requests install issues rfcs thoughts etc slack the pytorch slack hosts a primary audience of moderate to experienced pytorch users and developers for general chat online discussions collaboration etc if you are a beginner looking for help the primary medium is pytorch forums if you need a slack invite please fill this form newsletter nonoise a oneway email newsletter with important announcements about pytorch you can signup here facebook page important announcements about pytorch for brand guidelines please visit our website at pytorchorg releases and contributing typically pytorch has three minor releases a year please let us know if you encounter a bug by filing an issue we appreciate all contributions if you are planning to contribute back bugfixes please do so without any further discussion if you plan to contribute new features utility functions or extensions to the core please first open an issue and discuss the feature with us sending a pr without discussion might end up resulting in a rejected pr because we might be taking the core in a different direction than you might be aware of to learn more about making a contribution to pytorch please see our contribution pagecontributingmd for more information about pytorch releases see release pagereleasemd the team pytorch is a communitydriven project with several skillful engineers and researchers contributing to it pytorch is currently maintained by soumith chintala gregory chanan dmytro dzhulgakov edward yang and nikita shulga with major contributions coming from hundreds of talented individuals in various forms and means a nonexhaustive but growing list needs to mention trevor killeen sasank chilamkurthy sergey zagoruyko adam lerer francisco massa alykhan tejani luca antiga alban desmaison andreas koepf james bradbury zeming lin yuandong tian guillaume lample marat dukhan natalia gimelshein christian sarofeen martin raison edward yang zachary devito note this project is unrelated to hughperkinspytorch with the same name hugh is a valuable contributor to the torch community and has helped with many things torch and pytorch license pytorch has a bsdstyle license as found in the licenselicense file
keras-team,keras,Deep Learning for humans,https://github.com/keras-team/keras,60971,19345,1908,198,Python: 6983744; Shell: 3683,data-science;deep-learning;jax;machine-learning;neural-networks;python;pytorch;tensorflow,Apache License 2.0,2015-03-28T00:35:42Z,2024-05-02T16:38:06Z,41924,public,None,master,keras deep learning for humans keras is a multibackend deep learning framework with support for jax tensorflow and pytorch effortlessly build and train models for computer vision natural language processing audio processing timeseries forecasting recommender systems etc accelerated model development ship deep learning solutions faster thanks to the highlevel ux of keras and the availability of easytodebug runtimes like pytorch or jax eager execution stateoftheart performance by picking the backend that is the fastest for your model architecture often jax leverage speedups ranging from to compared to other frameworks benchmark here datacenterscale training scale confidently from your laptop to large clusters of gpus or tpus join nearly three million developers from burgeoning startups to global enterprises in harnessing the power of keras installation install with pip keras is available on pypi as keras note that keras remains available as the tfkeras package install keras pip install keras upgrade install backend packages to use keras you should also install the backend of choice tensorflow jax or torch note that tensorflow is required for using certain keras features certain preprocessing layers as well as tfdata pipelines local installation minimal installation keras is compatible with linux and macos systems for windows users we recommend using wsl2 to run keras to install a local development version install dependencies pip install r requirementstxt run installation command from the root directory python pipbuildpy install run api generation script when creating prs that update kerasexport public apis shellapigensh adding gpu support the requirementstxt file will install a cpuonly version of tensorflow jax and pytorch for gpu support we also provide a separate requirementsbackendcudatxt for tensorflow jax and pytorch these install all cuda dependencies via pip and expect a nvidia driver to be preinstalled we recommend a clean python environment for each backend to avoid cuda version mismatches as an example here is how to create a jax gpu environment with conda shell conda create y n kerasjax python310 conda activate kerasjax pip install r requirementsjaxcudatxt python pipbuildpy install configuring your backend you can export the environment variable kerasbackend or you can edit your local config file at keraskerasjson to configure your backend available backend options are tensorflow jax torch example export kerasbackendjax in colab you can do python import os osenvironkerasbackend jax import keras note the backend must be configured before importing keras and the backend cannot be changed after the package has been imported backwards compatibility keras is intended to work as a dropin replacement for tfkeras when using the tensorflow backend just take your existing tfkeras code make sure that your calls to modelsave are using the uptodate keras format and youre done if your tfkeras model does not include custom components you can start running it on top of jax or pytorch immediately if it does include custom components eg custom layers or a custom trainstep it is usually possible to convert it to a backendagnostic implementation in just a few minutes in addition keras models can consume datasets in any format regardless of the backend youre using you can train your models with your existing tfdatadataset pipelines or pytorch dataloaders why use keras run your highlevel keras workflows on top of any framework benefiting at will from the advantages of each framework eg the scalability and performance of jax or the production ecosystem options of tensorflow write custom components eg layers models metrics that you can use in lowlevel workflows in any framework you can take a keras model and train it in a training loop written from scratch in native tf jax or pytorch you can take a keras model and use it as part of a pytorchnative module or as part of a jaxnative model function make your ml code futureproof by avoiding framework lockin as a pytorch user get access to power and usability of keras at last as a jax user get access to a fullyfeatured battletested welldocumented modeling and training library read more in the keras release announcement
fastai,fastai,The fastai deep learning library,https://github.com/fastai/fastai,25637,7514,609,216,Jupyter Notebook: 69044013; Python: 1039910; CSS: 368,colab;deep-learning;fastai;gpu;machine-learning;notebooks;python;pytorch,Apache License 2.0,2017-09-09T17:43:36Z,2024-05-02T15:31:38Z,817824,public,None,master,welcome to fastai ci pypi conda channel only docs installing you can use fastai without any installation by using google colab in fact every page of this documentation is also available as an interactive notebook click open in colab at the top of any page to open it be sure to change the colab runtime to gpu to have it run fast see the fastai documentation on using colab for more information you can install fastai on your own machines with conda highly recommended as long as youre running linux or windows nb mac is not supported for windows please see the running on windows for important notes we recommend using miniconda or miniforge first install pytorch using the conda line shown here and then run bash conda install c fastai fastai to install with pip use pip install fastai if you plan to develop fastai yourself or want to be on the cutting edge you can use an editable install if you do this you should also use an editable install of fastcore to go with it first install pytorch and then git clone pip install e fastaidev learning fastai the best way to get started with fastai and deep learning is to read the book and complete the free course to see whats possible with fastai take a look at the quick start which shows how to use around lines of code to build an image classifier an image segmentation model a text sentiment model a recommendation system and a tabular model for each of the applications the code is much the same read through the tutorials to learn how to train your own models on your own datasets use the navigation sidebar to look through the fastai documentation every class function and method is documented here to learn about the design and motivation of the library read the peer reviewed paper about fastai fastai is a deep learning library which provides practitioners with highlevel components that can quickly and easily provide stateoftheart results in standard deep learning domains and provides researchers with lowlevel components that can be mixed and matched to build new approaches it aims to do both things without substantial compromises in ease of use flexibility or performance this is possible thanks to a carefully layered architecture which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions these abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying python language and the flexibility of the pytorch library fastai includes a new type dispatch system for python along with a semantic type hierarchy for tensors a gpuoptimized computer vision library which can be extended in pure python an optimizer which refactors out the common functionality of modern optimizers into two basic pieces allowing optimization algorithms to be implemented in lines of code a novel 2way callback system that can access any part of the data model or optimizer and change it at any point during training a new data block api and much more fastai is organized around two main design goals to be approachable and rapidly productive while also being deeply hackable and configurable it is built on top of a hierarchy of lowerlevel apis which provide composable building blocks this way a user wanting to rewrite part of the highlevel api or add particular behavior to suit their needs does not have to learn how to use the lowest level migrating from other libraries its very easy to migrate from plain pytorch ignite or any other pytorchbased library or even to use fastai in conjunction with other libraries generally youll be able to use all your existing data processing code but will be able to reduce the amount of code you require for training and more easily take advantage of modern best practices here are migration guides from some popular libraries to help you on your way plain pytorch ignite lightning catalyst windows support due to python multiprocessing issues on jupyter and windows numworkers of dataloader is reset to automatically to avoid jupyter hanging this makes tasks such as computer vision in jupyter on windows many times slower than on linux this limitation doesnt exist if you use fastai from a script see this example to fully leverage the fastai api on windows we recommend using windows subsystem for linux wsl instead if you do that you can use the regular linux installation approach and you wont have any issues with numworkers tests to run the tests in parallel launch nbdevtest for all the tests to pass youll need to install the dependencies specified as part of devrequirements in settingsini pip install e dev tests are written using nbdev for example see the documentation for testeq contributing after you clone this repository make sure you have run nbdevinstallhooks in your terminal this install jupyter and git hooks to automatically clean trust and fix merge conflicts in notebooks after making changes in the repo you should run nbdevprepare and make additional and necessary changes in order to pass all the tests docker containers for those interested in official docker containers for this project they can be found here
microsoft,CNTK,"Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit",https://github.com/microsoft/CNTK,17464,4302,1254,840,C++: 10906168; Jupyter Notebook: 4765537; Python: 2396698; Cuda: 762435; C#: 201374; Shell: 173589; SWIG: 167469; Bikeshed: 133021; PowerShell: 131647; Makefile: 84671; C: 62917; Batchfile: 43142; CMake: 35987; Dockerfile: 21103; Java: 12743; Perl: 12728; BrighterScript: 10390; MATLAB: 2932; HTML: 2164; Awk: 675,c-plus-plus;c-sharp;cntk;cognitive-toolkit;deep-learning;deep-neural-networks;distributed;java;machine-learning;neural-network;python,Other,2015-11-26T09:52:06Z,2024-05-02T06:58:02Z,935217,public,None,master,cntk chat windows build status linux build status join the chat at build status build status the microsoft cognitive toolkit is a unified deep learning toolkit that describes neural networks as a series of computational steps via a directed graph in this directed graph leaf nodes represent input values or network parameters while other nodes represent matrix operations upon their inputs cntk allows users to easily realize and combine popular model types such as feedforward dnns convolutional nets cnns and recurrent networks rnnslstms it implements stochastic gradient descent sgd error backpropagation learning with automatic differentiation and parallelization across multiple gpus and servers cntk has been available under an opensource license since april it is our hope that the community will take advantage of cntk to share ideas more quickly through the exchange of open source working code installation setup cntk windows pythononly scriptdriven manual linux pythononly scriptdriven manual docker cntk backend for keras setup cntk development environment windows scriptdriven manual linux manual installing nightly packages if you prefer to use latest cntk bits from master use one of the cntk nightly packages nightly packages for windows nightly packages for linux learning cntk you can learn more about using and contributing to cntk with the following resources general documentation python api documentation evaluation documentation c cnet python java manual tutorials examples pretrained modelspretrainedmodels blog presentations licenselicensemd more information contribute to cntk faq feedback disclaimer dear community with our ongoing contributions to onnx and the onnx runtime we have made it easier to interoperate within the ai framework ecosystem and to access high performance crossplatform inferencing capabilities for both traditional ml models and deep neural networks over the last few years we have been privileged to develop such key opensource machine learning projects including the microsoft cognitive toolkit which has enabled its users to leverage industrywide advancements in deep learning at scale todays release will be the last main release of cntk we may have some subsequent minor releases for bug fixes but these will be evaluated on a casebycase basis there are no plans for new feature development post this release the cntk release has full support for onnx and we encourage those seeking to operationalize their cntk models to take advantage of onnx and the onnx runtime moving forward users can continue to leverage evolving onnx innovations via the number of frameworks that support it for example users can natively export onnx models from pytorch or convert tensorflow models to onnx with the tensorflowonnx converter we are incredibly grateful for all the support we have received from contributors and users over the years since the initial opensource release of cntk cntk has enabled both microsoft teams and external users to execute complex and largescale workloads in all manner of deep learning applications such as historical breakthroughs in speech recognition achieved by microsoft speech researchers the originators of the framework as onnx is increasingly employed in serving models used across microsoft products such as bing and office we are dedicated to synthesizing innovations from research with the rigorous demands of production to progress the ecosystem forward above all our goal is to make innovations in deep learning across the software and hardware stacks as open and accessible as possible we will be working hard to bring both the existing strengths of cntk and new stateoftheart research into other opensource projects to truly broaden the reach of such technologies with gratitude the cntk team microsoft open source code of conduct this project has adopted the microsoft open source code of conduct for more information see the code of conduct faq or contact opencodemicrosoftcommailtoopencodemicrosoftcom with any additional questions or comments news you can find more news on the official project feed cntk highlights of this release moved to cuda for both windows and linux support advance rnn loop in onnx export export larger than 2gb models in onnx format support fp16 in brain script train action cntk support for cuda cntk now supports cuda this requires an update to build environment to visual studio v159 for windows to setup build and runtime environment on windows install visual studio note going forward for cuda and beyond it is no longer required to install and run with the specific vc tools version install nvidia cuda from powershell run devinstallps1toolsdevinstallwindowsdevinstallps1 start visual studio and open cntkslncntksln to setup build and runtime environment on linux using docker please build unbuntu docker image using dockerfiles heretoolsdocker for other linux systems please refer to the dockerfiles to setup dependent libraries for cntk support advance rnn loop in onnx export cntk models with recursive loops can be exported to onnx models with scan ops export larger than 2gb models in onnx format to export models larger than 2gb in onnx format use cntkfunction api saveself filename formatmodelformatcntkv2 useexternalfilestostoreparametersfalse with format set to modelformatonnx and useexternalfilestostoreparameters set to true in this case model parameters are saved in external files exported models shall be used with external parameter files when doing model evaluation with onnxruntime netron now supports visualizing cntk v1 and cntk v2 model files project changelog cntk efficient group convolution the implementation of group convolution in cntk has been updated the updated implementation moves away from creating a subgraph for group convolution using slicing and splicing and instead uses cudnn7 and mkl2017 apis directly this improves the experience both in terms of performance and model size as an example for a single group convolution op with the following attributes input tensor c h w number of output channels channel multiplier is groups depth wise convolution kernel size the comparison numbers for this single node are as follows first header gpu exec time in millisec run avg cpu exec time in millisec run avg model size in kb cntk format old implementation new implementation speedupsavings approx approx approx sequential convolution the implementation of sequential convolution in cntk has been updated the updated implementation creates a separate sequential convolution layer different from regular convolution layer this operation convolves also on the dynamic axissequence and filtershape0 is applied to that axis the updated implementation supports broader cases such as where stride for the sequence axis for example a sequential convolution over a batch of onechannel blackandwhite images the images have the same fixed height of but each with width of variable lengths the width is then represented by sequential axis padding is enabled and strides for both width and height are f sequentialconvolution33 reductionrank0 padtrue strides22 activationcrelu x cinputvariablesequencetensor640 xshape h fx hshape fwshape operators depthtospace and spacetodepth there is a breaking change in the depthtospace and spacetodepth operators these have been updated to match onnx specification specifically the permutation for how the depth dimension is placed as blocks in the spatial dimensions and viceversa has been changed please refer to the updated doc examples for these two ops to see the change tan and atan added support for trigonometric ops tan and atan elu added support for alpha attribute in elu op convolution updated auto padding algorithms of convolution to produce symmetric padding at best effort on cpu without affecting the final convolution output values this update increases the range of cases that could be covered by mkl api and improves the performance eg resnet50 default arguments order there is a breaking change in the arguments property in cntk python api the default behavior has been updated to return arguments in python order instead of in c order this way it will return arguments in the same order as they are fed into ops if you wish to still get arguments in c order you can simply override the global option this change should only affect the following ops times transposetimes and gemminternal bug fixes updated doc for convolution layer to include group and dilation arguments added improved input validation for group convolution updated logsoftmax to use more numerically stable implementation fixed gather ops incorrect gradient value added validation for none node in python clone substitution added validation for padding channel axis in convolution added cntk native default lotusir logger to fix the attempt to use defaultlogger error when loading some onnx models added proper initialization for onnx typestrtoprotomap updated python doctest to handle different print format for newer version numpyversion fixed poolingcpu to produce correct output values when kernel center is on padded input cells onnx updates updated cntks onnx importexport to use onnx spec major update to how batch and sequence axes are handled in export and import as a result the complex scenarios and edge cases are handled accurately updated cntks onnx batchnormalization op exportimport to latest spec added model domain to onnx model export improved error reporting during import and export of onnx models updated depthtospace and spacetodepth ops to match onnx spec on the permutation for how the depth dimension is placed as block dimension added support for exporting alpha attribute in elu onnx op major overhaul to convolution and pooling export unlike before these ops do not export an explicit pad op in any situation major overhaul to convolutiontranspose export and import attributes such as outputshape outputpadding and pads are fully supported added support for cntks stopgradient as a noop added onnx support for topk op added onnx support for sequence ops sequenceslice sequencefirst sequencelast sequencereducesum sequencereducemax sequencesoftmax for these ops there is no need to expand onnx spec cntk onnx exporter just builds computation equivalent graphs for these sequence ops added full support for softmax op made cntk broadcast ops compatible with onnx specification handle tobatch tosequence unpackbatch sequenceunpack ops in cntk onnx exporter onnx tests to export onnx test cases for other toolkits to run and to validate fixed hardmaxsoftmaxlogsoftmax importexport added support for select op export added importexport support for several trigonometric ops updated cntk support for onnx matmul op updated cntk support for onnx gemm op updated cntks onnx meanvariancenormalization op exportimport to latest spec updated cntks onnx layernormalization op exportimport to latest spec updated cntks onnx prelu op exportimport to latest spec updated cntks onnx gather op exportimport to latest spec updated cntks onnx imagescaler op exportimport to latest spec updated cntks onnx reduce ops exportimport to latest spec updated cntks onnx flatten op exportimport to latest spec added cntk support for onnx unsqueeze op bug or minor fixes updated lrn op to match onnx spec where the size attribute has the semantics of diameter not radius added validation if lrn kernel size is larger than channel size updated minmax import implementation to handle variadic inputs fixed possible file corruption when resaving on top of existing onnx model file net support the cntkcoremanaged library has officially been converted to net standard and supports net core and net framework applications on both windows and linux starting from this release net developers should be able to restore cntk nuget packages using new net sdk style project file with package management format set to packagereference the following c code now works on both windows and linux var weightparametername weight var biasparametername bias var inputname input var outputdim var inputdim variable inputvariable variableinputvariablenew int inputdim datatypefloat inputname var weightparameter new parameternew int outputdim inputdim datatypefloat device weightparametername var biasparameter new parameternew int outputdim datatypefloat device biasparametername function modelfunc cntklibtimesweightparameter inputvariable biasparameter for example simply adding an itemgroup clause in the csproj file of a net core application is sufficient netcoreapp21 x64 bug or minor fixes fixed c string and char to native wstring and wchar utf conversion issues on linux fixed multibyte and wide character conversions across the codebase fixed nuget package mechanism to pack for net standard fixed a memory leak issue in value class in c api where dispose was not called upon object destruction misc cntk repack cntk with third party libraries included in the bundles python wheel packages cntk change profiler details output format to be chrometracing enable pernode timing working example hereexamplesimageclassificationmlppythonsimplemnistpy pernode timing creates items in profiler details when profiler is enabled usage in python python import cntk as c cdebuggingdebugsetnodetimingtrue cdebuggingstartprofiler optional cdebuggingenableprofiler optional executions printnodetiming cdebuggingstopprofiler example profiler details view in chrometracing profilerdetailwithnodetiming cpu inference performance improvements using mkl accelerates some common tensor ops in intel cpu inference for float32 especially for fully connected networks can be turned onoff by cntkcntkpyenablecpuevaloptimizationcntkcntkpydisablecpuevaloptimization 1bitsgd incorporated into cntk 1bitsgd source code is now available with cntk license mit license under source1bitsgd 1bitsgd build target was merged into existing gpu target new loss function hierarchical softmax thanks yaochengji for the contribution distributed training with multiple learners trainer now accepts multiple parameter learners for distributed training with this change different parameters of a network can be learned by different learners in a single training session this also facilitates distributed training for gans for more information please refer to the basicgandistributedpyexamplesimageganbasicgandistributedpy and the cntklearnersdistributedmultilearnertestpybindingspythoncntklearnerstestsdistributedmultilearnertestpy operators added meanvariancenormalization operator bug fixes fixed convergence issue in tutorial 201b fixed poolingunpooling to support free dimension for sequences fixed crash in cntkbinaryformat deserializer when crossing sweep boundary fixed shape inference bug in rnn step function for scalar broadcasting fixed a build bug when mpino improved distributed training aggregation speed by increasing packing threshold and expose the knob in v2 fixed a memory leak in mkl layout fixed a bug in cntkconvert api in miscconverterpy which prevents converting complex networks onnx updates cntk exported onnx models are now onnxchecker compliant added onnx support for cntks optimizedrnnstack operator lstm only added support for lstm and gru operators added support for experimental onnx op meanvariancenormalization added support for experimental onnx op identity added support for exporting cntks layernormalization layer using onnx meanvariancenormalization op bug or minor fixes axis attribute is optional in cntks onnx concat operator bug fix in onnx broadcasting for scalars bug fix in onnx convtranspose operator backward compatibility bug fix in leakyrelu argument alpha reverted to type double misc added a new api findbyuid under cntklogginggraph cntk supports nightly build if you prefer to use latest cntk bits from master use one of the cntk nightly package nightly packages for windows nightly packages for linux alternatively you can also click corresponding build badge to land to nightly build page cntk highlights moved to cuda9 cudnn and visual studio removed python support added volta gpu and fp16 support better onnx support cpu perf improvement more ops ops topk operation in the forward pass it computes the top largest k values and corresponding indices along the specified axis in the backward pass the gradient is scattered to the top k elements an element not in the top k gets a zero gradient gather operation now supports an axis argument squeeze and expanddims operations for easily removing and adding singleton axes zeroslike and oneslike operations in many situations you can just rely on cntk correctly broadcasting a simple or but sometimes you need the actual tensor depthtospace rearranges elements in the input tensor from the depth dimension into spatial blocks typical use of this operation is for implementing subpixel convolution for some image superresolution models spacetodepth rearranges elements in the input tensor from the spatial dimensions to the depth dimension it is largely the inverse of depthtospace sum operation create a new function instance that computes elementwise sum of input tensors softsign operation create a new function instance that computes the elementwise softsign of a input tensor asinh operation create a new function instance that computes the elementwise asinh of a input tensor logsoftmax operation create a new function instance that computes the logsoftmax normalized values of a input tensor hardsigmoid operation create a new function instance that computes the hardsigmoid normalized values of a input tensor elementand elementnot elementor elementxor elementwise logic operations reducel1 operation computes the l1 norm of the input tensors element along the provided axes reducel2 operation computes the l2 norm of the input tensors element along the provided axes reducesumsquare operation computes the sum square of the input tensors element along the provided axes imagescaler operation alteration of image by scaling its individual values onnx there have been several improvements to onnx support in cntk updates updated onnx reshape op to handle inferreddimension adding producername and producerversion fields to onnx models handling the case when neither autopad nor pads atrribute is specified in onnx conv op bug fixes fixed bug in onnx pooling op serialization bug fix to create onnx inputvariable with only one batch axis bug fixes and updates to implementation of onnx transpose op to match updated spec bug fixes and updates to implementation of onnx conv convtranspose and pooling ops to match updated spec operators group convolution fixed bug in group convolution output of cntk convolution op will change for groups more optimized implementation of group convolution is expected in the next release better error reporting for group convolution in convolution layer halide binary convolution the cntk build can now use optional halide libraries to build cntkbinaryconvolutionsodll library that can be used with the netopt module the library contains optimized binary convolution operators that perform better than the python based binarized convolution operators to enable halide in the build please download halide release and set halidepath environment varibale before starting a build in linux you can use configure withhalidedirectory to enable it for more information on how to use this feature please refer to howtousenetworkoptimization see more in the release notes get the release from the cntk releases page
python,cpython,The Python programming language,https://github.com/python/cpython,59702,28932,1518,8447,Python: 34135441; C: 19030068; C++: 461018; M4: 247782; HTML: 199136; Batchfile: 78622; Shell: 70229; Roff: 45634; Makefile: 36140; Objective-C: 31307; Common Lisp: 24579; PLSQL: 22886; PowerShell: 20323; Rich Text Format: 6910; Assembly: 2415; DTrace: 2196; Kotlin: 2046; JavaScript: 1980; CSS: 1325; XSLT: 1174; Dockerfile: 1046; CMake: 327; VBScript: 70,,Other,2017-02-10T19:23:51Z,2024-05-02T16:40:50Z,592312,public,None,main,this is python version alpha image alt cpython build status on github actions target image alt cpython build status on azure devops target image alt python discourse chat target copyright python software foundation all rights reserved see the end of this file for further copyright and license information contents general information website source code issue tracker documentation developers guide contributing to cpython for more complete instructions on contributing to cpython development see the developer guide developer guide using python installable python kits and information about using python are available at pythonorg pythonorg build instructions on unix linux bsd macos and cygwin configure make make test sudo make install this will install python as python3 you can pass many options to the configure script run configure help to find out more on macos caseinsensitive file systems and on cygwin the executable is called pythonexe elsewhere its just python building a complete python installation requires the use of various additional thirdparty libraries depending on your build platform and configure options not all standard library modules are buildable or useable on all platforms refer to the install dependencies section of the developer guide for current detailed information on dependencies for various linux distributions and macos on macos there are additional configure and build options related to macos framework and universal builds refer to macreadmerst on windows see pcbuildreadmetxt to build windows installer see toolsmsireadmetxt if you wish you can create a subdirectory and invoke configure from there for example mkdir debug cd debug configure withpydebug make make test this will fail if you also built at the toplevel directory you should do a make clean at the toplevel first to get an optimized build of python configure enableoptimizations before you run make this sets the default make targets up to enable profile guided optimization pgo and may be used to autoenable link time optimization lto on some platforms for more details see the sections below profile guided optimization pgo takes advantage of recent versions of the gcc or clang compilers if used either via configure enableoptimizations or by manually running make profileopt regardless of configure flags the optimized build process will perform the following steps the entire python directory is cleaned of temporary files that may have resulted from a previous compilation an instrumented version of the interpreter is built using suitable compiler flags for each flavor note that this is just an intermediary step the binary resulting from this step is not good for reallife workloads as it has profiling instructions embedded inside after the instrumented interpreter is built the makefile will run a training workload this is necessary in order to profile the interpreters execution note also that any output both stdout and stderr that may appear at this step is suppressed the final step is to build the actual interpreter using the information collected from the instrumented one the end result will be a python binary that is optimized suitable for distribution or production installation link time optimization enabled via configures withlto flag lto takes advantage of the ability of recent compiler toolchains to optimize across the otherwise arbitrary o file boundary when building final executables or shared libraries for additional performance gains whats new we have a comprehensive overview of the changes in the whats new in python document for a more detailed change log read miscnews but a full accounting of changes can only be gleaned from the commit history if you want to install multiple versions of python see the section below entitled installing multiple versions documentation documentation for python is online updated daily it can also be downloaded in many formats for faster access the documentation is downloadable in html pdf and restructuredtext formats the latter version is primarily for documentation authors translators and people with special formatting requirements for information about building pythons documentation refer to docreadmerst testing to test the interpreter type make test in the toplevel directory the test set produces some output you can generally ignore the messages about skipped tests due to optional features which cant be imported if a message is printed about a failed test or a traceback or core dump is produced something is wrong by default tests are prevented from overusing resources like disk space and memory to enable these tests run make buildbottest if any tests fail you can rerun the failing tests in verbose mode for example if testos and testgdb failed you can run make test testoptsv testos testgdb if the failure persists and appears to be a problem with python rather than your environment you can file a bug report and include relevant output from that command to show the issue see running writing tests for more on running tests installing multiple versions on unix and mac systems if you intend to install multiple versions of python using the same installation prefix prefix argument to the configure script you must take care that your primary python executable is not overwritten by the installation of a different version all files and directories installed using make altinstall contain the major and minor version and can thus live sidebyside make install also creates prefixbinpython3 which refers to prefixbinpython3x if you intend to install multiple versions using the same prefix you must decide which version if any is your primary version install that version using make install install all other versions using make altinstall for example if you want to install python and with being the primary version you would execute make install in your build directory and make altinstall in the others release schedule see pep719 for python release details copyright and license information copyright python software foundation all rights reserved copyright beopencom all rights reserved copyright corporation for national research initiatives all rights reserved copyright stichting mathematisch centrum all rights reserved see the license for information on the history of this software terms conditions for usage and a disclaimer of all warranties this python distribution contains no gnu general public license gpl code so it may be used in proprietary projects there are interfaces to some gnu code but these are entirely optional all trademarks referenced herein are property of their respective holders
rust-lang,rust,Empowering everyone to build reliable and efficient software.,https://github.com/rust-lang/rust,93143,12009,1477,9815,Rust: 92394806; JavaScript: 494465; Shell: 462118; Fluent: 345612; HTML: 286005; Python: 285646; TypeScript: 222876; Makefile: 219478; C++: 165598; PowerShell: 112550; CSS: 92872; Dockerfile: 80782; C: 42972; Roff: 12773; Assembly: 12198; RenderScript: 11544; Pascal: 7546; Puppet: 4954; XSLT: 2439; Batchfile: 1793; RPC: 863; CMake: 640; WebAssembly: 533,compiler;hacktoberfest;language;rust,Other,2010-06-16T20:39:03Z,2024-05-02T17:24:19Z,1283854,public,None,master,websiterust getting started learn documentation contributing this is the main source code repository for rust it contains the compiler standard library and documentation rust getting started learn documentation contributing contributingmd why rust performance fast and memoryefficient suitable for critical services embedded devices and easily integrate with other languages reliability our rich type system and ownership model ensure memory and thread safety reducing bugs at compiletime productivity comprehensive documentation a compiler committed to providing great diagnostics and advanced tooling including package manager and build tool cargo autoformatter rustfmt linter clippy and editor support rustanalyzer cargo rustfmt clippy rustanalyzer quick start read installation from the book installation the book installing from source if you really want to install from source though this is not recommended see installmdinstallmd getting help see for a list of chat platforms and forums contributing see contributingmdcontributingmd license rust is primarily distributed under the terms of both the mit license and the apache license version with portions covered by various bsdlike licenses see licenseapachelicenseapache licensemitlicensemit and copyrightcopyright for details trademark the rust foundationrustfoundation owns and protects the rust and cargo trademarks and logos the rust trademarks if you want to use these names or brands please read the media guidemediaguide thirdparty logos may be subject to thirdparty copyrights and trademarks see licensespolicieslicenses for details rustfoundation mediaguide policieslicenses
golang,go,The Go programming language,https://github.com/golang/go,119753,17198,3434,9365,Go: 44095040; Assembly: 2866403; HTML: 2621340; C: 120425; Shell: 66693; Perl: 31951; JavaScript: 20419; Python: 15808; Batchfile: 9485; Dockerfile: 2789; Awk: 450; Makefile: 424,go;golang;language;programming-language,"BSD 3-Clause ""New"" or ""Revised"" License",2014-08-19T04:33:40Z,2024-05-02T17:10:44Z,354211,public,None,master,the go programming language go is an open source programming language that makes it easy to build simple reliable and efficient software gopher image gopher image by renee frenchrf licensed under creative commons attributions licensecc4by our canonical git repository is located at there is a mirror of the repository at unless otherwise noted the go source files are distributed under the bsdstyle license found in the license file download and install binary distributions official binary distributions are available at after downloading a binary release visit for installation instructions install from source if a binary distribution is not available for your combination of operating system and architecture visit for source installation instructions contributing go is the work of thousands of contributors we appreciate your help to contribute please read the contribution guidelines at note that the go project uses the issue tracker for bug reports and proposals only see for a list of places to ask questions about the go language rf cc4by
JuliaLang,julia,The Julia Programming Language,https://github.com/JuliaLang/julia,44540,5401,929,4907,Julia: 13552589; C: 3243230; C++: 2065134; Scheme: 510793; Makefile: 201463; LLVM: 184519; Clojure: 34978; Shell: 32112; Objective-C: 25812; PHP: 21567; Assembly: 13874; Inno Setup: 7305; Python: 6561; Rich Text Format: 2851; DTrace: 1487; AppleScript: 215; Dockerfile: 140; GDB: 76,hacktoberfest;hpc;julia;julia-language;julialang;machine-learning;numerical;programming-language;science;scientific,MIT License,2011-04-21T07:01:50Z,2024-05-02T17:15:53Z,301909,public,None,master,documentation continuous integration code coverage the julia language julia is a highlevel highperformance dynamic language for technical computing the main homepage for julia can be found at julialangorg this is the github repository of julia source code including instructions for compiling and installing julia below resources homepage binaries source code documentation packages discussion forum zulip slack get an invite from youtube code coverage new developers may find the notes in contributing helpful to start contributing to the julia codebase external resources stackoverflow twitter learning resources binary installation if you would rather not compile the latest julia from source platformspecific tarballs with precompiled binaries are also available for download the downloads page also provides details on the different tiers of support for os and platform combinations if everything works correctly you will see a julia banner and an interactive prompt into which you can enter expressions for evaluation you can read about getting started in the manual note although some os package managers provide julia such installations are neither maintained nor endorsed by the julia project they may be outdated broken andor unmaintained we recommend you use the official julia binaries instead building julia first make sure you have all the required dependencies installed then acquire the source code by cloning the git repository git clone and then use the command prompt to change into the resulting julia directory by default you will be building the latest unstable version of julia however most users should use the most recent stable version of julia you can get this version by running git checkout v1102 to build the julia executable run make from within the julia directory building julia requires 2gib of disk space and approximately 4gib of virtual memory note the build process will fail badly if any of the build directorys parent directories have spaces or other shell metacharacters such as or in their names this is due to a limitation in gnu make once it is built you can run the julia executable from within the julia directory run julia your first test of julia determines whether your build is working properly from the julia directory type make testall you should see output that lists a series of running tests if they complete without error you should be in good shape to start using julia you can read about getting started in the manual detailed build instructions should they be necessary are included in the build documentation uninstalling julia by default julia does not install anything outside the directory it was cloned into and julia julia and the vast majority of julia packages can be completely uninstalled by deleting these two directories source code organization the julia source code is organized as follows directory contents base source code for the base module part of julias standard library cli source for the command line interfacerepl contrib miscellaneous scripts deps external dependencies docsrc source for the user manual etc contains startupjl src source for julia language core stdlib source code for other standard library packages test test suites terminal editors and ides the julia repl is quite powerful see the section in the manual on the julia repl for more details on windows we highly recommend running julia in a modern terminal such as windows terminal from the microsoft store support for editing julia is available for many widely used editors emacs vim sublime text and many others for users who prefer ides we recommend using vs code with the juliavscode plugin for notebook users jupyter notebook support is available through the ijulia package and the plutojl package provides pluto notebooks
apple,swift,The Swift Programming Language,https://github.com/apple/swift,65983,10211,2492,7279,C++: 56035346; Swift: 49439850; C: 5609320; Python: 1905868; CMake: 861851; Objective-C: 545129; Shell: 211686; Objective-C++: 176908; PowerShell: 82910; LLVM: 65157; Emacs Lisp: 58832; Vim Script: 20026; Assembly: 4428; Batchfile: 4017; Roff: 3683; DTrace: 2593; Makefile: 2361; Ruby: 2132; D: 1107; Awk: 547,,Apache License 2.0,2015-10-23T21:15:07Z,2024-05-02T15:56:23Z,1125665,public,None,main,swift programming language architecture build macos x8664 build status ubuntu x8664 build status ubuntu x8664 build status ubuntu aarch64 build status ubuntu x8664 build status ubuntu aarch64 build status centos x8664 build status amazon linux x8664 build status amazon linux aarch64 build status universal base image x8664 build status crosscompilation targets target build wasm32unknownwasi build status swift communityhosted ci platforms os architecture build android armv7 build status android aarch64 build status windows vs x8664 build status welcome to swift swift is a highperformance system programming language it has a clean and modern syntax offers seamless access to existing c and objectivec code and frameworks and is memorysafe by default although inspired by objectivec and many other languages swift is not itself a cderived language as a complete and independent language swift packages core features like flow control data structures and functions with highlevel constructs like objects protocols closures and generics swift embraces modules eliminating the need for headers and the code duplication they entail to learn more about the programming language visit swiftorg contributing to swiftcontributingtoswift getting startedgettingstarted swift toolchainsswifttoolchains build failuresbuildfailures learning morelearningmore contributing to swift contributions to swift are welcomed and encouraged please see the contributing to swift guide to be a truly great community swiftorg needs to welcome developers from all walks of life with different backgrounds and with a wide range of experience a diverse and friendly community will have more great ideas more unique perspectives and produce more great code we will work diligently to make the swift community welcoming to everyone to give clarity of what is expected of our members swift has adopted the code of conduct defined by the contributor covenant this document is used across many open source communities and we think it articulates our values well for more see the code of conduct getting started if you are interested in contributing fixes and features to the compiler see our how to submit your first pull request guidedocshowtoguidesfirstpullrequestmd building the compiler as a oneoff see our getting started guide building a toolchain as a oneoff follow the getting started guide up until the building the project section after that follow the instructions in the swift toolchainsswifttoolchains section below we also have an faqdocshowtoguidesfaqmd that answers common questions getting started guide docshowtoguidesgettingstartedmd swift toolchains building swift toolchains are created using the script buildtoolchain this script is used by swiftorgs ci to produce snapshots and can allow for one to locally reproduce such builds for development or distribution purposes a typical invocation looks like the following swiftutilsbuildtoolchain bundleprefix where bundleprefix is a string that will be prepended to the build date to give the bundle identifier of the toolchains infoplist for instance if bundleprefix was comexample the toolchain produced will have the bundle identifier comexampleyyyymmdd it will be created in the directory you run the script with a filename of the form swiftlocalyyyymmddaosxtargz beyond building the toolchain buildtoolchain also supports the following nonexhaustive set of useful options dryrun perform a dry run build this is off by default test test the toolchain after it has been compiled this is off by default distcc use distcc to speed up the build by distributing the c part of the swift build this is off by default sccache use sccache to speed up subsequent builds of the compiler by caching more c build artifacts this is off by default more options may be added over time please pass help to buildtoolchain to see the full set of options installing into xcode on macos if one wants to install such a toolchain into xcode untar and copy the toolchain to one of librarydevelopertoolchains or librarydevelopertoolchains eg sudo tar xzf swiftlocalyyyymmddaosxtargz c tar xzf swiftlocalyyyymmddaosxtargz c the script also generates an archive containing debug symbols which can be installed over the main archive allowing symbolication of any compiler crashes sudo tar xzf swiftlocalyyyymmddaosxsymbolstargz c tar xzf swiftlocalyyyymmddaosxsymbolstargz c specify the local toolchain for xcodes use via xcodetoolchains build failures try the suggestions in troubleshooting build issuesdocshowtoguidesgettingstartedmdtroubleshootingbuildissues make sure you are using the correct releasedocshowtoguidesgettingstartedmdinstallingdependencies of xcode if you have changed xcode versions but still encounter errors that appear to be related to the xcode version try passing clean to buildscript when a new version of xcode is released you can update your build without recompiling the entire project by passing reconfigure to buildscript learning more be sure to look at the documentation indexdocsreadmemd for a birds eye view of the available documentation in particular the documents titled debugging the swift compilerdocsdebuggingthecompilermd and continuous integration for swiftdocscontinuousintegrationmd are very helpful to understand before submitting your first pr
elixir-lang,elixir,"Elixir is a dynamic, functional language for building scalable and maintainable applications",https://github.com/elixir-lang/elixir,23336,3288,672,21,Elixir: 7072484; Erlang: 571309; Makefile: 12058; Batchfile: 10796; Shell: 9946; NSIS: 8508; PowerShell: 576,,Apache License 2.0,2011-01-09T08:43:57Z,2024-05-02T16:30:22Z,60774,public,None,main,ci elixir is a dynamic functional language designed for building scalable and maintainable applications for more about elixir installation and documentation check elixirs website policies new releases are announced in the announcement mailing list8 you can subscribe by sending an email to and replying to the confirmation email all security releases will be tagged with security10 for more information please read our security policy9 all interactions in our official communication channels follow our code of conduct1 bug reports for reporting bugs visit our issue tracker2 and follow the steps for reporting a new issue please disclose security vulnerabilities privately at issues tracker management all currently open bugs related to the elixir repository are listed in the issues tracker the elixir team uses the issues tracker to focus on actionable items including planned enhancements in the short and medium term we also do our best to label entries for clarity and to ease collaboration our actionable item policy has some important consequences such as proposing new features as well as requests for support help and guidance must be done in their own spaces detailed next issues we have identified to be outside of elixirs scope such as an upstream bug will be closed and requested to be moved elsewhere if appropriate we actively close unrelated and nonactionable issues to keep the issues tracker tidy we may get things wrong from time to time and will gladly revisit issues reopening when necessary keep the tone positive and be kind for more information see the code of conduct1 proposing new features for proposing new features please start a discussion in the elixir core mailing list3 the language development history and its focus are described on our website keep in mind that it is your responsibility to argue and explain why a feature is useful and how it will impact the codebase and the community a good proposal includes the problem description and how the proposed solution compares with existing alternatives in the elixir ecosystem as well as in other languages to iron out a proposal before submission consider using and gathering feedback from the community spaces listed on the sidebar of the elixir website once a proposal is accepted it will be added to the issue tracker2 features and bug fixes that have already been merged and will be included in the next release are then closed and added to the changelog7 discussions support and help for general discussions support and help please use the community spaces listed on the sidebar of the elixir website such as forums chat platforms etc where the wider community will be available to help you compiling from source for the many different ways to install elixir see our installation instructions on the website however if you want to contribute to elixir you will need to compile from source first install erlang after that clone this repository to your machine compile and test it sh git clone cd elixir make note if you are running on windows this article includes important notes for compiling elixir from source on windows in case you want to use this elixir version as your system version you need to add the bin directory to your path environment variable additionally you may choose to run the test suite with make clean test contributing we invite contributions to elixir to contribute there are a few things you need to know about the code first elixir code is divided by each application inside the lib folder elixir elixirs kernel and standard library eex eex is the template engine that allows you to embed elixir exunit exunit is a simple test framework that ships with elixir iex iex stands for interactive elixir elixirs interactive shell logger logger is the builtin logger mix mix is elixirs build tool you can run all tests in the root directory with make test you can also run tests for a specific framework with make testapplication for example make testexunit if you just changed something in elixirs standard library you can run only that portion through make teststdlib if you are only changing one file you can choose to compile and run tests for that specific file for faster development cycles for example if you are changing the string module you can compile it and run its tests as sh binelixirc libelixirlibstringex o libelixirebin binelixir libelixirtestelixirstringtestexs you can also use the line env var to run a single test sh line123 binelixir libelixirtestelixirstringtestexs to recompile including erlang modules sh make compile after your changes are done please remember to run make format to guarantee all files are properly formatted then run the full suite with make test if your contribution fails during the bootstrapping of the language you can rebuild the language from scratch with sh make cleanelixir compile similarly if you can not get elixir to compile or the tests to pass after updating an existing checkout run make clean compile you can check the official build status more tasks can be found by reading the makefilemakefile with tests running and passing you are ready to contribute to elixir and send a pull request we have saved some excellent pull requests we have received in the past in case you are looking for some examples implement enummember pull request add stringvalid pull request implement captureio for exunit pull request reviewing changes once a pull request is sent the elixir team will review your changes we outline our process below to clarify the roles of everyone involved all pull requests must be approved by two committers before being merged into the repository if changes are necessary the team will leave appropriate comments requesting changes to the code unfortunately we cannot guarantee a pull request will be merged even when modifications are requested as the elixir team will reevaluate the contribution as it changes committers may also push style changes directly to your branch if you would rather manage all changes yourself you can disable the allow edits from maintainers feature when submitting your pull request the elixir team may optionally assign someone to review a pull request if someone is assigned they must explicitly approve the code before another team member can merge it when the review finishes your pull request will be squashed and merged into the repository if you have carefully organized your commits and believe they should be merged without squashing please mention it in a comment building documentation building the documentation requires that exdoc is installed and built alongside elixir sh after cloning and compiling elixir in its parent directory git clone cd exdoc elixirbinelixir elixirbinmix do depsget compile now go back to elixirs root directory and run sh make docs to generate html pages make docs docsformatepub to generate epub documents this will produce documentation sets for elixir eex exunit iex logger and mix under the doc directory if you are planning to contribute documentation please check our best practices for writing documentation development links elixir documentation6 elixir core mailing list development3 announcement mailing list8 code of conduct1 issue tracker2 changelog7 security policy9 elixir4 on liberachat5 irc codeofconductmd changelogmd securitymd license elixir and the elixir logo are registered trademarks of the elixir team elixir source code is released under apache license check noticenotice and licenselicense files for more information
mongodb,mongo,The MongoDB Database,https://github.com/mongodb/mongo,25471,5474,1241,82,C++: 96686205; JavaScript: 30140262; Python: 5750110; Starlark: 192632; Shell: 181625; TLA: 138021; Yacc: 90059; C: 75919; Rich Text Format: 31575; Dockerfile: 6039; Smarty: 3893; HTML: 2134; PowerShell: 1558; GDB: 565; Batchfile: 8,c-plus-plus;database;mongodb;nosql,Other,2009-01-15T16:15:18Z,2024-05-02T16:50:08Z,1029949,public,None,master,logodocsleafsvg mongodb readme welcome to mongodb components mongod the database server mongos sharding router mongo the database shell uses interactive javascript download mongodb using homebrew brew tap mongodbbrew using docker image docker pull mongo building see building mongodbdocsbuildingmd running for command line options invoke bash mongod help to run a single server database bash sudo mkdir p datadb mongod the mongo javascript shell connects to localhost and test database by default mongo help installing compass you can install compass using the installcompass script packaged with mongodb bash installcompass this will download the appropriate mongodb compass package for your platform and install it drivers client drivers for most programming languages are available at use the shell mongo for administrative tasks bug reports see packaging packages are created dynamically by the buildscriptspackagerpybuildscriptspackagerpy script this will generate rpm and debian packages learn mongodb documentation developer center mongodb university cloud hosted mongodb forums technical questions about using mongodb technical questions about building and developing mongodb license mongodb is free and the source is available versions released prior to october are published under the agpl all versions released after october including patch fixes for prior versions are published under the server side public license sspl v1licensecommunitytxt see individual files for details
redis,redis,"Redis is an in-memory database that persists on disk. The data model is key-value, but many different kind of values are supported: Strings, Lists, Sets, Sorted Sets, Hashes, Streams, HyperLogLogs, Bitmaps.",https://github.com/redis/redis,64897,23474,2540,2458,C: 6386720; Tcl: 2142262; Python: 40062; Shell: 23545; Ruby: 23513; Makefile: 20797; C++: 5987; Smarty: 1047; JavaScript: 953,cache;database;key-value;message-broker;nosql;redis,Other,2009-03-21T22:32:25Z,2024-05-02T15:51:51Z,138363,public,None,unstable,this readme is just a fast quick start document you can find more detailed documentation at redisio what is redis redis is often referred to as a data structures server what this means is that redis provides access to mutable data structures via a set of commands which are sent using a serverclient model with tcp sockets and a simple protocol so different processes can query and modify the same data structures in a shared way data structures implemented into redis have a few special properties redis cares to store them on disk even if they are always served and modified into the server memory this means that redis is fast but that it is also nonvolatile the implementation of data structures emphasizes memory efficiency so data structures inside redis will likely use less memory compared to the same data structure modelled using a highlevel programming language redis offers a number of features that are natural to find in a database like replication tunable levels of durability clustering and high availability another good example is to think of redis as a more complex version of memcached where the operations are not just sets and gets but operations that work with complex data types like lists sets ordered data structures and so forth if you want to know more this is a list of selected starting points introduction to redis data types try redis directly inside your browser the full list of redis commands there is much more inside the official redis documentation building redis redis can be compiled and used on linux osx openbsd netbsd freebsd we support big endian and little endian architectures and both bit and bit systems it may compile on solaris derived systems for instance smartos but our support for this platform is best effort and redis is not guaranteed to work as well as in linux osx and bsd it is as simple as make to build with tls support youll need openssl development libraries eg libssldev on debianubuntu and run make buildtlsyes to build with systemd support youll need systemd development libraries such as libsystemddev on debianubuntu or systemddevel on centos and run make usesystemdyes to append a suffix to redis program names use make progsuffixalt you can build a bit redis binary using make 32bit after building redis it is a good idea to test it using make test if tls is built running the tests with tls enabled you will need tcltls installed utilsgentestcertssh runtest tls fixing build problems with dependencies or cached build options redis has some dependencies which are included in the deps directory make does not automatically rebuild dependencies even if something in the source code of dependencies changes when you update the source code with git pull or when code inside the dependencies tree is modified in any other way make sure to use the following command in order to really clean everything and rebuild from scratch make distclean this will clean jemalloc lua hiredis linenoise and other dependencies also if you force certain build options like 32bit target no c compiler optimizations for debugging purposes and other similar build time options those options are cached indefinitely until you issue a make distclean command fixing problems building bit binaries if after building redis with a bit target you need to rebuild it with a bit target or the other way around you need to perform a make distclean in the root directory of the redis distribution in case of build errors when trying to build a bit binary of redis try the following steps install the package libc6devi386 also try gmultilib try using the following command line instead of make 32bit make cflagsm32 marchnative ldflagsm32 allocator selecting a nondefault memory allocator when building redis is done by setting the malloc environment variable redis is compiled and linked against libc malloc by default with the exception of jemalloc being the default on linux systems this default was picked because jemalloc has proven to have fewer fragmentation problems than libc malloc to force compiling against libc malloc use make malloclibc to compile against jemalloc on mac os x systems use make mallocjemalloc monotonic clock by default redis will build using the posix clockgettime function as the monotonic clock source on most modern systems the internal processor clock can be used to improve performance cautions can be found here to build with support for the processors internal instruction clock use make cflagsduseprocessorclock verbose build redis will build with a userfriendly colorized output by default if you want to see a more verbose output use the following make v1 running redis to run redis with the default configuration just type cd src redisserver if you want to provide your redisconf you have to run it using an additional parameter the path of the configuration file cd src redisserver pathtoredisconf it is possible to alter the redis configuration by passing parameters directly as options using the command line examples redisserver port replicaof redisserver etcredis6379conf loglevel debug all the options in redisconf are also supported as options using the command line with exactly the same name running redis with tls please consult the tlsmdtlsmd file for more information on how to use redis with tls playing with redis you can use rediscli to play with redis start a redisserver instance then in another terminal try the following cd src rediscli redis ping pong redis set foo bar ok redis get foo bar redis incr mycounter integer redis incr mycounter integer redis you can find the list of all the available commands at installing redis in order to install redis binaries into usrlocalbin just use make install you can use make prefixsomeotherdirectory install if you wish to use a different destination make install will just install binaries in your system but will not configure init scripts and configuration files in the appropriate place this is not needed if you just want to play a bit with redis but if you are installing it the proper way for a production system we have a script that does this for ubuntu and debian systems cd utils installserversh note installserversh will not work on mac osx it is built for linux only the script will ask you a few questions and will setup everything you need to run redis properly as a background daemon that will start again on system reboots youll be able to stop and start redis using the script named etcinitdredis for instance etcinitdredis6379 code contributions by contributing code to the redis project in any form including sending a pull request via github a code fragment or patch via private email or public discussion groups you agree to release your code under the terms of the redis software grant and contributor license agreement1 redis software contains contributions to the original redis core project which are owned by their contributors and licensed under the 3bsd license any copy of that license in this repository applies only to those contributions redis releases all redis project versions from 74x and thereafter under the rsalv2sspl duallicense as described in the licensetxt2 file included in the redis source distribution please see the contributingmd1 file in this source distribution for more information for security bugs and vulnerabilities please see securitymd3 redis trademarks the purpose of a trademark is to identify the goods and services of a person or company without causing confusion as the registered owner of its name and logo redis accepts certain limited uses of its trademarks but it has requirements that must be followed as described in its trademark guidelines available at redis internals if you are reading this readme you are likely in front of a github page or you just untarred the redis distribution tar ball in both the cases you are basically one step away from the source code so here we explain the redis source code layout what is in each file as a general idea the most important functions and structures inside the redis server and so forth we keep all the discussion at a high level without digging into the details since this document would be huge otherwise and our code base changes continuously but a general idea should be a good starting point to understand more moreover most of the code is heavily commented and easy to follow source code layout the redis root directory just contains this readme the makefile which calls the real makefile inside the src directory and an example configuration for redis and sentinel you can find a few shell scripts that are used in order to execute the redis redis cluster and redis sentinel unit tests which are implemented inside the tests directory inside the root are the following important directories src contains the redis implementation written in c tests contains the unit tests implemented in tcl deps contains libraries redis uses everything needed to compile redis is inside this directory your system just needs to provide libc a posix compatible interface and a c compiler notably deps contains a copy of jemalloc which is the default allocator of redis under linux note that under deps there are also things which started with the redis project but for which the main repository is not redisredis there are a few more directories but they are not very important for our goals here well focus mostly on src where the redis implementation is contained exploring what there is inside each file the order in which files are exposed is the logical one to follow in order to disclose different layers of complexity incrementally note lately redis was refactored quite a bit function names and file names have been changed so you may find that this documentation reflects the unstable branch more closely for instance in redis the serverc and serverh files were named redisc and redish however the overall structure is the same keep in mind that all the new developments and pull requests should be performed against the unstable branch serverh the simplest way to understand how a program works is to understand the data structures it uses so well start from the main header file of redis which is serverh all the server configuration and in general all the shared state is defined in a global structure called server of type struct redisserver a few important fields in this structure are serverdb is an array of redis databases where data is stored servercommands is the command table serverclients is a linked list of clients connected to the server servermaster is a special client the master if the instance is a replica there are tons of other fields most fields are commented directly inside the structure definition another important redis data structure is the one defining a client in the past it was called redisclient now just client the structure has many fields here well just show the main ones c struct client int fd sds querybuf int argc robj argv redisdb db int flags list reply many other fields char bufprotoreplychunkbytes the client structure defines a connected client the fd field is the client socket file descriptor argc and argv are populated with the command the client is executing so that functions implementing a given redis command can read the arguments querybuf accumulates the requests from the client which are parsed by the redis server according to the redis protocol and executed by calling the implementations of the commands the client is executing reply and buf are dynamic and static buffers that accumulate the replies the server sends to the client these buffers are incrementally written to the socket as soon as the file descriptor is writable as you can see in the client structure above arguments in a command are described as robj structures the following is the full robj structure which defines a redis object c struct redisobject unsigned type4 unsigned encoding4 unsigned lrulrubits lru time relative to global lruclock or lfu data least significant bits frequency and most significant bits access time int refcount void ptr basically this structure can represent all the basic redis data types like strings lists sets sorted sets and so forth the interesting thing is that it has a type field so that it is possible to know what type a given object has and a refcount so that the same object can be referenced in multiple places without allocating it multiple times finally the ptr field points to the actual representation of the object which might vary even for the same type depending on the encoding used redis objects are used extensively in the redis internals however in order to avoid the overhead of indirect accesses recently in many places we just use plain dynamic strings not wrapped inside a redis object serverc this is the entry point of the redis server where the main function is defined the following are the most important steps in order to startup the redis server initserverconfig sets up the default values of the server structure initserver allocates the data structures needed to operate setup the listening socket and so forth aemain starts the event loop which listens for new connections there are two special functions called periodically by the event loop servercron is called periodically according to serverhz frequency and performs tasks that must be performed from time to time like checking for timed out clients beforesleep is called every time the event loop fired redis served a few requests and is returning back into the event loop inside serverc you can find code that handles other vital things of the redis server call is used in order to call a given command in the context of a given client activeexpirecycle handles eviction of keys with a time to live set via the expire command performevictions is called when a new write command should be performed but redis is out of memory according to the maxmemory directive the global variable rediscommandtable defines all the redis commands specifying the name of the command the function implementing the command the number of arguments required and other properties of each command commandsc this file is auto generated by utilsgeneratecommandcodepy the content is based on the json files in the srccommands folder these are meant to be the single source of truth about the redis commands and all the metadata about them these json files are not meant to be used by anyone directly instead that metadata can be obtained via the command command networkingc this file defines all the io functions with clients masters and replicas which in redis are just special clients createclient allocates and initializes a new client the addreply family of functions are used by command implementations in order to append data to the client structure that will be transmitted to the client as a reply for a given command executed writetoclient transmits the data pending in the output buffers to the client and is called by the writable event handler sendreplytoclient readqueryfromclient is the readable event handler and accumulates data read from the client into the query buffer processinputbuffer is the entry point in order to parse the client query buffer according to the redis protocol once commands are ready to be processed it calls processcommand which is defined inside serverc in order to actually execute the command freeclient deallocates disconnects and removes a client aofc and rdbc as you can guess from the names these files implement the rdb and aof persistence for redis redis uses a persistence model based on the fork system call in order to create a process with the same shared memory content of the main redis process this secondary process dumps the content of the memory on disk this is used by rdbc to create the snapshots on disk and by aofc in order to perform the aof rewrite when the append only file gets too big the implementation inside aofc has additional functions in order to implement an api that allows commands to append new commands into the aof file as clients execute them the call function defined inside serverc is responsible for calling the functions that in turn will write the commands into the aof dbc certain redis commands operate on specific data types others are general examples of generic commands are del and expire they operate on keys and not on their values specifically all those generic commands are defined inside dbc moreover dbc implements an api in order to perform certain operations on the redis dataset without directly accessing the internal data structures the most important functions inside dbc which are used in many command implementations are the following lookupkeyread and lookupkeywrite are used in order to get a pointer to the value associated to a given key or null if the key does not exist dbadd and its higher level counterpart setkey create a new key in a redis database dbdelete removes a key and its associated value emptydata removes an entire single database or all the databases defined the rest of the file implements the generic commands exposed to the client objectc the robj structure defining redis objects was already described inside objectc there are all the functions that operate with redis objects at a basic level like functions to allocate new objects handle the reference counting and so forth notable functions inside this file incrrefcount and decrrefcount are used in order to increment or decrement an object reference count when it drops to the object is finally freed createobject allocates a new object there are also specialized functions to allocate string objects having a specific content like createstringobjectfromlonglong and similar functions this file also implements the object command replicationc this is one of the most complex files inside redis it is recommended to approach it only after getting a bit familiar with the rest of the code base in this file there is the implementation of both the master and replica role of redis one of the most important functions inside this file is replicationfeedslaves that writes commands to the clients representing replica instances connected to our master so that the replicas can get the writes performed by the clients this way their data set will remain synchronized with the one in the master this file also implements both the sync and psync commands that are used in order to perform the first synchronization between masters and replicas or to continue the replication after a disconnection script the script unit is composed of units scriptc integration of scripts with redis commands execution set replicationresp scriptluac responsible to execute lua code uses scriptc to interact with redis from within the lua code functionluac contains the lua engine implementation uses scriptluac to execute the lua code functionsc contains redis functions implementation function command uses functionsluac if the function it wants to invoke needs the lua engine evalc contains the eval implementation using scriptluac to invoke the lua code other c files thashc tlistc tsetc tstringc tzsetc and tstreamc contains the implementation of the redis data types they implement both an api to access a given data type and the client command implementations for these data types aec implements the redis event loop its a self contained library which is simple to read and understand sdsc is the redis string library check for more information anetc is a library to use posix networking in a simpler way compared to the raw interface exposed by the kernel dictc is an implementation of a nonblocking hash table which rehashes incrementally clusterc implements the redis cluster probably a good read only after being very familiar with the rest of the redis code base if you want to read clusterc make sure to read the redis cluster specification4 anatomy of a redis command all the redis commands are defined in the following way c void foobarcommandclient c printfscargv1ptr do something with the argument addreplycsharedok reply something to the client the command function is referenced by a json file together with its metadata see commandsc described above for details the command flags are documented in the comment above the struct rediscommand in serverh for other details please refer to the command command after the command operates in some way it returns a reply to the client usually using addreply or a similar function defined inside networkingc there are tons of command implementations inside the redis source code that can serve as examples of actual commands implementations eg pingcommand writing a few toy commands can be a good exercise to get familiar with the code base there are also many other files not described here but it is useless to cover everything we just want to help you with the first steps eventually youll find your way inside the redis code base enjoy
postgres,postgres,"Mirror of the official PostgreSQL GIT repository. Note that this is just a *mirror* - we don't work with pull requests on github. To contribute, please see https://wiki.postgresql.org/wiki/Submitting_a_Patch",https://github.com/postgres/postgres,14760,4317,524,1,C: 46467169; PLpgSQL: 3653432; Perl: 2188953; Yacc: 686068; Makefile: 354102; Meson: 350840; Ruby: 279888; Lex: 224113; M4: 191217; Shell: 74756; PLSQL: 54772; Python: 52819; C++: 30403; Roff: 17748; XS: 6998; Emacs Lisp: 4164; DTrace: 3452; Assembly: 2468; Starlark: 1640; sed: 581,,Other,2010-09-21T11:35:45Z,2024-05-02T15:28:47Z,551662,public,None,master,postgresql database management system this directory contains the source code distribution of the postgresql database management system postgresql is an advanced objectrelational database management system that supports an extended subset of the sql standard including transactions foreign keys subqueries triggers userdefined types and functions this distribution also contains c language bindings copyright and license information can be found in the file copyright general documentation about this version of postgresql can be found at in particular information about building postgresql from the source code can be found at the latest version of this software and related software may be obtained at for more information look at our web site located at
mysql,mysql-server,"MySQL Server, the world's most popular open source database, and MySQL Cluster, a real-time, open source transactional database.",https://github.com/mysql/mysql-server,10273,3712,562,0,C++: 261416109; C: 32686540; Java: 3583804; Makefile: 2651470; NASL: 2329732; CMake: 2048654; Shell: 1846956; Objective-C: 1589250; Perl: 981835; HTML: 933841; Yacc: 667123; JavaScript: 471261; Roff: 432738; M4: 344040; Pascal: 290499; PHP: 152888; Starlark: 104858; CSS: 68769; Assembly: 40877; RPC: 40215; SWIG: 26929; DIGITAL Command Language: 26404; Lex: 20635; Python: 17958; Awk: 17928; PowerShell: 14807; Gnuplot: 13714; SourcePawn: 11415; Pawn: 9963; Emacs Lisp: 8220; LLVM: 5692; Vim Script: 3805; POV-Ray SDL: 2954; Batchfile: 1957; VBScript: 1549; Module Management System: 1545; Dockerfile: 634; Ruby: 439; Visual Basic 6.0: 433; PLSQL: 280,,Other,2014-09-26T09:31:03Z,2024-05-02T16:08:42Z,4337850,public,None,trunk,copyright c oracle andor its affiliates this is a release of mysql an sql database server license information can be found in the license file in test packages where this file is renamed readmetest the license file is renamed licensetest this distribution may include materials developed by third parties for license and attribution notices for these materials please refer to the license file for further information on mysql or additional documentation visit for additional downloads and the source of mysql visit mysql is brought to you by the mysql team at oracle
apache,cassandra,Mirror of Apache Cassandra,https://github.com/apache/cassandra,8521,3543,443,471,Java: 43315569; Python: 590563; HTML: 265026; Shell: 223516; GAP: 95879; Lex: 10152; AMPL: 801,cassandra;database;java,Apache License 2.0,2009-05-21T02:10:09Z,2024-05-02T15:47:31Z,429138,public,None,trunk,apache cassandra apache cassandra is a highlyscalable partitioned row store rows are organized into tables with a required primary key means that cassandra can distribute your data across multiple machines in an applicationtransparent matter cassandra will automatically repartition as machines are added and removed from the cluster store means that like relational databases cassandra organizes data by rows and columns the cassandra query language cql is a close relative of sql for more information see apache cassandra web site issues should be reported on cassandra jira requirements java see supported versions in buildxml search for property javasupported python for cqlsh see bincqlsh search for function issupportedversion getting started this short guide will walk you through getting a basic one node cluster up and running and demonstrate some simple reads and writes for a morecomplete guide please see the apache cassandra websites started guide first well unpack our archive tar zxvf apachecassandraversiontargz cd apachecassandraversion after that we start the server running the startup script with the f argument will cause cassandra to remain in the foreground and log to standard out it can be stopped with ctrlc bincassandra f now lets try to read and write some data using the cassandra query language bincqlsh the command line client is interactive so if everything worked you should be sitting in front of a prompt connected to test cluster at localhost9160 cqlsh cassandra 50snapshot cql spec native protocol v5 use help for help cqlsh as the banner says you can use help or to see what cql has to offer and quit or exit when youve had enough fun but lets try something slightly more interesting cqlsh create keyspace schema1 with replication class simplestrategy replicationfactor cqlsh use schema1 cqlshschema1 create table users userid varchar primary key first varchar last varchar age int cqlshschema1 insert into users userid first last age values jsmith john smith cqlshschema1 select from users userid age first last jsmith john smith cqlshschema1 if your session looks similar to whats above congrats your single node cluster is operational for more on what commands are supported by cql see cql reference a reasonable way to think of it is as sql minus joins and subqueries plus collections wondering where to go from here join us in cassandra on the slack and ask questions subscribe to the users mailing list by sending a mail to usersubscribecassandraapacheorg subscribe to the developer mailing list by sending a mail to devsubscribecassandraapacheorg visit the section of the cassandra website for more information on getting involved visit the section of the cassandra website for more information on how to contribute
neo4j,neo4j,Graphs for Everyone,https://github.com/neo4j/neo4j,12486,2315,517,306,Java: 38545456; Scala: 16101091; Gherkin: 285061; Roff: 62526; Shell: 33886; PowerShell: 21127; Makefile: 4236; Batchfile: 1796; Dockerfile: 512; HTML: 146,cypher;database;graph;graph-database;graphdb;neo4j;nosql,GNU General Public License v3.0,2012-11-12T08:46:15Z,2024-05-02T14:39:03Z,622800,public,None,5.17,neo4j graphs for everyone is the worlds leading graph database it is a high performance graph store with all the features expected of a mature and robust database like a friendly query language and acid transactions the programmer works with a flexible network structure of nodes and relationships rather than static tables yet enjoys all the benefits of enterprisequality database for many applications neo4j offers orders of magnitude performance benefits compared to relational dbs learn more on the website users using neo4j neo4j is available both as a standalone server or an embeddable component you can or online extending neo4j we encourage experimentation with neo4j you can build extensions to neo4j develop library or drivers atop the product or make contributions directly to the product core youll need to sign a contributor license agreement in order for us to accept your patches dependencies neo4j is built using maven version and a recent version of supported vm bash and make are also required note that maven needs more memory than the standard configuration this can be achieved with export mavenoptsxmx2048m macos users need to have installed with brew on macos brew install maven please note that we do not support building debian packages on macos with aptget on ubuntu sudo apt install maven openjdk17jdk be sure that the javahome environment variable points to usrlibjvmjava17openjdkamd64 you may have various java versions installed building neo4j before you start running the unit and integration tests in the neo4j maven project on a linuxlike system you should ensure your limit on open files is set to a reasonable value you can test it with ulimit n we recommend you have a limit of at least 40k a plain mvn clean install t1c will only build the individual jar files test execution is of course part of the build in case you just want the jars without running tests this is for you mvn clean install dskiptests t1c you may need to increase the memory available to maven export mavenoptsxmx2048m try this first if you get build errors you may run into problems resolving orgneo4jbuildbuildresources due to a bug in maven to resolve this simply invoke mvn clean install pl buildresources running neo4j after running a mvn clean install cd into packagingstandalonetarget and extract the version you want then binneo4jadmin server start in the extracted folder to start neo4j on localhost7474 on windows you want to run binneo4jadmin server start instead neo4j desktop neo4j desktop is a convenient way for developers to work with local neo4j databases to install neo4j desktop go to download center and follow the instructions licensing neo4j community edition is an open source product licensed under gplv3 neo4j enterprise edition includes additional closedsource components not available in this repository and requires a commercial license from neo4j or one of its affiliates trademark neo4js trademark policy is available at trademark policy page
docker,docker-ce,:warning: This repository is deprecated and will be archived (Docker CE itself is NOT deprecated) see the https://github.com/docker/docker-ce/blob/master/README.md :warning:,https://github.com/docker/docker-ce,5721,1509,304,2,Go: 11712624; Shell: 517985; PowerShell: 80464; Makefile: 44253; Dockerfile: 40020; Python: 7179; C: 4815; HCL: 2012; Assembly: 81,docker;git;golang;moby,Apache License 2.0,2017-05-19T23:09:47Z,2024-05-02T00:26:15Z,187193,public,None,master,docker ce warning this repository is now deprecated and will be archived docker ce itself is not deprecated warning starting with the docker release packages for the docker engine and docker cli are built directly from their respective source repositories instead of from this repository practically this means this repository is no longer the source of truth for docker ce builds the commit sha and tag for docker cli build will come from the dockercli repository and the commit sha and tag for the docker engine will come from the mobymoby repository release branches for the engine cli and packaging will be maintained on their respective repositories updates will stop being made to this repository and it will be archived in the future changelog is now release notes the master branch of this repository will be emptied when the repository is archived description this repository hosts open source components of docker ce products the master branch serves to unify the upstream components on a regular basis longlived release branches host the code that goes into a product version for the lifetime of the product this repository is solely maintained by docker inc issues there are separate issuetracking repos for the end user docker ce products specialized for a platform find your issue or file a new issue for the platform you are using submitting pull requests this repository does not accept prs for files under the componentscomponents directory directly to contribute to the files under the components directory see contributingmdcontributingmdsubmittingpullrequests unifying upstream sources the master branch is a combination of components adapted from different upstream git repos into a unified directory structure using the mobycomponents tool you can view the upstream git repos in the componentsconfcomponentsconf file each component is isolated into its own directory under the componentscomponents directory the tool will import each component git history within the appropriate path for example this shows a commit is imported into the component engine from mobymobya27b4b8 into the componentsengine directory commit 5c70746915d4589a692cbe50a43cf619ed0b7152 author andrea luzzardi date sat jan initial commit upstreamcommit a27b4b8cb8e838d03a99b6d2b30f76bdaf2f9e5d component engine componentsenginecontainergo componentsenginecontainertestgo componentsenginedockergo componentsenginedockertestgo componentsenginefilesystemgo componentsenginefilesystemtestgo componentsenginelxctemplatego componentsenginestatego componentsengineutilsgo componentsengineutilstestgo files changed insertions updates to master branch main development of new features should be directed towards the upstream git repos the master branch of this repo will periodically pull in new changes from upstream to provide a point for integration branching for release when a release is started for docker ce a new branch will be created from master branch names will be yymm to represent the timebased release version of the product eg adding fixes to release branch note every commit of a fix should affect files only within one component directory fix available upstream a pr cherrypicking the necessary commits should be created against the release branch if the the cherrypick cannot be applied cleanly the logic of the fix should be ported manually no fix yet first create the pr with the fix for the release branch once the fix has been merged be sure to port the fix to the respective upstream git repo release tags there will be a git tag for each release candidate rc and general availability ga release the tag will only point to commits on release branches
kubernetes,kubernetes,Production-Grade Container Scheduling and Management,https://github.com/kubernetes/kubernetes,106930,38453,3233,2577,Go: 70274132; Shell: 1906491; PowerShell: 146830; Makefile: 64196; Dockerfile: 49117; Python: 24146; C: 3902; sed: 1262; Batchfile: 833; HTML: 106,cncf;containers;go;kubernetes,Apache License 2.0,2014-06-06T22:56:04Z,2024-05-02T17:15:31Z,1267289,public,None,master,kubernetes k8s cii best practices go report card github release latest semver kubernetes also known as k8s is an open source system for managing containerized applications across multiple hosts it provides basic mechanisms for the deployment maintenance and scaling of applications kubernetes builds upon a decade and a half of experience at google running production workloads at scale using a system called borg combined with bestofbreed ideas and practices from the community kubernetes is hosted by the cloud native computing foundation cncf if your company wants to help shape the evolution of technologies that are containerpackaged dynamically scheduled and microservicesoriented consider joining the cncf for details about whos involved and how kubernetes plays a role read the cncf announcement to start using k8s see our documentation on kubernetesio take a free course on scalable microservices with kubernetes to use kubernetes code as a library in other applications see the list of published components use of the k8siokubernetes module or k8siokubernetes packages as libraries is not supported to start developing k8s the community repository hosts all information about building kubernetes from source how to contribute code and documentation who to contact about what etc if you want to build kubernetes right away there are two options you have a working go environment git clone cd kubernetes make you have a working docker environment git clone cd kubernetes make quickrelease for the full story head over to the developers documentation support if you need support start with the troubleshooting guide and work your way through the process that weve outlined that said if you have questions reach out to us one way or anothercommunication announcement borg cncf communication community repository containerized applications developers documentation docker environment go environment kubernetesio scalable microservices with kubernetes troubleshooting guide community meetings the calendar has the list of all the meetings in the kubernetes community in a single location adopters the user case studies website has realworld use cases of organizations across industries that are deployingmigrating to kubernetes governance kubernetes project is governed by a framework of principles values policies and processes to help our community and constituents towards our shared goals the kubernetes community is the launching point for learning about how we organize ourselves the kubernetes steering community repo is used by the kubernetes steering committee which oversees governance of the kubernetes project roadmap the kubernetes enhancements repo provides information about kubernetes releases as well as feature tracking and backlogs
ansible,ansible,"Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.",https://github.com/ansible/ansible,61202,23695,1919,860,Python: 9028713; PowerShell: 724932; Shell: 282881; C#: 218479; Jinja: 44461; Go: 2010; Makefile: 757; Roff: 555; Batchfile: 144,ansible;hacktoberfest;python,GNU General Public License v3.0,2012-03-06T14:58:02Z,2024-05-02T17:23:03Z,252975,public,None,devel,pypi version docs badge chat badge build status ansible code of conduct ansible mailing lists repository license ansible cii best practices certification ansible ansible is a radically simple it automation system it handles configuration management application deployment cloud provisioning adhoc task execution network automation and multinode orchestration ansible makes complex changes like zerodowntime rolling updates with load balancers easy more information on the ansible website design principles have an extremely simple setup process with a minimal learning curve manage machines quickly and in parallel avoid customagents and additional open ports be agentless by leveraging the existing ssh daemon describe infrastructure in a language that is both machine and human friendly focus on security and easy auditabilityreviewrewriting of content manage new remote machines instantly without bootstrapping any software allow module development in any dynamic language not just python be usable as nonroot be the easiest it automation system to use ever use ansible you can install a released version of ansible with pip or a package manager see our installation guide for details on installing ansible on a variety of platforms power users and developers can run the devel branch which has the latest features and fixes directly although it is reasonably stable you are more likely to encounter breaking changes when running the devel branch we recommend getting involved in the ansible community if you want to run the devel branch get involved read community information for all kinds of ways to contribute to and interact with the project including mailing list information and how to submit bug reports and code to ansible join a working group an organized community devoted to a specific technology domain or platform submit a proposed code update through a pull request to the devel branch talk to us before making larger changes to avoid duplicate efforts this not only helps everyone know what is going on but it also helps save time and effort if we decide some changes are needed for a list of email lists irc channels and working groups see the communication page coding guidelines we document our coding guidelines in the developer guide we particularly suggest you review contributing your module to ansible conventions tips and pitfalls branch info the devel branch corresponds to the release actively under development the stable2x branches correspond to stable releases create a branch based on devel and set up a dev environment if you want to open a pr see the ansible release and maintenance page for information about active branches roadmap based on team and community feedback an initial roadmap will be published for a major or minor version ex the ansible roadmap page details what is planned and how to influence the roadmap authors ansible was created by michael dehaan and has contributions from over users and growing thanks everyone ansible is sponsored by red hat inc license gnu general public license v30 or later see copyingcopying to see the full text
hashicorp,terraform,"Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.",https://github.com/hashicorp/terraform,41220,9328,1179,1986,Go: 13561973; MDX: 1398016; HCL: 32914; Shell: 17364; Makefile: 3696; Dockerfile: 874,cloud;cloud-management;graph;infrastructure-as-code;terraform,Other,2014-03-13T22:25:48Z,2024-05-02T17:25:21Z,309715,public,None,main,terraform website forums hashicorp discuss documentation tutorials hashicorps learn platform certification exam hashicorp certified terraform associate terraform is a tool for building changing and versioning infrastructure safely and efficiently terraform can manage existing and popular service providers as well as custom inhouse solutions the key features of terraform are infrastructure as code infrastructure is described using a highlevel configuration syntax this allows a blueprint of your datacenter to be versioned and treated as you would any other code additionally infrastructure can be shared and reused execution plans terraform has a planning step where it generates an execution plan the execution plan shows what terraform will do when you call apply this lets you avoid any surprises when terraform manipulates infrastructure resource graph terraform builds a graph of all your resources and parallelizes the creation and modification of any nondependent resources because of this terraform builds infrastructure as efficiently as possible and operators get insight into dependencies in their infrastructure change automation complex changesets can be applied to your infrastructure with minimal human interaction with the previously mentioned execution plan and resource graph you know exactly what terraform will change and in what order avoiding many possible human errors for more information refer to the what is terraform page on the terraform website getting started documentation documentation is available on the terraform website introduction documentation if youre new to terraform and want to get started creating infrastructure please check out our getting started guides on hashicorps learning platform there are also additional guides to continue your learning show off your terraform knowledge by passing a certification exam visit the certification page for information about exams and find study materials on hashicorps learning platform developing terraform this repository contains only terraform core which includes the command line interface and the main graph engine providers are implemented as plugins and terraform can automatically download providers that are published on the terraform registry hashicorp develops some providers and others are developed by other organizations for more information see extending terraform to learn more about compiling terraform and contributing suggested changes refer to the contributing guidegithubcontributingmd to learn more about how we handle bug reports refer to the bug triage guidebugprocessmd to learn how to contribute to the terraform documentation in this repository refer to the terraform documentation readmewebsitereadmemd license business source license
jenkinsci,jenkins,Jenkins automation server,https://github.com/jenkinsci/jenkins,22420,8521,868,78,Java: 12048597; HTML: 992947; JavaScript: 399744; SCSS: 329105; CSS: 201743; Groovy: 73789; Ruby: 17290; Perl: 16145; Handlebars: 14894; Python: 4709; ANTLR: 4633; Shell: 3887; C: 2091; Batchfile: 1023; Dockerfile: 210,cicd;continuous-delivery;continuous-deployment;continuous-integration;devops;groovy;hacktoberfest;java;jenkins;pipelines-as-code,MIT License,2010-11-22T21:21:23Z,2024-05-02T17:06:13Z,157743,public,None,master,about jenkins regular release jenkins lts release docker pulls cii best practices gitter in a nutshell jenkins is the leading opensource automation server built with java it provides over plugins to support automating virtually anything so that humans can spend their time doing things machines cannot what to use jenkins for and when to use it use jenkins to automate your development workflow so you can focus on work that matters most jenkins is commonly used for building projects running tests to detect bugs and other issues as soon as they are introduced static code analysis deployment execute repetitive tasks save time and optimize your development process with jenkins downloads the jenkins project provides official distributions as war files docker images native packages and installers for platforms including several linux distributions and windows see the downloads page for references for all distributions jenkins offers two release lines weekly frequent releases which include all new features improvements and bug fixes longterm support lts older release line which gets periodically updated via bug fix backports latest releases jenkins regular release jenkins lts release source our latest and greatest source of jenkins can be found on github fork us contributing to jenkins follow the contributing guidelinescontributingmd if you want to propose a change in the jenkins core for more information about participating in the community and contributing to the jenkins project see this page documentation for jenkins core maintainers is in the maintainers guidelinesdocsmaintainersadoc news and website all information about jenkins can be found on our website follow us on twitter or linkedin governance see the jenkins governance document for information about the projects open governance our philosophy and values and development practices jenkins code of conduct can be found here adopters jenkins is used by millions of users and thousands of companies see adopters for the list of jenkins adopters and their success stories license jenkins is licensed under the mit licenselicensetxt
puppetlabs,puppet,Server automation framework and application,https://github.com/puppetlabs/puppet,7286,2178,464,56,Ruby: 12867747; HTML: 23697; Puppet: 20124; Shell: 12321; C#: 5195; Pascal: 993; Batchfile: 594,,Apache License 2.0,2010-09-14T19:26:44Z,2024-05-02T12:42:32Z,89053,public,None,main,puppet rspec tests gem version inline docs puppet an automated administrative engine for your linux unix and windows systems performs administrative tasks such as adding users installing packages and updating server configurations based on a centralized specification documentation documentation for puppet and related projects can be found online at the puppet docs site http api http api index installation the best way to run puppet is with puppet enterprise pe which also includes orchestration features a web console and professional support the pe documentation is available here to install an open source release of puppet see the installation guide on the docs site if you need to run puppet from source as a tester or developer see the quick start to developing on puppetdocsquickstartmd guide developing and contributing wed love to get contributions from you for a quick guide to getting your system setup for developing take a look at our quickstart guide once you are up and running take a look at the contribution documents to see how to get your changes merged in for more complete docs on developing with puppet take a look at the rest of the developer documents licensing see license file puppet is licensed by puppet inc under the apache license puppet inc can be contacted at infopuppetcom support please log issues in this projects github issues a mailing list is available for asking questions and getting help from others or if you prefer chat we also have a puppet community slack we use semantic version numbers for our releases and recommend that users stay as uptodate as possible by upgrading to patch releases and minor releases as they become available bug fixes and ongoing development will occur in minor releases for the current major version security fixes will be backported to a previous major version on a besteffort basis until the previous major version is no longer maintained for example if a security vulnerability is discovered in puppet we would fix it in the series most likely as maintainers would then make a best effort to backport that fix onto the latest puppet release longterm support including security patches and bug fixes is available for commercial customers please see the following page for more details puppet enterprise support lifecycle
Unity-Technologies,UnityCsReference,Unity C# reference source code.,https://github.com/Unity-Technologies/UnityCsReference,11401,2446,865,12,C#: 45361742,,Other,2018-03-23T13:08:32Z,2024-05-02T14:14:51Z,64805,public,None,master,unity 600000f1 c reference source code the c part of the unity engine and editor source code may be used for reference purposes only for terms of use see the repository includes thirdparty code subject to thirdparty noticesthirdpartynoticestxt the terms of use do not permit you to modify or redistribute the c code in either source or binary form if you want to modify unitys source code c and c contact unity sales for a commercial source code license we do not take pull requests at this time sorry but if you find something that looks like a bug wed appreciate it if youd file it using the unity bug reporter for more information see our blog post unless expressly provided otherwise the software under this license is made available strictly on an as is basis without warranty of any kind express or implied please review the license for details on these and other terms and conditions the c solution is in projectscsharpunityreferencesourcesln the folder and file layout of the reference source matches the unity source tree layout it can and will change between different unity versions
godotengine,godot,Godot Engine â€“ Multi-platform 2D and 3D game engine,https://github.com/godotengine/godot,83889,18289,1512,12330,C++: 48740733; C#: 2127250; C: 1488418; GLSL: 958599; Java: 588388; Python: 570949; Objective-C++: 522754; GDScript: 224637; JavaScript: 222919; Kotlin: 158548; Objective-C: 24461; Shell: 15457; AIDL: 1633; CMake: 638; GAP: 62,game-development;game-engine;gamedev;godot;godotengine;hacktoberfest;multi-platform;open-source,MIT License,2014-01-04T16:05:36Z,2024-05-02T17:20:49Z,1335322,public,None,master,godot engine 2d and 3d crossplatform game engine godot engine is a featurepacked crossplatform game engine to create 2d and 3d games from a unified interface it provides a comprehensive set of common tools so that users can focus on making games without having to reinvent the wheel games can be exported with one click to a number of platforms including the major desktop platforms linux macos windows mobile platforms android ios as well as webbased platforms and consoles free open source and communitydriven godot is completely free and open source under the very permissive mit license no strings attached no royalties nothing the users games are theirs down to the last line of engine code godots development is fully independent and communitydriven empowering users to help shape their engine to match their expectations it is supported by the godot foundation notforprofit before being open sourced in february godot had been developed by juan linietsky and ariel manzur both still maintaining the project for several years as an inhouse engine used to publish several workforhire titles screenshot of a 3d scene in the godot engine editor getting the engine binary downloads official binaries for the godot editor and the export templates can be found on the godot website compiling from source see the official docs for compilation instructions for every supported platform community and contributing godot is not only an engine but an evergrowing community of users and engine developers the main community channels are listed on the homepage the best way to get in touch with the core engine developers is to join the godot contributors chat to get started contributing to the project see the contributing guidecontributingmd this document also includes guidelines for reporting bugs documentation and demos the official documentation is hosted on read the docs it is maintained by the godot community in its own github repository the class reference is also accessible from the godot editor we also maintain official demos in their own github repository as well as a list of awesome godot community resources there are also a number of other learning resources provided by the community such as text and video tutorials demos etc consult the community channels for more information code triagers badge translate on weblate todos
MonoGame,MonoGame,One framework for creating powerful cross-platform games.,https://github.com/MonoGame/MonoGame,10838,2820,469,797,C#: 6578967; HLSL: 60474; Rich Text Format: 45920; Smalltalk: 30342; XSLT: 21787; Shell: 1903; Batchfile: 259; PowerShell: 68,3d;c-sharp;cross-platform;csharp;dotnet;game-development;game-engine;game-framework;gamedev;graphics;monogame;open-source;xna,Other,2011-04-07T00:23:40Z,2024-05-02T11:19:30Z,93248,public,None,develop,monogame monogame is a simple and powerful net framework for creating games for desktop pcs video game consoles and mobile devices using the c programming language it has been successfully used to create games such as streets of rage carrion celeste stardew valley and many others it is an opensource reimplementation of the discontinued microsofts xna framework join the chat at build statusbuildstatus supported platformssupportedplatforms support and contributionssupportandcontributions source codesourcecode helpful linkshelpfullinks licenselicense build status we use github actions to automate builds and packages distribution of the latest monogame changes we also rely on a build server to run tests in order to avoid regressions the table below shows the current build status for the develop branch name status builds build supported platforms we support a growing list of platforms across the desktop mobile and console space if there is a platform we dont support please make a request or come help uscontributingmd add it desktop pcs windows and up opengl directx windows store apps uwp linux opengl macos and up opengl mobiletablet devices android and up opengl iphoneipad and up opengl consoles for registered developers playstation playstation xbox one both uwp and xdk nintendo switch google stadia support and contributions if you think you have found a bug or have a feature request use our issue tracker before opening a new issue please search to see if your problem has already been reported try to be as detailed as possible in your issue reports if you need help using monogame or have other questions we suggest you post on our community forums please do not use the github issue tracker for personal support requests if you are interested in contributing fixes or features to monogame please read our contributors guidecontributingmd first subscription if youd like to help the project by supporting us financially consider supporting us via a subscription for the price of a monthly coffee money goes towards hosting new hardware and if enough people subscribe a dedicated developer there are several options on our donation page source code the full source code is available here from github clone the source git clone set up the submodules git submodule update init open the solution for your target platform to build the game framework open the tools solution for your development platform to build the pipeline and content tools for the prerequisites for building from source please look at the requirementsrequirementsmd file a high level breakdown of the components of the framework the game framework is found in monogameframeworkmonogameframework the content pipeline is located in monogameframeworkcontentpipelinemonogameframeworkcontentpipeline project templates are in templatestemplates see teststests for the framework unit tests see toolsteststoolsmonogametoolstests for the content pipeline and other tool tests mgcbtoolsmonogamecontentbuilder is the command line tool for content processing mgfxctoolsmonogameeffectcompiler is the command line effect compiler tool the mgcbeditortoolsmonogamecontentbuildereditor tool is a gui frontend for content processing helpful links the official website is monogamenet our issue tracker is on github use our community forums for support questions you can join the discord server and chat live with the core developers and other users the official documentation is on our website download release and development packages follow monogameteam on twitter license the monogame project is under the microsoft public license except for a few portions of the code see the licensetxtlicensetxt file for more details thirdparty libraries used by monogame are under their own licenses please refer to those libraries for details on the license they use
photonstorm,phaser,"Phaser is a fun, free and fast 2D game framework for making HTML5 games for desktop and mobile web browsers, supporting Canvas and WebGL rendering.",https://github.com/phaserjs/phaser,36356,7052,1224,84,JavaScript: 11177451; TypeScript: 27498; GLSL: 26552,canvas;facebook-instant-games;game-development;game-frameworks;gamedev;html5-game-development;javascript;phaser;phaser-development;phaserjs;webgl,MIT License,2013-04-12T12:27:51Z,2024-05-02T16:29:09Z,402719,public,None,master,phaser html5 game framework phaser header phaser header banner discord chat twitter follow npm github phaser is a fast free and fun open source html5 game framework that offers webgl and canvas rendering across desktop and mobile web browsers games can be compiled to ios android and native apps by using 3rd party tools you can use javascript or typescript for development along with the fantastic open source community phaser is actively developed and maintained by phaser studio inc as a result of rapid support and a developer friendly api phaser is currently one of the most starred game frameworks on github thousands of developers from indies to multinational digital agencies along with universities worldwide use phaser take a look at their incredible games in our showcase video phaser games showcase video visit the phaser website and follow on phaser twitter play some of the amazing games madewithphaser learn api docs support forumforum and stackoverflow code examples source available in this repoexamples read the phaser worldnewsletter newsletter discord join us on discord grab the source and join the fun whats new whats new 27th february the release of phaser affectionately dubbed nino represents a significant leap forward in our quest to provide an even more powerful and versatile web game development framework this update showcases our commitment to innovation bolstered by the insightful feedback and contributions from our dedicated community and the tireless efforts of our development team phaser brings an array of new capabilities and improvements that enrich the developer experience among the highlights webgl context loss handling a robust solution to keep your games running smoothly even in the face of webgl context losses ensuring uninterrupted gameplay compressed texture improvements added support for bptc and rgtc file formats srgb color spaces and lots of updates around mipmaps levels base64 loader integration allows for the loading of base64 encoded assets facilitating smoother development processes for environments requiring embedded assets like playable ads scale manager snap mode a new feature allowing developers to set a snapping value for game dimensions ideal for pixelart games and those requiring precise scaling control tilemap enhancements fixes and updates for tile collision and rendering enhanced tile to sprite creation properties and more control over tilebased game elements with this release weve implemented over updates and bug fixes addressing communityreported issues and optimizing phasers performance and stability these changes reflect our ongoing dedication to enhancing the frameworks capabilities ensuring developers have the tools they need to bring their creative visions to life at the same time as this release we also hit the stars milestone on github are used by over developers and have over contributors these figures are a testament to the growing community of developers who have embraced phaser as their goto framework for web game development were grateful for the support and feedback weve received and were committed to continuing to evolve phaser to meet the needs of our community were excited for you to dive into phaser nino and explore the new features and improvements as always we look forward to your feedback and contributions as we continue to evolve phaser together to make sure you read our weekly developer logs please subscribe to our free newsletter if you find any problems please report them in github issues as usual id like to send my thanks to the phaser community for their help in both reporting issues and submitting pull requests to fix them you can also follow phaser on twitter and chat with fellow phaser devs in our discord phaser wouldnt have been possible without the fantastic support of the community thank you to everyone who supports our work who shares our belief in the future of html5 gaming and phasers role in that happy coding everyone cheers rich and the team at phaser studio photonstorm boogie download phaser download phaser phaser is available via github npm and cdns clone the git repository via httpsclonehttp sshclonessh or with the github windowscloneghwin or maccloneghmac clients download as zip download the build files phaserjsgetjs and phaserminjsgetminjs npm install via npm bash npm install phaser cdn phaser is on jsdelivr which is a superfast cdn for developers include the following in your html html or the minified version html api documentation go to to read the docs online use the links to navigate the namespaces classes and game objects lists and also use the search box the documentation for phaser is an ongoing project please help us by contributing improved docs and examples typescript definitions the typescript definitions can be found inside the types folder they are also referenced in the types entry in packagejson depending on your project you may need to add the following to your tsconfigjson file json lib es6 dom domiterable scripthost typeroots nodemodulesphasertypes types phaser the typescript defs are automatically generated from the jsdoc comments found in the phaser source code if you wish to help refine them then you must edit the phaser jsdoc blocks directly not the defs file you can find more details about the parser we built in the scriptstsgen folder project templates if you are familiar with web development and bundlers then we have published a selection of project templates to help you get started with your game quicky choose from the following vue vite template vite template webpack template esbuild template import map template rollup template parcel template license phaser is released under the mit license phaser world phaser world the phaser world newsletter is a weekly email that contains the latest news updates and releases from the phaser community it includes new games code examples and the latest articles subscribe here getting started getting started tutorials and guides on phaser are being published every week getting started with phaser useful if you are completely new to phaser making your first phaser game the complete phaser game development course contains over hours of videos covering all kinds of important topics plus there are over phaser tutorials listed on the official website source code examples during the development of phaser we created hundreds of examples with the full source code and assets ready available these examples can be browsed on the phaser labs or clone the examples repoexamples we are constantly adding to and refining these examples hathora hathora cloud is a scalable hosting platform for online multiplayer games you upload your server project using the hathora console or cli and then dynamically create server instances in regions around the world you get charged only for the duration of active matchessessions its perfect for nodejs servers handling websocket connections and takes care of ssl termination for wss and ddos protection they have also published a brandnew tutorial on creating a scalable multiplayer phaser game if you think this could be useful for your hosting needs join their discord server to get in touch huge list of phaser plugins super community member rexrainbow has been publishing phaser content for years building up an impressive catalogue in that time youll find loads of plugins from ui controls such as text input boxes to firebase support finite state machines and lots more as well as the plugins there is also a comprehensive set of notes about phaser going into great detail about how the various systems work its an invaluable resource and well worth checking out at create your first phaser example create an indexhtml page locally and paste the following code into it html this is a standard empty webpage youll notice theres a script tag that is pulling in a build of phaser but otherwise this webpage doesnt do anything yet now lets setup the game config paste the following between the tags javascript const config type phaserauto width height physics default arcade arcade gravity y scene example const game new phasergameconfig config is a pretty standard phaser game configuration object we tell config to use the webgl renderer if it can set the canvas to a size of x pixels enable arcade physics and finally we tell it to use the example scene this hasnt been implemented yet so if you run this javascript code now you will have an error add the following above the config javascript class example extends phaserscene constructor super preload thisloadsetbaseurl thisloadimagesky assetsskiesspace3png thisloadimagelogo assetsspritesphaser3logopng thisloadimagered assetsparticlesredpng create here we create a scene called example weve given it functions the preload function is where you load assets into your game in preload we set the base url to be the phaser server and load png files the create function is empty so its time to fill it in javascript create thisaddimage400 sky const particles thisaddparticles0 red speed scale start end blendmode add const logo thisphysicsaddimage400 logo logosetvelocity100 logosetbounce1 logosetcollideworldboundstrue particlesstartfollowlogo here we add a sky image into the game and create a particle emitter the scale value means that the particles will initially be large and will shrink to nothing as their lifespan progresses after creating the emitter we add a logo image called logo since logo is a physics image logo is given a physics body by default we set some properties for logo velocity bounce or restitution and collision with the world bounds these properties will make our logo bounce around the screen finally we tell the particle emitter to follow the logo so as the logo moves the particles will flow from it run it in your browser and youll see the following phaser demo phaser demo got an error heres the full code this is a tiny example and there are hundreds more for you to explore but hopefully it shows how expressive and quick phaser is to use with just a few easily readable lines of code weve got something pretty impressive up on screen ourcade ourcade have published two great phaser books theyll take you from getting setup through to finishing your first game using modern javascript or typescript and theyre both completely free they also publish a huge range of quality tutorials and videos so be sure to check out their site every week html5 cross platform game development with phaser learn the secrets of html5 game development with phaser while building a cross platform endless runner game designed both for beginners and skilled programmers the course guides you from an empty folder introducing the bare bones of javascript to advanced phaser features find out more details about html5 cross platform game development with phaser building phaser building phaser there are both plain and minified compiled versions of phaser in the dist folder of the repository the plain version is for use during development and the minified version is for production use you can and should also create your own builds custom builds phaser is built using webpack and we take advantage of the webpack defineplugin feature to allow for conditional building of the canvas and webgl renderers and extra plugins you can custom the build process to only include the features you require doing so can cut the main build file size down to just 70kb read our comprehensive guide on creating custom builds of phaser for full details building from source if you wish to build phaser from source ensure you have the required packages by cloning the repository and then running npm install on your source directory you can then run webpack to create a development build in the build folder which includes source maps for local testing you can also npm run dist to create a minified packaged build in the dist folder for a list of all commands available use npm run help change log change log change log due to the increasing size of our change logs we have now split them up one version per folder v3801 change logchangelog3801changelogv3801md v300 to v3800 change logschangelogmd weve organized the change logs into commonly themed sections to make it more digestible but we appreciate there is a lot in there please dont feel overwhelmed if you need clarification about something join us on the phaser discord and ask contributing contributing the contributors guidecontribute contains full details on how to help with phaser development the main points are found a bug report it on github issuesissues and include a code sample please state which version of phaser you are using this is vitally important before submitting a pull request run your code through es lint using our config and respect our editor config before contributing read the code of conduct written something cool in phaser please tell us about it in discord the forumforum or simply email gamesphaserio created by created by phaser is a photon storm and phaser studio inc production storm created by richard daveymailtorichphaserio and the team at phaser studio inc powered by coffee anime pixels and love the phaser logo and characters are copy phaser studio inc all rights reserved above all video games are meant to be just one thing fun fun for everyone satoru iwata getjs getminjs clonehttp clonessh gitgithubcomphaserjsphasergit cloneghwin githubwindowsopenrepo cloneghmac githubmacopenrepo phaser issues examples contribute forum
BabylonJS,Babylon.js,"Babylon.js is a powerful, beautiful, simple, and open game and rendering engine packed into a friendly JavaScript framework.",https://github.com/BabylonJS/Babylon.js,22500,3339,540,89,TypeScript: 19780257; JavaScript: 988832; HLSL: 909157; SCSS: 330094; Roff: 276786; HTML: 96867; Batchfile: 12,3d;babylon;game-development;game-engine;game-engine-3d;typescript;webaudio;webgl;webgl2;webgpu;webvr;webxr,Apache License 2.0,2013-06-27T20:40:42Z,2024-05-02T15:52:59Z,1193654,public,None,master,babylonjs getting started play directly with the babylonjs api using our playground it also contains a lot of samples to learn how to use it npm version build status average time to resolve an issue average time to resolve an issue percentage of issues still open percentage of issues still open build size twitter discourse users any questions here is our official forum cdn warning the cdn should not be used in production environments the purpose of our cdn is to serve babylon packages to users learning how to use the platform or running small experiments once youve built an application and are ready to share it with the world at large you should serve all packages from your own cdn for the preview release use the following urls a list of additional references can be found here npm babylonjs and its modules are published on npm with full typing support to install use text npm install babylonjs save alternatively you can now rely on our es6 packages using the es6 version will allow tree shaking among other bundling benefits this will allow you to import babylonjs entirely using javascript import as babylon from babylonjs or individual classes using javascript import scene engine from babylonjs if using typescript dont forget to add babylonjs to types in tsconfigjson json types babylonjs anotherawesomedependency to add a module install the respective package a list of extra packages and their installation instructions can be found on the babylonjs user on npm usage see getting started javascript get the canvas dom element var canvas documentgetelementbyidrendercanvas load the 3d engine var engine new babylonenginecanvas true preservedrawingbuffer true stencil true createscene function that creates and return the scene var createscene function create a basic bjs scene object var scene new babylonsceneengine create a freecamera and set its position to x y z var camera new babylonfreecameracamera1 new babylonvector30 scene target the camera to scene origin camerasettargetbabylonvector3zero attach the camera to the canvas cameraattachcontrolcanvas false create a basic light aiming meaning to the sky var light new babylonhemisphericlightlight1 new babylonvector30 scene create a builtin sphere shape using the spherebuilder var sphere babylonmeshbuildercreatespheresphere1 segments diameter sideorientation babylonmeshfrontside scene move the sphere upward of its height spherepositiony create a builtin ground shape var ground babylonmeshbuildercreategroundground1 width height subdivisions updatable false scene return the created scene return scene call the createscene function var scene createscene run the render loop enginerunrenderloopfunction scenerender the canvaswindow resize event handler windowaddeventlistenerresize function engineresize contributing if you want to contribute please read our contribution guidelines first documentation documentation demos contributing please see the contributing guidelinescontributingmd useful links official web site wwwbabylonjscom online playground to learn by experimentating online sandbox where you can test your babylon and gltf scenes with a simple dragndrop online shader creation tool where you can learn how to create glsl shaders 3ds max exporter can be used to generate a babylon file from 3ds max maya exporter can be used to generate a babylon file from maya blender exporter can be used to generate a babylon file from blender 3d unity deprecated exporter can be used to export your geometries from unity scene editoranimations are supported gltf tools by khronosgroup features to get a complete list of supported features please visit our website
cocos2d,cocos2d-x,"Cocos2d-x is a suite of open-source, cross-platform, game-development tools utilized by millions of developers across the globe. Its core has evolved to serve as the foundation for Cocos Creator 1.x & 2.x.",https://github.com/cocos2d/cocos2d-x,17898,7042,1229,1604,C++: 23181789; Lua: 1490727; C: 712993; Objective-C++: 561914; Java: 354126; Python: 193394; Objective-C: 173385; CMake: 171835; GLSL: 137481; PLSQL: 26674; Shell: 24403; Makefile: 8965; Csound Document: 8229; PowerShell: 5488; Batchfile: 2270; AIDL: 258; HTML: 86,android;c-plus-plus;cocos2d;cocos2d-x;game-development;game-engine;gamedev;ios;linx;lua;metal;windows,None,2010-11-18T23:17:00Z,2024-05-02T11:19:30Z,988721,public,None,v4,cocos2dx win32others build status status cocos2dx1 is a multiplatform framework for building 2d games interactive books demos and other graphical applications it is based on cocos2diphone but instead of using objectivec it uses c it works on ios android macos windows and linux cocos2dx framework architecture docsframeworkarchitecturev4png cocos2dx is fast free easy to use community supported git user attention clone the repo from github git clone after cloning the repo please execute downloaddepspy to download and install dependencies cd cocos2dx cocos2dx python downloaddepspy after running downloaddepspy cocos2dx git submodule update init download stable versions cocos2dx stable versions documentations and samples all docs in a single place online api reference note that cocos2dx and cocos creator have different api set programmers guide latest release note changelog main features scene management workflow transitions between scenes sprites and sprite sheets effects lens ripple waves liquid etc actions behaviours transformation actions move rotate scale fade tint etc composable actions sequence spawn repeat reverse ease actions exp sin cubic elastic etc misc actions callfunc orbitcamera follow tween basic menus and buttons integrated with physics engines box2d5 and chipmunk6 particle system skeleton animations spine7 and armature support fonts fast font rendering using fixed and variable width fonts support for ttf fonts tile map support orthogonal isometric and hexagonal parallax scrolling motion streak render to texture touchaccelerometer on mobile devices touchmousekeyboard on desktop sound engine support integrated slow motionfast forward fast and compressed textures pvr compressed and uncompressed textures etc1 compressed textures and more resolution independent language c with lua and javascript bindings open source commercial friendlymit compatible with open and closed source projects opengl es mobile opengl desktop metalmacos and ios based build requirements mac os x xcode or ubuntu cmake or windows vs python 275not python ndk r16 is required to build android games android studio to build android gamestested with jre or jdk is required for web publishing runtime requirements ios for iphone ipad games android for android os x v109 for mac games windows for win games environment setup should set up environment before starting a new game or running tests cd cocos2dx setuppy source filetosavesystemvariable should invoke this script if using linux system cd cocos2dx installlinuxdepssh running tests cd cocos2dx mkdir build cd build cocos run projdir p macwin32androidlinuxios how to start a new game cd cocos2dx setuppy source filetosavesystemvariable cocos new mygame p comyourcompanymygame l cpp d newprojectsdir cd newprojectsdirmygame mkdir build cd build cocos run projdir p macwin32androidlinuxios you can also create a lua project with l lua using ide if need to debug program then it is more convinent to use ide to run and debug it all platforms other than android can use cmake to generate corresponding project file can refer to detail cmake guidecmakereadmemd for detail information for android the android studio project file lies in projectdirprojandroid can just use android studio to import the exsting project file learning resources programmers guide android fundamentals games from scratch make school tutorials spreading the word you can help us spread the word about cocos2dx we would surely appreciate it twitter cocosengine facebook youtube weibo cocos bilibili where to get help english forums9 bug tracker api reference latest release note changelog discord channel cpptests project this project is our basis for testing use this project to learn how we implement the functionality of the engine this project is located in cocos2dxrootbuild contributing to the project cocos2dx is licensed under the mit license we welcome participation did you find a bug do you have feature request do you want to merge a feature contributing to cocos2dx8 embrace the future switch to cocos creator for a better experience cocos creator12 is the new generation of cocos game engine with a full featured editor and content creation friendly workflow it supports all major platforms allowing games to be quickly released for the web ios android windows mac and various minigame platforms millions of developers have built 2d 3d experiences from hardcore games to web instant entertainment a pure javascriptdeveloped engine runtime is available on the web and minigame platforms for better performance and smaller packages on other native platforms c is used to implement the underlying framework providing greater operational efficiency the engine is completely open source13 and retains the advantages of cocos2dx which includes high performance customizability ease for debugging easy to learn and small package size therefore we no longer recommend new users to start with cocos2dx instead please use the brandnew cocos creator12 for project development to enjoy the best editor and 3d support cocos2dx box2d chipmunk2d
microsoft,vscode,Visual Studio Code,https://github.com/microsoft/vscode,158462,27673,3287,8440,TypeScript: 57535249; JavaScript: 1031480; CSS: 881674; Rust: 494904; HTML: 386825; Inno Setup: 310714; Scilab: 197909; Shell: 86512; Batchfile: 18574; PowerShell: 13157; SCSS: 6732; Groovy: 3928; Cuda: 3634; C++: 2745; Makefile: 2307; Python: 2171; Perl: 1922; Ruby: 1703; TeX: 1602; Objective-C: 1387; Objective-C++: 1387; Clojure: 1206; Handlebars: 1064; Less: 1029; PHP: 998; Dockerfile: 959; Julia: 940; Jupyter Notebook: 929; Visual Basic .NET: 893; C#: 864; C: 818; Raku: 761; Pug: 654; Go: 652; F#: 634; Java: 599; CoffeeScript: 590; R: 362; Roff: 351; ShaderLab: 330; Dart: 324; Swift: 284; Lua: 252; HLSL: 184; Hack: 16,editor;electron;microsoft;typescript;visual-studio-code,MIT License,2015-09-03T20:23:38Z,2024-05-02T17:22:05Z,912719,public,None,main,visual studio code open source code oss feature requests bugs gitter the repository this repository code oss is where we microsoft develop the visual studio code product together with the community not only do we work on code and issues here we also publish our roadmap monthly iteration plans and our endgame plans this source code is available to everyone under the standard mit license visual studio code visual studio code is a distribution of the code oss repository with microsoftspecific customizations released under a traditional microsoft product license visual studio code combines the simplicity of a code editor with what developers need for their core editbuilddebug cycle it provides comprehensive code editing navigation and understanding support along with lightweight debugging a rich extensibility model and lightweight integration with existing tools visual studio code is updated monthly with new features and bug fixes you can download it for windows macos and linux on visual studio codes website to get the latest releases every day install the insiders build contributing there are many ways in which you can participate in this project for example submit bugs and feature requests and help us verify as they are checked in review source code changes review the documentation and make pull requests for anything from typos to additional and new content if you are interested in fixing issues and contributing directly to the code base please see the document how to contribute which covers the following how to build and run from source the development workflow including debugging and running tests coding guidelines submitting pull requests finding an issue to work on contributing to translations feedback ask a question on stack overflow request a new featurecontributingmd upvote popular feature requests file an issue connect with the extension author community on github discussions or slack follow code and let us know what you think see our wiki for a description of each of these channels and information on some other available communitydriven channels related projects many of the core components and extensions to vs code live in their own repositories on github for example the node debug adapter and the mono debug adapter repositories are separate from each other for a complete list please visit the related projects page on our wiki bundled extensions vs code includes a set of builtin extensions located in the extensionsextensions folder including grammars and snippets for many languages extensions that provide rich language support code completion go to definition for a language have the suffix languagefeatures for example the json extension provides coloring for json and the jsonlanguagefeatures extension provides rich language support for json development container this repository includes a visual studio code dev containers github codespaces development container for dev containers use the dev containers clone repository in container volume command which creates a docker volume for better disk io on macos and windows if you already have vs code and docker installed you can also click here to get started this will cause vs code to automatically install the dev containers extension if needed clone the source code into a container volume and spin up a dev container for use for codespaces install the github codespaces extension in vs code and use the codespaces create new codespace command docker the codespace should have at least cores and gb of ram gb recommended to run full build see the development container readmedevcontainerreadmemd for more information code of conduct this project has adopted the microsoft open source code of conduct for more information see the code of conduct faq or contact opencodemicrosoftcommailtoopencodemicrosoftcom with any additional questions or comments license copyright c microsoft corporation all rights reserved licensed under the mitlicensetxt license
atom,atom,:atom: The hackable text editor,https://github.com/atom/atom,59983,17375,2634,993,JavaScript: 4525809; Less: 445983; CoffeeScript: 142807; Shell: 7778; Batchfile: 2431; Dockerfile: 682; HTML: 336; EJS: 124,atom;editor;electron;javascript;linux;macos;windows,MIT License,2012-01-20T18:18:21Z,2024-05-02T16:47:57Z,330585,public,None,master,atom build status atom and all repositories under atom will be archived on december learn more in our official announcement atom is a hackable text editor for the 21st century built on electron and based on everything we love about our favorite editors we designed it to be deeply customizable but still approachable using the default configuration atom atom screenshot visit atomio to learn more or visit the atom forum follow atomeditor on twitter for important announcements this project adheres to the contributor covenant code of conductcodeofconductmd by participating you are expected to uphold this code please report unacceptable behavior to atomgithubcom documentation if you want to read about using atom or developing packages in atom the atom flight manual is free and available online you can find the source to the manual in atomflightmanualatomio the api reference for developing packages is also documented on atomio installing prerequisites git macos download the latest atom release atom will automatically update when a new release is available windows download the latest atom installer atomsetupexe is 32bit for 64bit systems download atomsetupx64exe atom will automatically update when a new release is available you can also download atomwindowszip 32bit or atomx64windowszip 64bit from the releases page the zip version will not automatically update using chocolatey run cinst atom to install the latest version of atom linux atom is only available for 64bit linux systems configure your distributions package manager to install and update atom by following the linux installation instructions in the flight manual you will also find instructions on how to install atoms official linux packages without using a package repository though you will not get automatic updates after installing atom this way archive extraction an archive is available for people who dont want to install atom as root this version enables you to install multiple atom versions in parallel it has been built on ubuntu 64bit but should be compatible with other linux distributions install dependencies on ubuntu sh sudo apt install git libasound2 libcurl4 libgbm1 libgcrypt20 libgtk30 libnotify4 libnss3 libglib20bin xdgutils libx11xcb1 libxcbdri30 libxss1 libxtst6 libxkbfile1 download atomamd64targz from the atom releases page run tar xf atomamd64targz in the directory where you want to extract the atom folder launch atom using the installed atom command from the newly extracted directory the linux version does not currently automatically update so you will need to repeat these steps to upgrade to future releases building linux macos windows discussion discuss atom on github discussions license mit when using the atom or other github logos be sure to follow the github logo guidelines
sublimehq,sublime_text,Issue tracker for Sublime Text,https://github.com/sublimehq/sublime_text,794,35,55,1845,None,sublime-text;sublime-text-core;sublimehq,None,2013-04-22T12:22:31Z,2024-04-23T07:45:40Z,49,public,None,master,sublime text core bug and issue tracker the issue list head straight to for a list of all issues or click issues in the navigation bar on the almosttop use githubs reactions feature to vote on issues simple comments with no further content will be deleted without notice you can also use labels to filter the list of issues before creating a new issue this tracker is for issues with the sublime text core only this includes packages providing core functionality such as default or color scheme default but excludes packages providing support for syntaxeslanguages for languagespecific issues with the default packages which handle syntax highlighting and other languagerelated things refer to the default packages repository search for the issue here to check if it was already reported you may use labels for filtering the issue list by clicking any of these related to the problem you want to report or request filing a bug start with a descriptive but concise subject that quickly and uniquely identifies the problem write a summary of the problem in a few lines giving an idea of what the issue is about then describe the bug with all the information you can give be sure to include the following information operating system the version of sublime text that youre using any related software which may cause st to act strangely if relevant does the bug occur with no packages installed with st in safe mode also keep in mind to clearly separate fact from speculation try to find a way to reproduce the problem and write down precise steps it might be useful to include a code example for this workarounds or other related tips on how to avoid the issue are welcome we wont slaughter you if you cant fulfill all of these steps but prepare to answer a few questions if we think were lacking information if you want to be really good at reporting bugs you can also read these guidelines for bugzilla bugs filing an enhancement or a feature request start with a descriptive but concise subject that quickly and uniquely identifies the issue explain briefly what the enhancement is and why you think it would be useful provide any other necessary or useful information regarding your issue such as code examples or related links note enhancements are modifications to existing behavior as opposed to something entirely new this bug tracker was initiated by the community and has since been adopted by sublime hq
vim,vim,The official Vim repository,https://github.com/vim/vim,35009,5235,674,1519,Vim Script: 19174325; C: 14153023; Roff: 512382; Makefile: 474965; C++: 238727; NSIS: 180697; M4: 159196; PostScript: 64070; Perl: 63885; Shell: 62268; Module Management System: 55906; Python: 51761; XS: 51261; Ruby: 40269; JavaScript: 37668; NewLisp: 37321; Emacs Lisp: 30216; Java: 29551; SystemVerilog: 27795; Smalltalk: 25674; Awk: 19308; Objective-C: 13147; Batchfile: 12500; DIGITAL Command Language: 10835; Assembly: 5004; KRL: 4206; IDL: 4200; POV-Ray SDL: 2544; MATLAB: 1970; HTML: 1931; sed: 826; Tcl: 745; BitBake: 388; Lua: 166; Prolog: 136,c;cross-platform;text-editor;vim,Vim License,2015-08-18T21:03:56Z,2024-05-02T15:10:39Z,133879,public,None,master,vim the editor github build status appveyor build status cirrus build status coverage status coverity scan debian ci packages fossies codespell report if you find a bug or want to discuss the best way to add a new feature please open an issue if you have a question or want to discuss the best way to do something with vim you can use stackexchange or one of the maillists what is vim vim is a greatly improved version of the good old unix editor vi many new features have been added multilevel undo syntax highlighting command line history online help spell checking filename completion block operations script language etc there is also a graphical user interface gui available still vi compatibility is maintained those who have vi in the fingers will feel at home see runtimedocvidifftxtruntimedocvidifftxt for differences with vi this editor is very useful for editing programs and other plain text files all commands are given with normal keyboard characters so those who can type with ten fingers can work very fast additionally function keys can be mapped to commands by the user and the mouse can be used vim runs under mswindows macos haiku vms and almost all flavours of unix porting to other systems should not be very difficult older versions of vim run on msdos mswindows 9598ment2000xpvista amiga dos atari mint beos risc os and os2 these are no longer maintained for vim9 script see readmevim9readmevim9md distribution you can often use your favorite package manager to install vim on mac and linux a small version of vim is preinstalled you still need to install vim if you want more features there are separate distributions for unix pc amiga and some other systems this readmemd file comes with the runtime archive it includes the documentation syntax files and other files that are used at runtime to run vim you must get either one of the binary archives or a source archive which one you need depends on the system you want to run it on and whether you want or must compile it yourself check for an overview of currently available distributions some popular places to get the latest vim check out the git repository from github get the source code as an archive get a windows executable from the vimwin32installer repository compiling if you obtained a binary distribution you dont need to compile vim if you obtained a source distribution all the stuff for compiling vim is in the srcsrc directory see srcinstallsrcinstall for instructions installation see one of these files for systemspecific instructions either in the readmedir directoryreadmedir in the repository or the top directory if you unpack an archive readmeamitxt amiga readmeunixtxt unix readmedostxt msdos and mswindows readmemactxt macintosh readmehaikutxt haiku readmevmstxt vms there are other readmetxt files depending on the distribution you used documentation the vim tutor is a one hour training course for beginners often it can be started as vimtutor see help tutor for more information the best is to use help in vim if you dont have an executable yet read runtimedochelptxtruntimedochelptxt it contains pointers to the other documentation files the user manual reads like a book and is recommended to learn to use vim see help usermanual copying vim is charityware you can use and copy it as much as you like but you are encouraged to make a donation to help orphans in uganda please read the file runtimedocugandatxtruntimedocugandatxt for details do help uganda inside vim summary of the license there are no restrictions on using or distributing an unmodified copy of vim parts of vim may also be distributed but the license text must always be included for modified versions a few restrictions apply the license is gpl compatible you may compile vim with gpl libraries and distribute it sponsoring fixing bugs and adding new features takes a lot of time and effort to show your appreciation for the work and motivate developers to continue working on vim please send a donation the money you donated will be mainly used to help children in uganda see runtimedocugandatxtruntimedocugandatxt but at the same time donations increase the development team motivation to keep working on vim for the most recent information about sponsoring look on the vim web site contributing if you would like to help make vim better see the contributingmdcontributingmd file information if you are on macos you can use macvim the latest news about vim can be found on the vim home page if you have problems have a look at the vim documentation or tips if you still have problems or any other questions use one of the mailing lists to discuss them with vim users and developers if nothing else works report bugs directly to the vimdev mailing list main author most of vim was created by bram moolenaar brammoolenaar send any other comments patches flowers and suggestions to the vimdev mailing list this is readmemd for version of vim vi improved
emacs-mirror,emacs,Mirror of GNU Emacs,https://github.com/emacs-mirror/emacs,4247,1261,261,15,Emacs Lisp: 69363597; Roff: 30192357; C: 20713934; M4: 918087; Objective-C: 719582; TeX: 568638; C++: 566403; Makefile: 493645; Java: 400273; Shell: 286394; PostScript: 155594; Mathematica: 138829; Perl: 132967; HTML: 98964; Ruby: 98654; Python: 97104; Mercury: 80392; Pascal: 75359; Prolog: 72589; MATLAB: 70571; JavaScript: 66050; NewLisp: 54116; SystemVerilog: 51348; Slash: 49281; SRecode Template: 49014; Smalltalk: 47140; GDB: 42394; Yacc: 40928; Awk: 39614; Ada: 39126; Assembly: 34155; PHP: 33630; Batchfile: 18464; Lua: 14918; Fortran: 12354; Erlang: 11862; SmPL: 9916; Hack: 3431; Raku: 2506; NSIS: 2152; SCSS: 2016; CSS: 1857; Forth: 1388; Rust: 1002; Modula-2: 890; Tcl: 876; Less: 718; Scheme: 659; Go: 503,,GNU General Public License v3.0,2014-08-07T06:58:17Z,2024-05-02T16:52:40Z,1478145,public,None,master,copyright c free software foundation inc see the end of the file for license conditions this directory tree holds version of gnu emacs the extensible customizable selfdocumenting realtime display editor the file install in this directory says how to build and install gnu emacs on various systems once you have unpacked or checked out the entire emacs file tree see the file etcnews for information on new features and other uservisible changes in recent versions of emacs the file etcproblems contains information on many common problems that occur in building installing and running emacs the file contribute contains information on contributing to emacs as a developer you may encounter bugs in this release if you do please report them your bug reports are valuable contributions to the fsf since they allow us to notice and fix problems on machines we dont have or in code we dont use often please send bug reports to the mailing list buggnuemacsgnuorg if possible use mx reportemacsbug see the bugs section of the emacs manual for more information on how to report bugs the file bugs in this directory explains how you can find and read that section using the info files that come with emacs for a list of mailing lists related to emacs see for the complete list of gnu mailing lists see the etc subdirectory contains several other files named in capital letters which you might consider looking at when installing gnu emacs the file configure is a shell script to acclimate emacs to the oddities of your processor and operating system it creates the file makefile a script for the make program which automates the process of building and installing emacs see install for more detailed information the file configureac is the input used by the autoconf program to construct the configure script the shell script autogensh generates configure and other files by running autoconf which in turn uses gnu m4 and configures files in the git subdirectory if you are using git if you want to use it you will need to install recent versions of these build tools this should be needed only if you edit files like configureac that specify emacss autobuild procedure the file makefilein is a template used by configure to create makefile the file makedist is a shell script to build a distribution tar file from the current emacs tree containing only those files appropriate for distribution if you make extensive changes to emacs this script will help you distribute your version to others there are several subdirectories src holds the c code for emacs the emacs lisp interpreter and its primitives the redisplay code and some basic editing functions lisp holds the emacs lisp code for emacs most everything else leim holds the original source files for the generated files in lispleim these form the library of emacs input methods required to type international characters that cant be directly produced by your keyboard lib holds source code for libraries used by emacs and its utilities libsrc holds the source code for some utility programs for use by or with emacs like movemail and etags lwlib holds the sources of the lucid widget library used on x oldxmenu source files from x11r2 xmenu library used in nontoolkit builds etc holds miscellaneous architectureindependent data files emacs uses like the tutorial text and tool bar images the contents of the lisp leim info and doc subdirectories are architectureindependent too info holds the info documentation tree for emacs docemacs holds the source code for the emacs manual if you modify the manual sources you will need the makeinfo program to produce an updated manual makeinfo is part of the gnu texinfo package you need a suitably recent version of texinfo doclispref holds the source code for the emacs lisp reference manual doclispintro holds the source code for the introduction to programming in emacs lisp manual msdos holds configuration files for compiling emacs under msdos nextstep holds instructions and some other files for compiling the nextstep port of emacs for gnustep and macos cocoa nt holds code and documentation for building emacs on mswindows test holds tests for various aspects of emacss functionality modules holds the modhelppy helper script admin holds files used by emacs developers and unicode data files buildaux holds auxiliary files used during the build m4 holds autoconf macros used for generating the configure script java holds the java code for the emacs port to android cross holds makefiles and an additional copy of gnulib used to build emacs for android devices exec holds the source code to several helper executables used to run userinstalled programs on android building emacs on nonposix platforms requires tools that arent part of the standard distribution of the os the platformspecific readme files and installation instructions should list the required tools note on copyright years in copyright notices where the copyright holder is the free software foundation then where a range of years appears this is an inclusive range that applies to every year in the range for example represents the years and this file is part of gnu emacs gnu emacs is free software you can redistribute it andor modify it under the terms of the gnu general public license as published by the free software foundation either version of the license or at your option any later version gnu emacs is distributed in the hope that it will be useful but without any warranty without even the implied warranty of merchantability or fitness for a particular purpose see the gnu general public license for more details you should have received a copy of the gnu general public license along with gnu emacs if not see
adobe,brackets,"An open source code editor for the web, written in JavaScript, HTML and CSS.",https://github.com/adobe/brackets,33290,7668,1568,2786,JavaScript: 13258040; HTML: 2065660; Less: 218278; CSS: 187807; PHP: 27024; Shell: 12541; Ruby: 9040; SCSS: 5072; Batchfile: 2667; Hack: 2646; Makefile: 2186; Handlebars: 872; Clojure: 28,,MIT License,2011-12-07T21:14:40Z,2024-05-02T11:00:09Z,92974,public,None,master,warning on september adobe will end support for brackets if you would like to continue using maintaining and improving brackets you may fork the project on github through adobes partnership with microsoft we encourage users to migrate to visual studio code microsofts free code editor built on open source welcome to brackets build status brackets is a modern opensource code editor for html css and javascript thats built in html css and javascript what makes brackets different from other web code editors tools shouldnt get in your way instead of cluttering up your coding environment with lots of panels and icons the quick edit ui in brackets puts contextspecific code and tools inline brackets is in sync with your browser with live preview brackets works directly with your browser to push code edits instantly and jump back and forth between your real source code and the browser view do it yourself because brackets is open source and built with html css and javascript you can help build the best code editor for the web brackets may have reached version but were not stopping there we have many feature ideas on our trello board that were anxious to add and other innovative web development workflows that were planning to build into brackets so take brackets out for a spin and let us know how we can make it your favorite editor you can see some screenshots of brackets on the wiki intro videos on youtube and news on the brackets blog how to install and run brackets download installers for the latest stable build for mac windows and linux debianubuntu can be downloaded here usage by default brackets opens a folder containing some simple getting started content you can choose a different folder to edit using file open folder most of brackets should be pretty selfexplanatory but for information on how to use its unique features like quick edit and live preview please read how to use brackets also see the release notes for a list of new features and known issues in each build in addition to the core features built into brackets there is a large and growing community of developers building extensions that add all sorts of useful functionality see the brackets extension registry for a list of available extensions for installation instructions see the extensions wiki page need help having problems starting brackets the first time or not sure how to use brackets please review troubleshooting which helps you to fix common problems and find extra help if needed helping brackets i found a bug if you found a repeatable bug and troubleshooting tips didnt help then be sure to search existing issues first include steps to consistently reproduce the problem actual vs expected results screenshots and your os and brackets version number disable all extensions to verify the issue is a core brackets bug read more guidelines for filing good bugs i have a new suggestion but dont know how to program for feature requests please first check our trello board to see if its already there you can upvote it if so if not feel free to file it as an issue as above well move it to the feature backlog for you i want to help with the code awesome there are lots of ways you can help first read contributingmd then learn how to pull the repo and hack on brackets the text editor inside brackets is based on codemirror to marijn for taking our pull requests implementing feature requests and fixing bugs see notes on codemirror for info on how were using codemirror although brackets is built in htmlcssjs it currently runs as a desktop application in a thin native shell so that it can access your local files if you just try to open the indexhtml file in a browser it wont work yet the native shell for brackets lives in a separate repo adobebracketsshell i want to keep track of how brackets is doing not sure you needed the exclamation point there but we like your enthusiasm whats brackets working on next in our feature backlog the columns to the right starting from development list the features that were currently working on ready shows what well be working on next watch our github activity stream watch our waffle kanban board work items in stories in ready are next the entire development process is outlined in the developer guide contact info email adminbracketsiomailtoadminbracketsio slack brackets on slack you can join by sending a mail to adminbracketsiomailtoadminbracketsio with the subject line slack registration request specifying the email addresses you would like to register developers mailing list twitter brackets blog irc brackets on freenode please note that this project is released with a contributor code of conduct by participating in this project you agree to abide by its terms
bitcoin,bitcoin,Bitcoin Core integration/staging tree,https://github.com/bitcoin/bitcoin,76123,35334,3990,692,C++: 11764804; Python: 3655633; C: 1957481; M4: 211469; Shell: 185545; Makefile: 146759; CMake: 59971; Sage: 59399; Assembly: 28405; Scheme: 22230; HTML: 21833; Rust: 10514; Objective-C++: 5497; Dockerfile: 4777; Cap'n Proto: 1867; Java: 541; QMake: 438,bitcoin;c-plus-plus;cryptocurrency;cryptography;p2p,MIT License,2010-12-19T15:16:43Z,2024-05-02T16:47:33Z,257965,public,None,master,bitcoin core integrationstaging tree for an immediately usable binary version of the bitcoin core software see what is bitcoin core bitcoin core connects to the bitcoin peertopeer network to download and fully validate blocks and transactions it also includes a wallet and graphical user interface which can be optionally built further information about bitcoin core is available in the doc folderdoc license bitcoin core is released under the terms of the mit license see copyingcopying for more information or see development process the master branch is regularly built see docbuildmd for instructions and tested but it is not guaranteed to be completely stable tags are created regularly from release branches to indicate new official stable release versions of bitcoin core the repository is used exclusively for the development of the gui its master branch is identical in all monotree repositories release branches and tags do not exist so please do not fork that repository unless it is for development reasons the contribution workflow is described in contributingmdcontributingmd and useful hints for developers can be found in docdevelopernotesmddocdevelopernotesmd testing testing and code review is the bottleneck for development we get more pull requests than we can review and test on short notice please be patient and help out by testing other peoples pull requests and remember this is a securitycritical project where any mistake might cost people lots of money automated testing developers are strongly encouraged to write unit testssrctestreadmemd for new code and to submit new unit tests for old code unit tests can be compiled and run assuming they werent disabled in configure with make check further details on running and extending unit tests can be found in srctestreadmemdsrctestreadmemd there are also regression and integration teststest written in python these tests can be run if the test dependenciestest are installed with testfunctionaltestrunnerpy the ci continuous integration systems make sure that every pull request is built for windows linux and macos and that unitsanity tests are run automatically manual quality assurance qa testing changes should be tested by somebody other than the developer who wrote the code this is especially important for large or highrisk changes it is useful to add a test plan to the pull request description if testing the changes is not straightforward translations changes to translations as well as new translations can be submitted to bitcoin cores transifex page translations are periodically pulled from transifex and merged into the git repository see the translation processdoctranslationprocessmd for details on how this works important we do not accept translation changes as github pull requests because the next pull from transifex would automatically overwrite them again
ethereum,go-ethereum,Go implementation of the Ethereum protocol,https://github.com/ethereum/go-ethereum,46167,19430,2202,347,Go: 11176895; C: 673770; JavaScript: 444954; Assembly: 63663; Shell: 31428; Java: 30290; Sage: 30191; M4: 25931; NSIS: 23197; Python: 11233; Solidity: 9568; Makefile: 8529; HTML: 1121; Dockerfile: 898,blockchain;ethereum;geth;go;p2p,GNU Lesser General Public License v3.0,2013-12-26T13:05:46Z,2024-05-02T17:19:44Z,207540,public,None,master,go ethereum golang execution layer implementation of the ethereum protocol api reference go report card travis discord automated builds are available for stable releases and the unstable master branch binary archives are published at building the source for prerequisites and detailed build instructions please read the installation instructions building geth requires both a go version or later and a c compiler you can install them using your favourite package manager once the dependencies are installed run shell make geth or to build the full suite of utilities shell make all executables the goethereum project comes with several wrappersexecutables found in the cmd directory command description geth our main ethereum cli client it is the entry point into the ethereum network main test or private net capable of running as a full node default archive node retaining all historical state or a light node retrieving data live it can be used by other processes as a gateway into the ethereum network via json rpc endpoints exposed on top of http websocket andor ipc transports geth help and the cli page for command line options clef standalone signing tool which can be used as a backend signer for geth devp2p utilities to interact with nodes on the networking layer without running a full blockchain abigen source code generator to convert ethereum contract definitions into easytouse compiletime typesafe go packages it operates on plain ethereum contract abis with expanded functionality if the contract bytecode is also available however it also accepts solidity source files making development much more streamlined please see our native dapps page for details bootnode stripped down version of our ethereum client implementation that only takes part in the network node discovery protocol but does not run any of the higher level application protocols it can be used as a lightweight bootstrap node to aid in finding peers in private networks evm developer utility version of the evm ethereum virtual machine that is capable of running bytecode snippets within a configurable environment and execution mode its purpose is to allow isolated finegrained debugging of evm opcodes eg evm code 60ff60ff debug run rlpdump developer utility tool to convert binary rlp recursive length prefix dumps data encoding used by the ethereum protocol both network as well as consensus wise to userfriendlier hierarchical representation eg rlpdump hex ce0183ffffffc4c304050583616263 running geth going through all the possible command line flags is out of scope here please consult our cli wiki page but weve enumerated a few common parameter combos to get you up to speed quickly on how you can run your own geth instance hardware requirements minimum cpu with cores 4gb ram 1tb free storage space to sync the mainnet mbitsec download internet service recommended fast cpu with cores 16gb ram highperformance ssd with at least 1tb of free space mbitsec download internet service full node on the main ethereum network by far the most common scenario is people wanting to simply interact with the ethereum network create accounts transfer funds deploy and interact with contracts for this particular use case the user doesnt care about yearsold historical data so we can sync quickly to the current state of the network to do so shell geth console this command will start geth in snap sync mode default can be changed with the syncmode flag causing it to download more data in exchange for avoiding processing the entire history of the ethereum network which is very cpu intensive start the builtin interactive javascript console via the trailing console subcommand through which you can interact using web3 methods note the web3 version bundled within geth is very old and not up to date with official docs as well as geths own management apis this tool is optional and if you leave it out you can always attach it to an already running geth instance with geth attach a full node on the grli test network transitioning towards developers if youd like to play around with creating ethereum contracts you almost certainly would like to do that without any real money involved until you get the hang of the entire system in other words instead of attaching to the main network you want to join the test network with your node which is fully equivalent to the main network but with playether only shell geth goerli console the console subcommand has the same meaning as above and is equally useful on the testnet too specifying the goerli flag however will reconfigure your geth instance a bit instead of connecting to the main ethereum network the client will connect to the grli test network which uses different p2p bootnodes different network ids and genesis states instead of using the default data directory ethereum on linux for example geth will nest itself one level deeper into a goerli subfolder ethereumgoerli on linux note on osx and linux this also means that attaching to a running testnet node requires the use of a custom endpoint since geth attach will try to attach to a production node endpoint by default eg geth attach goerligethipc windows users are not affected by this note although some internal protective measures prevent transactions from crossing over between the main network and test network you should always use separate accounts for play and real money unless you manually move accounts geth will by default correctly separate the two networks and will not make any accounts available between them configuration as an alternative to passing the numerous flags to the geth binary you can also pass a configuration file via shell geth config pathtoyourconfigtoml to get an idea of how the file should look like you can use the dumpconfig subcommand to export your existing configuration shell geth yourfavouriteflags dumpconfig note this works only with geth v160 and above docker quick start one of the quickest ways to get ethereum up and running on your machine is by using docker shell docker run d name ethereumnode v usersaliceethereumroot p p ethereumclientgo this will start geth in snapsync mode with a db memory allowance of 1gb as the above command does it will also create a persistent volume in your home directory for saving your blockchain as well as map the default ports there is also an alpine tag available for a slim version of the image do not forget httpaddr if you want to access rpc from other containers andor hosts by default geth binds to the local interface and rpc endpoints are not accessible from the outside programmatically interfacing geth nodes as a developer sooner rather than later youll want to start interacting with geth and the ethereum network via your own programs and not manually through the console to aid this geth has builtin support for a jsonrpc based apis standard apis and geth specific apis these can be exposed via http websockets and ipc unix sockets on unix based platforms and named pipes on windows the ipc interface is enabled by default and exposes all the apis supported by geth whereas the http and ws interfaces need to manually be enabled and only expose a subset of apis due to security reasons these can be turned onoff and configured as youd expect http based jsonrpc api options http enable the httprpc server httpaddr httprpc server listening interface default localhost httpport httprpc server listening port default httpapi apis offered over the httprpc interface default ethnetweb3 httpcorsdomain comma separated list of domains from which to accept cross origin requests browser enforced ws enable the wsrpc server wsaddr wsrpc server listening interface default localhost wsport wsrpc server listening port default wsapi apis offered over the wsrpc interface default ethnetweb3 wsorigins origins from which to accept websocket requests ipcdisable disable the ipcrpc server ipcapi apis offered over the ipcrpc interface default admindebugethminernetpersonaltxpoolweb3 ipcpath filename for ipc socketpipe within the datadir explicit paths escape it youll need to use your own programming environments capabilities libraries tools etc to connect via http ws or ipc to a geth node configured with the above flags and youll need to speak jsonrpc on all transports you can reuse the same connection for multiple requests note please understand the security implications of opening up an httpws based transport before doing so hackers on the internet are actively trying to subvert ethereum nodes with exposed apis further all browser tabs can access locally running web servers so malicious web pages could try to subvert locally available apis operating a private network maintaining your own private network is more involved as a lot of configurations taken for granted in the official networks need to be manually set up defining the private genesis state first youll need to create the genesis state of your networks which all nodes need to be aware of and agree upon this consists of a small json file eg call it genesisjson json config chainid homesteadblock eip150block eip155block eip158block byzantiumblock constantinopleblock petersburgblock istanbulblock berlinblock londonblock alloc coinbase difficulty extradata gaslimit nonce mixhash parenthash timestamp the above fields should be fine for most purposes although wed recommend changing the nonce to some random value so you prevent unknown remote nodes from being able to connect to you if youd like to prefund some accounts for easier testing create the accounts and populate the alloc field with their addresses json alloc balance balance with the genesis state defined in the above json file youll need to initialize every geth node with it prior to starting it up to ensure all blockchain parameters are correctly set shell geth init pathtogenesisjson creating the rendezvous point with all nodes that you want to run initialized to the desired genesis state youll need to start a bootstrap node that others can use to find each other in your network andor over the internet the clean way is to configure and run a dedicated bootnode shell bootnode genkeybootkey bootnode nodekeybootkey with the bootnode online it will display an enode url that other nodes can use to connect to it and exchange peer information make sure to replace the displayed ip address information most probably with your externally accessible ip to get the actual enode url note you could also use a fullfledged geth node as a bootnode but its the less recommended way starting up your member nodes with the bootnode operational and externally reachable you can try telnet to ensure its indeed reachable start every subsequent geth node pointed to the bootnode for peer discovery via the bootnodes flag it will probably also be desirable to keep the data directory of your private network separated so do also specify a custom datadir flag shell geth datadirpathtocustomdatafolder bootnodes note since your network will be completely cut off from the main and test networks youll also need to configure a miner to process transactions and create new blocks for you running a private miner in a private network setting a single cpu miner instance is more than enough for practical purposes as it can produce a stable stream of blocks at the correct intervals without needing heavy resources consider running on a single thread no need for multiple ones either to start a geth instance for mining run it with all your usual flags extended by shell geth mine minerthreads1 mineretherbase0x0000000000000000000000000000000000000000 which will start mining blocks and transactions on a single cpu thread crediting all proceedings to the account specified by mineretherbase you can further tune the mining by changing the default gas limit blocks converge to minertargetgaslimit and the price transactions are accepted at minergasprice contribution thank you for considering helping out with the source code we welcome contributions from anyone on the internet and are grateful for even the smallest of fixes if youd like to contribute to goethereum please fork fix commit and send a pull request for the maintainers to review and merge into the main code base if you wish to submit more complex changes though please check up with the core devs first on our discord server to ensure those changes are in line with the general philosophy of the project andor get some early feedback which can make both your efforts much lighter as well as our review and merge procedures quick and simple please make sure your contributions adhere to our coding guidelines code must adhere to the official go formatting guidelines ie uses gofmt code must be documented adhering to the official go commentary guidelines pull requests need to be based on and opened against the master branch commit messages should be prefixed with the packages they modify eg eth rpc make trace configs optional please see the developers guide for more details on configuring your environment managing project dependencies and testing procedures contributing to gethethereumorg for contributions to the goethereum website please checkout and raise pull requests against the website branch for more detailed instructions please see the website branch readme or the contributing page of the website license the goethereum library ie all code outside of the cmd directory is licensed under the gnu lesser general public license v30 also included in our repository in the copyinglesser file the goethereum binaries ie all code inside of the cmd directory are licensed under the gnu general public license v30 also included in our repository in the copying file
ripple,rippled,Decentralized cryptocurrency blockchain daemon implementing the XRP Ledger protocol in C++,https://github.com/XRPLF/rippled,4463,1431,505,376,C++: 13375759; CMake: 101219; JavaScript: 34939; Shell: 23382; C: 16382; Python: 12932,blockchain;c-plus-plus;cplusplus;cryptography;xrp;xrp-ledger;xrpl,ISC License,2011-11-07T04:40:15Z,2024-05-02T15:15:04Z,1088793,public,None,develop,the xrp ledger the xrp ledger is a decentralized cryptographic ledger powered by a network of peertopeer nodes the xrp ledger uses a novel byzantine fault tolerant consensus algorithm to settle and record transactions in a secure distributed database without a central operator xrp xrp is a public counterpartyfree asset native to the xrp ledger and is designed to bridge the many different currencies in use worldwide xrp is traded on the openmarket and is available for anyone to access the xrp ledger was created in with a finite supply of billion units of xrp rippled the server software that powers the xrp ledger is called rippled and is available in this repository under the permissive isc opensource licenselicensemd the rippled server software is written primarily in c and runs on a variety of platforms the rippled server software can run in several modes depending on its configuration if you are interested in running an api server including a full history server or a reporting mode server take a look at clio rippled reporting mode is expected to be replaced by clio build from source read the build instructions in buildmdbuildmd if you encounter any issues please open an issue key features of the xrp ledger censorshipresistant transaction processing no single party decides which transactions succeed or fail and no one can roll back a transaction after it completes as long as those who choose to participate in the network keep it healthy they can settle transactions in seconds fast efficient consensus algorithm the xrp ledgers consensus algorithm settles transactions in to seconds processing at a throughput of up to transactions per second these properties put xrp at least an order of magnitude ahead of other top digital assets finite xrp supply when the xrp ledger began billion xrp were created and no more xrp will ever be created the available supply of xrp decreases slowly over time as small amounts are destroyed to pay transaction costs responsible software governance a team of fulltime worldclass developers at ripple maintain and continually improve the xrp ledgers underlying software with contributions from the opensource community ripple acts as a steward for the technology and an advocate for its interests and builds constructive relationships with governments and financial institutions worldwide secure adaptable cryptography the xrp ledger relies on industry standard digital signature systems like ecdsa the same scheme used by bitcoin but also supports modern efficient algorithms like ed25519 the extensible nature of the xrp ledgers software makes it possible to add and disable algorithms as the state of the art in cryptography advances modern features for smart contracts features like escrow checks and payment channels support cuttingedge financial applications including the interledger protocol this toolbox of advanced features comes with safety features like a process for amending the network and separate checks against invariant constraints onledger decentralized exchange in addition to all the features that make xrp useful on its own the xrp ledger also has a fullyfunctional accounting system for tracking and trading obligations denominated in any way users want and an exchange built into the protocol the xrp ledger can settle long crosscurrency payment paths and exchanges of multiple currencies in atomic transactions bridging gaps of trust with xrp censorshipresistant transaction processing fast efficient consensus algorithm finite xrp supply responsible software governance secure adaptable cryptography modern features for smart contracts onledger decentralized exchange source code here are some good places to start learning the source code read the markdown files in the source tree srcripplemd read the levelization documentbuildslevelization to get an idea of the internal dependency graph in the big picture the main function constructs an applicationimp object which implements the application virtual interface almost every component in the application takes an application parameter in its constructor typically named app and stored as a member variable app this allows most components to depend on any other component repository contents folder contents bin scripts and data files for ripple integrators builds platformspecific guides for building rippled docs source documentation files and doxygen config cfg example configuration files src source code some of the directories under src are external repositories included using gitsubtree see those directories readme files for more details additional documentation xrp ledger dev portal setup and installation source documentation doxygen see also clio api server for the xrp ledger mailing list for release announcements learn more about the xrp ledger youtube
litecoin-project,litecoin,Litecoin source tree,https://github.com/litecoin-project/litecoin,4322,3020,502,58,C++: 8901337; Python: 2301604; C: 1600400; Assembly: 898000; M4: 226027; Shell: 150347; Makefile: 125447; Sage: 31382; Java: 30291; CMake: 29310; HTML: 21833; Scheme: 7554; Objective-C++: 5489; QMake: 798,cryptocurrency;litecoin,MIT License,2012-06-13T04:18:26Z,2024-05-01T10:19:29Z,231616,public,bitcoin/bitcoin,master,litecoin core integrationstaging tree build status what is litecoin litecoin is an experimental digital currency that enables instant payments to anyone anywhere in the world litecoin uses peertopeer technology to operate with no central authority managing transactions and issuing money are carried out collectively by the network litecoin core is the name of open source software which enables the use of this currency for more information as well as an immediately useable binary version of the litecoin core software see license litecoin core is released under the terms of the mit license see copyingcopying for more information or see development process the master branch is regularly built see docbuildmd for instructions and tested but it is not guaranteed to be completely stable tags are created regularly from release branches to indicate new official stable release versions of litecoin core the repository is used exclusively for the development of the gui its master branch is identical in all monotree repositories release branches and tags do not exist so please do not fork that repository unless it is for development reasons the contribution workflow is described in contributingmdcontributingmd and useful hints for developers can be found in docdevelopernotesmddocdevelopernotesmd the developer mailing list should be used to discuss complicated or controversial changes before working on a patch set developer irc can be found on freenode at litecoindev testing testing and code review is the bottleneck for development we get more pull requests than we can review and test on short notice please be patient and help out by testing other peoples pull requests and remember this is a securitycritical project where any mistake might cost people lots of money automated testing developers are strongly encouraged to write unit testssrctestreadmemd for new code and to submit new unit tests for old code unit tests can be compiled and run assuming they werent disabled in configure with make check further details on running and extending unit tests can be found in srctestreadmemdsrctestreadmemd there are also regression and integration teststest written in python that are run automatically on the build server these tests can be run if the test dependenciestest are installed with testfunctionaltestrunnerpy the travis ci system makes sure that every pull request is built for windows linux and macos and that unitsanity tests are run automatically manual quality assurance qa testing changes should be tested by somebody other than the developer who wrote the code this is especially important for large or highrisk changes it is useful to add a test plan to the pull request description if testing the changes is not straightforward translations we only accept translation fixes that are submitted through bitcoin cores transifex page translations are converted to litecoin periodically translations are periodically pulled from transifex and merged into the git repository see the translation processdoctranslationprocessmd for details on how this works important we do not accept translation changes as github pull requests because the next pull from transifex would automatically overwrite them again
input-output-hk,cardano-node,The core component that is used to participate in a Cardano decentralised blockchain.,https://github.com/IntersectMBO/cardano-node,3020,717,197,360,Haskell: 3796930; Shell: 774356; Nix: 362045; jq: 80235; JSONiq: 32888; Python: 23924; C: 13867; Makefile: 12751; Emacs Lisp: 4731; Gnuplot: 3388,,Apache License 2.0,2019-05-23T20:12:22Z,2024-05-02T16:11:34Z,125119,public,None,master,raw html github actions contents contents overview of the cardanonode repository integration of the ledger consensus networking and node shell repositories logging is provided as a feature by the node shell to the other packages the cardanonode is the top level for the node and aggregates the other components from other packages consensus ledger and networking with configuration cli logging and monitoring the node no longer incorporates wallet or explorer functionality the wallet backend and explorer backend are separate components that run in separate external processes that communicate with the node via local ipc network configuration genesis and topology files the latest supported networks can be found at obtaining cardanonode building from source documentation for building the node can be found here executables you can download the hydra binaries of cardanonode and cardanocli from the release notes running the node on windows the download includes cardanonodeexe and a dll to run the node with cardanonode run you need to reference a few files and directories as arguments these can be copied from the cardanonode repo into the executables directory the command to run the node on mainnet looks like this codeblock console cardanonodeexe run topology configurationcardanomainnettopologyjson databasepath state port config configurationcardanomainnetconfigyaml socketpath pipecardanonode docker image you can pull the docker image with the latest version of cardanonode from here codeblock console docker pull ghcriointersectmbocardanonode891 using cardanonode command line summary cardanonode this refers to the client that is used for running a node the general synopsis is as follows codeblock console usage cardanonode run topology filepath databasepath filepath socketpath filepath byrondelegationcertificate filepath byronsigningkey filepath shelleykeskey filepath shelleyvrfkey filepath shelleyoperationalcertificate filepath startasnonproducingnode hostaddr ipv4address hostipv6addr ipv6address port port config nodeconfiguration validatedb run the node topology filepath to a topology file describing which peers the node should connect to databasepath path to the blockchain database byrondelegationcertificate optional path to the byron delegation certificate the delegation certificate allows the delegator the issuer of said certificate to give hisher own block signing rights to somebody else the delegatee the delegatee can then sign blocks on behalf of the delegator byronsigningkey optional path to the byron signing key shelleysigningkey optional path to the shelley signing key shelleykeskey optional path to the shelley kes signing key shelleyvrfkey optional path to the shelley vrf signing key shelleyoperationalcertificate optional path to the shelley operational certificate startasnonproducingnode optional flag to disable block production on node start if credentials flags are passed the node will start block producing however with this flag the node will only start block producing on sighup see here for more details socketpath path to the socket file hostaddr optionally specify your nodes ipv4 address hostipv6addr optionally specify your nodes ipv6 address port specify which port to assign to the node config specify the filepath to the config yaml file this file is responsible for all the other nodes required settings see examples in configuration eg config0yaml validatedb flag to revalidate all ondisk database files configuration the config flag points to a yaml or a structurally equivalent json file that is responsible to configuring the logging other important settings for the node eg see the byron mainnet configuration in this configurationyaml some of the more important settings are as follows protocol realpbft protocol the node will execute requiresnetworkmagic requiresnomagic used to distinguish between mainnet requiresnomagic and testnets requiresmagic scripts please see scriptsreadmemd for information on the various scripts using cardanocli a cli utility to support a variety of key material operations genesis migration prettyprinting for different system generations usage documentation can be found at the general synopsis is as follows codeblock console usage cardanocli era based commands byron specific commands miscellaneous commands note the exact invocation command depends on the environment if you have only built cardanocli without installing it then you have to prepend cabal run before cardanocli we henceforth assume that the necessary environmentspecific adjustment has been made so we only mention cardanocli command line options cardanocli the subcommands are subdivided in groups and their full list can be seen in the output of cardanocli help all subcommands have help available for example codeblock console cabal run cardanocli byron key migratedelegatekeyfrom help cardanocli byron key migratedelegatekeyfrom usage cardanocli byron key migratedelegatekeyfrom from filepath to filepath migrate a delegate key from an older version available options byronlegacyformats byroncardanosl formats and compatibility byronformats byron era formats and compatibility from filepath signing key file to migrate to filepath nonexistent file to write the signing key to hhelp show this help text genesis generation the byron genesis generation operations will create a directory that contains genesisjson the genesis json file itself avvmseedseed ada voucher vending machine seeds secret affected by avvmentrycount and avvmentrybalance delegatekeyskey delegate private keys affected by ndelegateaddresses delegationcertjson delegation certificates affected by ndelegateaddresses genesiskeyskey genesis stake private keys affected by ndelegateaddresses totalbalance poorkeyskey nondelegate private keys with genesis utxo affected by npooraddresses totalbalance more details on the byron genesis json file can be found in byron genesis delegation and related concepts are described in detail in the canned scriptsbenchmarkinggenesissh example provides a nice set of defaults and illustrates available options key operations note that key operations do not support passwordprotected keys signing key generation verification key extraction signing keys can be generated using the keygen subcommand extracting a verification key out of the signing key is performed by the toverification subcommand delegate key migration in order to continue using a delegate key from the byron legacy era in the new implementation it needs to be migrated over which is done by the migratedelegatekeyfrom subcommand codeblock console cabal v2run cardanocli byron key migratedelegatekeyfrom from key0sk to key0convertedsk signing key queries one can gather information about a signing keys properties through the signingkeypublic and signingkeyaddress subcommands the latter requires the network magic codeblock console cabal v2run cardanocli byron key signingkeypublic byronformats secret key0sk public key hash a2b1af0df8ca764876a45608fae36cf04400ed9f413de2e37d92ce04 public key sc4pa1parixo7izmpbyko4cg90hcfd465iad284udyz06dhcqbwmhrukreq90tavqpj4l1ynalhi7ds0z2vg cabal v2run cardanocli signingkeyaddress byronformats secret key0pbft testnetmagic 2cwkmjemobakxhxgzssmtelp9tuvz7owhyeybudwkrlsw2ugdrg93gpqmpv1d9ohwnddx verkey address with root e5a3807d99a1807c3f161a1558bcbc45de8392e049682df01809c488 attributes addrattributes derivation path transactions creation transactions can be created via the issuegenesisutxoexpenditure issueutxoexpenditure commands the easiest way to create a transaction is via the scriptsbenchmarkingissuegenesisutxoexpendituresh script as follows scriptsbenchmarkingissuegenesisutxoexpendituresh transactionfile nb this by default creates a transaction based on configurationdefaultsliveviewconfig0yaml if you do not have a genesisfile you can run scriptsbenchmarkinggenesissh which will create an example genesisfile for you the script scriptsbenchmarkingissuegenesisutxoexpendituresh has defaults for all the requirements of the issuegenesisutxoexpenditure command submission the submittx subcommand provides the option of submitting a presigned transaction in its raw wire format see gentx for byron transactions the canned scriptsbenchmarkingsubmittxsh script will submit the supplied transaction to a testnet launched by scriptsbenchmarkingshelleytestnetliveviewsh script issuing utxo expenditure genesis and regular to make a transaction spending utxo you can either use the issuegenesisutxoexpenditure for genesis utxo issueutxoexpenditure for normal utxo subcommands directly or again use canned scripts that will make transactions tailored for the aforementioned testnet cluster scriptsbenchmarkingissuegenesisutxoexpendituresh scriptsbenchmarkingissueutxoexpendituresh the script requires the target file name to write the transaction to input txid for normal utxo and optionally allows specifying the source txin output index source and target signing keys and lovelace value to send the target address defaults to the 1st richman key configurationdelegatekeys001key of the testnet and lovelace amount is almost the entirety of its funds local node queries you can query the tip of your local node via the gettip command as follows open tmux run cabal build cardanonode run scriptsliteshelleytestnetsh example run export cardanonodesocketpathcardanonodeexamplesocketnode1socket cabal exec cardanocli gettip testnetmagic you will see output from stdout in this format codeblock console current tip block hash 4ab21a10e1b25e39 slot block number update proposals update proposal creation a byron update proposal can be created as follows codeblock console cardanocli byron governance createupdateproposal mainnet testnetmagic natural signingkey filepath protocolversionmajor word16 protocolversionminor word16 protocolversionalt word8 applicationname string softwareversionnum word32 systemtag string installerhash hash filepath filepath the mandatory arguments are mainnet testnetmagic signingkey protocolversionmajor protocolversionminor protocolversionalt applicationname softwareversionnum systemtag installerhash and filepath the remaining arguments are optional parameters you want to update in your update proposal you can also check your proposals validity using the validatecbor command see validate cbor files see the byron specification for more details on update proposals update proposal submission you can submit your proposal using the submitupdateproposal command example codeblock console cardanocli byron governance submitupdateproposal config configurationdefaultsmainnetconfigurationyaml mainnet testnetmagic natural filepath myupdateproposal see the byron specification for more details on update proposals update proposal voting you can create and submit byron update proposal votes with the createproposalvote submitproposalvote commands the following are two example commands byron vote creation codeblock console cabal exec cardanocli byron governance createproposalvote mainnet testnetmagic natural signingkey configurationdefaultsliveviewgenesisdelegatekeys000key proposalfilepath protocolupdateproposalfile voteyes outputfilepath updateproposalvotefile byron vote submission codeblock console cabal exec cardanocli byron governance submitproposalvote mainnet testnetmagic natural filepath updateproposalvotefile development ghcid run ghcid with ghcid c cabal repl execardanonode reordergoals note when developing locally for any package you are working on in cabalproject set ghcoptions to wwarn and set the development flag eg package cardanonode ghcoptions wwarn flags development otherwise ghc might complain about unused packages native tokens native tokens is a new feature that enables the transacting of multiassets on cardano native tokens are now supported on mainnet and users can transact with ada and an unlimited number of userdefined custom tokens natively note that users who do not need to create new assets token holders will be able to send and receive existing multiasset tokens using a wallet such as daedalus or yoroi and with no requirement to use any cli commands to help you get started see cardano forum discussion ledger explanations native tokens covers explainers about assets tokens token bundles minting policies comparison to erc20 and minimum ada value requirements a tutorial on how to get started with native tokens explains how to create new currencies and assets submit and send transactions containing multiasset tokens send and receive token bundles manage your addresses and values native tokens exercises to start please ensure that you are familiar with setting up and operating the cardano node alternatively see instructions on how to start your node to submit the commands you will not need to set up and start a full block producing node stake pool just a much simpler relay node this node will need to connect to a cardano network that is capable of processing native tokens eg the native token preproduction environment ppe or the cardano mainnet api documentation the api documentation is published here the documentation is built with each push but is only published from master branch in order to test if the documentation is working build the documentation locally with cabal haddockproject local outputhaddocks and open haddocksindexhtml in the browser using the cardanonode haskell packages if you want to use the cardanonode haskell packages from another project you should use chap to get the packages defined in this repository please note that you may need to use any sourcerepositorypackage stanzas defined in cabalproject although we will endeavour to keep these to an absolute minimum style guide the style guide for can be found on the cardanonode repositorys wiki troubleshooting cardanonode issues for some troubleshooting help with building or running cardanonode the wiki has a troubleshooting page that documents some common gotchas
zcash,zcash,Zcash - Internet Money,https://github.com/zcash/zcash,4857,1985,373,1085,C++: 7491364; Python: 2408441; C: 1314875; Rust: 497045; Shell: 193860; M4: 177264; Makefile: 107090; Sage: 41479; CMake: 28560; Assembly: 28178; HTML: 20943; Dockerfile: 2929,,Other,2014-11-22T03:13:10Z,2024-04-28T03:21:21Z,112423,public,None,master,zcash what is zcash zcash is https for money initially based on bitcoins design zcash has been developed from the zerocash protocol to offer a far higher standard of privacy and anonymity it uses a sophisticated zeroknowledge proving scheme to preserve confidentiality and hide the connections between shielded transactions more technical details are available in our protocol specification the zcashd full node this repository hosts the zcashd software a zcash consensus node implementation it downloads and stores the entire history of zcash transactions depending on the speed of your computer and network connection the synchronization process could take several days the zcashd code is derived from a source fork of bitcoin core the code was forked initially from bitcoin core v0112 and the two codebases have diverged substantially lock security warnings see important security warnings on the security information page zcash is experimental and a work in progress use it at your own risk ledger deprecation policy this release is considered deprecated weeks after the release day there is an automatic deprecation shutdown feature which will halt the node some time after this 16week period the automatic feature is based on block height other zcash implementations the zebra project offers a different zcash consensus node implementation written largely from the ground up getting started please see our user guide for instructions on joining the main zcash network need help bluebook see the documentation at the readthedocs for help and more information incomingenvelope ask for help on the zcash forum speechballoon join our community on discord learn at zechub participation in the zcash project is subject to a code of conductcodeofconductmd building build zcash along with most dependencies from source by running the following command zcutilbuildsh jnproc currently zcash is only officially supported on debian and ubuntu see the debian ubuntu build for detailed instructions license for license information see the file copyingcopying
openai,gym,A toolkit for developing and comparing reinforcement learning algorithms.,https://github.com/openai/gym,33907,8553,1062,92,Python: 1113386; Dockerfile: 1016; Shell: 484,,Other,2016-04-27T14:59:16Z,2024-05-02T17:02:50Z,7113,public,None,master,precommit code style black important notice the team that has been maintaining gym since has moved all future development to gymnasium a drop in replacement for gym import gymnasium as gym and gym will not be receiving any future updates please switch over to gymnasium as soon as youre able to do so if youd like to read more about the story behind this switch please check out this blog post gym gym is an open source python library for developing and comparing reinforcement learning algorithms by providing a standard api to communicate between learning algorithms and environments as well as a standard set of environments compliant with that api since its release gyms api has become the field standard for doing this gym documentation website is at and you can propose fixes and changes to it here gym also has a discord server for development purposes that you can join here installation to install the base gym library use pip install gym this does not include dependencies for all families of environments theres a massive number and some can be problematic to install on certain systems you can install these dependencies for one family like pip install gymatari or use pip install gymall to install all dependencies we support python and on linux and macos we will accept prs related to windows but do not officially support it api the gym apis api models environments as simple python env classes creating environment instances and interacting with them is very simple heres an example using the cartpolev1 environment python import gym env gymmakecartpolev1 observation info envresetseed42 for in range1000 action envactionspacesample observation reward terminated truncated info envstepaction if terminated or truncated observation info envreset envclose notable related libraries please note that this is an incomplete list and just includes libraries that the maintainers most commonly point newcommers to when asked for recommendations cleanrl is a learning library based on the gym api it is designed to cater to newer people in the field and provides very good reference implementations tianshou is a learning library thats geared towards very experienced users and is design to allow for ease in complex algorithm modifications rllib is a learning library that allows for distributed training and inferencing and supports an extraordinarily large number of features throughout the reinforcement learning space pettingzoo is like gym but for environments with multiple agents environment versioning gym keeps strict versioning for reproducibility reasons all environments end in a suffix like v0 when changes are made to environments that might impact learning results the number is increased by one to prevent potential confusion mujoco environments the latest v4 and future versions of the mujoco environments will no longer depend on mujocopy instead mujoco will be the required dependency for future gym mujoco environment versions old gym mujoco environment versions that depend on mujocopy will still be kept but unmaintained to install the dependencies for the latest gym mujoco environments use pip install gymmujoco dependencies for old mujoco environments can still be installed by pip install gymmujocopy citation a whitepaper from when gym just came out is available and can be cited with the following bibtex entry misc160601540 author greg brockman and vicki cheung and ludwig pettersson and jonas schneider and john schulman and jie tang and wojciech zaremba title openai gym year eprint arxiv160601540 release notes there used to be release notes for all the new gym versions here new release notes are being moved to releases page on github like most other libraries do old notes can be viewed here
deepmind,lab,A customisable 3D platform for agent-based AI research,https://github.com/google-deepmind/lab,7025,1361,468,59,C: 12886842; Lua: 1325159; C++: 1025625; GLSL: 151382; Python: 140986; ShaderLab: 109219; Starlark: 87059; HTML: 69263; Assembly: 25861; Roff: 21060; Shell: 6050; Yacc: 4260; Objective-C: 3253; Perl: 944; Makefile: 829,artificial-intelligence;deep-learning;machine-learning;neural-networks,Other,2016-11-30T13:41:26Z,2024-05-01T14:22:17Z,460126,public,None,master,deepmind lab is a 3d learning environment based on id softwares quake iii arena via ioquake3 and other open source softwareupstreamsources deepmind lab provides a suite of challenging 3d navigation and puzzlesolving tasks for learning agents its primary purpose is to act as a testbed for research in artificial intelligence especially deep reinforcement learning about disclaimer this is not an official google product if you use deepmind lab in your research and would like to cite the deepmind lab environment we suggest you cite the deepmind lab paper you can reach us at labdeepmindcommailtolabdeepmindcom getting started on linux get bazel from bazelio clone deepmind lab eg by running shell git clone cd lab for a live example of a random agent run shell lab bazel run pythonrandomagent define graphicssdl length10000 width640 height480 here is some more detailed build documentationdocsusersbuildmd including how to install dependencies if you dont have them to enable compiler optimizations pass the flag compilationmodeopt or c opt for short to each bazel build bazel test and bazel run command the flag is omitted from the examples here for brevity but it should be used for real training and evaluation where performance matters play as a human to test the game using human input controls run shell lab bazel run game levelscripttestsemptyroomtest levelsettinglogtostderrtrue or lab bazel run game l testsemptyroomtest s logtostderrtrue leave the logtostderr setting off to disable most log output the values of observations that the environment exposes can be printed at every step by adding a flag observation observationname for each observation of interest shell lab bazel run game levelscriptltchasm observation veltrans observation velrot train an agent deepmind lab ships with an example random agent in pythonrandomagentpypythonrandomagentpy which can be used as a starting point for implementing a learning agent to let this agent interact with deepmind lab for training run shell lab bazel run pythonrandomagent the python apidocsuserspythonapimd is used for agentenvironment interactions we also provide bindings to deepminds dmenv general api for reinforcement learning as well as a way to build a selfcontained pip package see the separate documentationpythonpippackagereadmemd for details deepmind lab ships with different levelsdocslevelsmd implementing different tasks these tasks can be configured using lua scripts as described in the lua apidocsdevelopersreferenceluaapimd upstream sources deepmind lab is built from the ioquake3 game engine and it uses the tools q3map2 and bspc for map creation bug fixes and cleanups that originate with those projects are best fixed upstream and then merged into deepmind lab bspc is taken from githubcomttimobspc revision d9a372db3fb6163bc49ead41c76c801a3d14cf80 there are virtually no local modifications although we integrate this code with the main ioq3 code and do not use their copy in the deps directory we expect this code to be stable q3map2 is taken from githubcomttimogtkradiant revision d3d00345c542c8d7cc74e2e8a577bdf76f79c701 a few minor local modifications add synchronization we also expect this code to be stable ioquake3 is taken from githubcomioquakeioq3 revision 29db64070aa0bae49953bddbedbed5e317af48ba the code contains extensive modifications and additions we aim to merge upstream changes occasionally we are very grateful to the maintainers of these repositories for all their hard work on maintaining highquality code bases external dependencies prerequisites and porting notes deepmind lab currently ships as source code only it depends on a few external software libraries which we ship in several different ways the zlib glib libxml2 jpeg and png libraries are referenced as external bazel sources and bazel build files are provided the dependent code itself should be fairly portable but the build rules we ship are specific to linux on x86 to build on a different platform you will most likely have to edit those build files message digest algorithms are included in this package in thirdpartymdthirdpartymd taken from the reference implementations of their respective rfcs a generic reinforcement learning api is included in thirdpartyrlapithirdpartyrlapi which has also been created by the deepmind lab authors this code is portable egl headers are included in this package in thirdpartygleglthirdpartygleglkhrthirdpartyglkhr taken from the khronos openglopengl es xml api registry at wwwkhronosorgregistryegl the headers have been modified slightly to remove the dependency of egl on x several additional libraries are required but are not shipped in any form they must be present on your system sdl gettext required by glib opengl a hardware driver and library are needed for hardwareaccelerated human play the headless library that machine learning agents will want to use can use either hardwareaccelerated rendering via egl or glx or software rendering via osmesa depending on the define headless build setting python other versions might work too with numpy pil a few tests require a numpy version of at least or python at least with numpy and pillow the build rules are using a few compiler settings that are specific to gcc if some flags are not recognized by your compiler typically those would be specific warning suppressions you may have to edit those flags the warnings should be noisy but harmless
Latitude-Archives,AIDungeon,Infinite adventures await!,https://github.com/latitudegames/AIDungeon,3164,552,84,64,Python: 90515; Jupyter Notebook: 8949; Shell: 3675,,MIT License,2019-04-03T02:38:55Z,2024-04-29T23:33:34Z,39478,public,None,develop,aidungeon2 read more about aidungeon2 and how it was built here play the mobile app version of the game by following the links here play the game online by following this link here play the game in colab here to play the game locally it is recommended that you have an nvidia gpu with gb or more of memory and cuda installed if you do not have such a gpu each turn can take a couple of minutes or more for the game to compose its response to install and play locally git clone branch master cd aidungeon installsh installs system packages and creates python3 virtual environment downloadmodelsh source venvbinactivate playpy finetune the model yourself formatting the data after scraping the data i formatted text adventures into a json dict structure that looked like the following treeid storystart actionresults action result actionresults action result actionresults essentially its a tree that captures all the action result nodes then i used this to transform that data into one giant txt file the txt file looks something like you are a survivor living in some place you search for food you search for food but are unable to find any do another thing you do another thing above repeated many times then once you have that you can use the finetuning script to fine tune the model provided you have the hardware fine tuning the largest gpt2 model is difficult due to the immense hardware required i no longer have access to the same hardware so there are two ways i would suggest doing it i originally fine tuned the model on 32gb v100 gpus an nvidia dgx1 this allowed me to use a batch size of which i found to be helpful in improving quality the only cloud resource i could find that matches those specs is an aws p3dn24xlarge instance so youd want to spin that up on ec2 and fine tune it there might have to also request higher limits another way you could do it is to use a sagemaker notebook similar to a colab notebook and select the p324xlarge instance type this is equivalent to gb v100 gpus because each gpu has only 16gb memory you probably need to reduce the batch size to around community aidungeon is an open source project questions discussion and contributions are welcome contributions can be anything from new packages to bugfixes documentation or even new core features resources website aidungeonio email aidungeoniogmailcom twitter creator nickwalton00 dev benjbay reddit raidungeon discord aidungeon discord contributing contributing to aidungeon is easy just send us a pull request from your fork before you send it summarize your change in the unreleased section of the changelogchangelogmd and make sure develop is the destination branch aidungeon uses a rough approximation of the git flow branching model the develop branch contains the latest contributions and master is always tagged and points to the latest stable release if youre a contributor make sure youre testing and playing on develop thats where all the magic is happening and where we hope bugs stop
CorentinJ,Real-Time-Voice-Cloning,Clone a voice in 5 seconds to generate arbitrary speech in real-time,https://github.com/CorentinJ/Real-Time-Voice-Cloning,50823,8544,935,192,Python: 252952,deep-learning;python;pytorch;tensorflow;tts;voice-cloning,Other,2019-05-26T08:56:15Z,2024-05-02T16:50:35Z,369676,public,None,master,realtime voice cloning this repository is an implementation of transfer learning from speaker verification to multispeaker texttospeech synthesis sv2tts with a vocoder that works in realtime this was my masters thesis sv2tts is a deep learning framework in three stages in the first stage one creates a digital representation of a voice from a few seconds of audio in the second and third stages this representation is used as reference to generate speech given arbitrary text video demonstration click the picture toolbox demo papers implemented url designation title implementation source sv2tts transfer learning from speaker verification to multispeaker texttospeech synthesis this repo wavernn vocoder efficient neural audio synthesis fatchordwavernn tacotron synthesizer tacotron towards endtoend speech synthesis fatchordwavernn ge2e encoder generalized endtoend loss for speaker verification this repo heads up like everything else in deep learning this repo is quickly getting old many other opensource repositories or saas apps often paying will give you a better audio quality than this repository will if you care about the fidelity of the voice youre cloning and its expressivity here are some personal recommendations of alternative voice cloning solutions check out coquitts for an open source repository that is more uptodate with a better voice cloning quality and more functionalities check out paperswithcode for other repositories and recent research in the field of speech synthesis check out resembleai disclaimer i work there for state of the art voice cloning with little hassle setup install requirements both windows and linux are supported a gpu is recommended for training and for inference speed but is not mandatory python is recommended python or greater should work but youll probably have to tweak the dependencies versions i recommend setting up a virtual environment using venv but this is optional install ffmpeg this is necessary for reading audio files install pytorch pick the latest stable version your operating system your package manager pip by default and finally pick any of the proposed cuda versions if you have a gpu otherwise pick cpu run the given command install the remaining requirements with pip install r requirementstxt optional download pretrained models pretrained models are now downloaded automatically if this doesnt work for you you can manually download them here optional test configuration before you download any dataset you can begin by testing your configuration with python democlipy if all tests pass youre good to go optional download datasets for playing with the toolbox alone i only recommend downloading librispeechtrainclean100 extract the contents as librispeechtrainclean100 where is a directory of your choosing other datasets are supported in the toolbox see here youre free not to download any dataset but then you will need your own data as audio files or you will have to record it with the toolbox launch the toolbox you can then try the toolbox python demotoolboxpy d or python demotoolboxpy depending on whether you downloaded any datasets if you are running an xserver or if you have the error aborted core dumped see this issue
johnolafenwa,DeepStack,The World's Leading Cross Platform AI Engine for Edge Devices,https://github.com/johnolafenwa/DeepStack,647,105,34,69,Python: 119363; CSS: 60295; Go: 53979; SCSS: 11930; PowerShell: 8709; HTML: 5672; JavaScript: 3379; Inno Setup: 1622; Shell: 688,ai-engine;computer-vision;deepstack;face-detection;face-recognition;object-detection;scene-recognition,Apache License 2.0,2020-05-23T19:31:08Z,2024-05-01T18:05:21Z,413887,public,None,dev,deepstack the worlds leading cross platform ai engine for edge devices with over million installs on docker hub black license devtest website documentation forum dev center deepstack is owned and maintained by deepquest ai introduction deepstack is an ai api engine that serves prebuilt models and custom models on multiple edge devices locally or on your private cloud supported platforms are linux os via docker cpu and nvidia gpu support mac os via docker windows native application cpu and gpu nvidia jetson via docker rasperry pi arm64 devices via docker deepstack runs completely offline and independent of the cloud you can also install and run deepstack on any cloud vm with docker installed to serve as your private stateoftheart and realtime ai server features face apis face detection recognition and matching face apidemofaceapijpg common objects apis object detection for common objects detection apidemodetectionapijpg custom models train and deploy new models to detect any custom objects custom models apidemocustommodeljpg image enhance 4x image superresolution input image enhance api iputdemoenhanceinputjpg output image enhance api iputdemoenhanceoutputjpg scene recognition image scene recognition ssl support api key support security options to protect your deepstack endpoints installation and usage visit for installation instructions the documentation provides example codes for the following programming languages with more to be added soon python c nodejs build from source for docker version install prerequisites install golang install docker install git install git lfs install redis server install python37 install powershell clone deepstack repo git clone cd to deepstack repo dir cd deepstack fetch repo files git lfs pull download binary dependencies with powershell downloaddependenciesps1 build deepstack cpu version cd sudo docker build t deepquestaideepstackcpu f dockerfilecpu build deepstack gpu version sudo docker build t deepquestaideepstackgpu f dockerfilegpu build deepstack jetson version sudo docker build t deepquestaideepstackjetpack f dockerfilegpujetpack running and testing locally without building unless you wish to install requirements system wide create a virtual environment with python37 m venv venv and activate with source venvbinactivate install requirements with pip3 install r requirementstxt for cpu version install pytorch with pip3 install torch160cpu torchvision070cpu f for gpu version install pytorch with pip3 install torch160cu101 torchvision070cu101 f start powershell pwsh for cpu version run setupdockercpups1 for gpu version run setupdockergpups1 cd to server dir cd server build deepstack server go build set any of the apis to enable envvisiondetection true envvisionface true envvisionscene true run deepstack server you can find all logs in the directory in the repo root note that deepstack will be running on the default port integrations and community the deepstack ecosystem includes a number of popular integrations and libraries built to expand the functionalities of the ai engine to serve iot industrial monitoring and research applications a number of them are listed below hassdeepstackobject an home assistant addon by robin cole for detecting common and custom objects hassdeepstackface an home assistant addon by robin cole for face detection registration and recognition hassdeepstackscene an home assistant addon by robin cole for scene recognition deepstack with blue iris youtube video a deepstack bluiris setup tutorial by thehookup youtube channel blue iris deepstack built in full walk through another and very recent deepstack bluiris setup tutorial by thehookup youtube channel deepstack with blue iris forum discussion a comprehensive deepstack discussion thread on the ipcamtalk website deepstack on home assistant a comprehensive deepstack discussion thread on the home assistant forum website deepstackui a streamlit by robin cole for exploring deepstacks features deepstackpython helper a python client library by robin cole for deepstack apis deepstackanalytics a analytics tool by robin cole for exploring deepstacks apis deepstackai trigger a deepstack automation system integration with mqtt and telegram support by neil enns noderedcontribdeepstack a nodered integration for all deepstack apis by joakim lundin deepstackusps a custom deepstack model for detecting usps logo by stephen stratoti agendvr a dvr platform with deepstack integrations built by sean tearney onguard a security camera application for http onvif and ftp with deepstack integrations by ken contributors guide coming soon
apache,mahout,Mirror of Apache Mahout,https://github.com/apache/mahout,2122,945,234,5,HTML: 23467; Python: 15927; SCSS: 12611; JavaScript: 5649; Shell: 2255; Ruby: 1722,java;library;mahout,Apache License 2.0,2014-05-23T07:00:07Z,2024-05-02T15:13:05Z,63907,public,None,main,welcome to apache mahout the goal of the apache mahout project is to build an environment for quickly creating scalable performant machine learning applications for additional information about mahout visit the mahout home page qumat logodocsassetsmascotpng qumat qumat is a poc of a high level python library for intefacing with multiple quantum computing backends it is designed to be easy to use and to abstract the particularities of each backend so that you may write once run anywhere like the java of quantum computing but java is the new cobol so were trying to distance ourselves from that comparison p check out basic gatesdocsbasicgatesmd for a quick introduction to the basic gates which are basically all that exist right now and even those only exist for qiskit getting started to install dependencies run the following pip install u poetry poetry install legal please see the noticetxt included in this directory for more information
